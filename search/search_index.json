{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"eyepy <p> A powerful Python package for importing, analyzing, and visualizing retinal imaging data, including OCT and OCT Angiography. </p> <p></p> <p> </p> <p><code>eyepy</code> provides a unified and user-friendly interface for working with retinal imaging data. With support for a wide range of file formats, it enables researchers and clinicians to import, process, and visualize OCT volumes and angiography data with ease. The core <code>EyeVolume</code> object offers intuitive methods for plotting fundus images, B-scans, and quantitative analyses such as drusen and retinal layer thickness. Comprehensive documentation and example workflows are available to help you get started quickly.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Import Structural Data (HEYEX-E2E, HEYEX-VOL, HEYEX-XML, Topcon-FDA, B-Scan collections, RETOUCH Challenge, AMD Dataset from Duke University)</li> <li>Import Angiographic OCT Data (HEYEX-VOL)</li> <li>Analyze OCT volumes (compute and quantify drusen)</li> <li>Visualize OCT volumes with annotations and quantifications</li> <li>Compute and visualize retinal layer thickness</li> <li>Compute and visualize OCTA enface projections.</li> <li>Save and load EyeVolume objects</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<p>Attention: If you want to use a version prior to 0.12.0 you have to install from the <code>eyepie</code> name instead. This is because we used <code>eyepie</code> as a package name on PyPI until the previous owner of the <code>eyepy</code> name on PyPI was so kind to transfer it to us.</p> <p>To install the latest version of eyepy run <code>pip install -U eyepy</code>. (It is <code>eyepie</code> for versions &lt; 0.12.0)</p>"},{"location":"#optional-dependencies","title":"Optional Dependencies","text":"<p>Some file formats require additional dependencies: - Topcon FDA files: <code>pip install eyepy[fda]</code> (requires <code>oct-converter</code>) - RETOUCH dataset: <code>pip install eyepy[itk]</code> (requires <code>itk</code>)</p>"},{"location":"#getting-started_1","title":"Getting Started","text":"<p>When you don't have a supported OCT volume at hand you can check out our sample datasets to get familiar with <code>eyepy</code>.</p> <pre><code>from eyepy.data import load\nstruc_ev = load(\"drusen_patient\")\nstruc_ev = load(\"healthy_OD\")\nangio_ev = load(\"healthy_OD_Angio\")\n</code></pre> <p>If you have data at hand use one of eyepy's import functions.</p> <pre><code># Import HEYEX E2E export\nev = ep.import_heyex_e2e(\"path/to/file.e2e\")\n# Import HEYEX XML export\nev = ep.import_heyex_xml(\"path/to/folder\")\n# Import HEYEX VOL export\nev = ep.import_heyex_vol(\"path/to/file.vol\")\n# Import Topcon FDA export\nev = ep.import_topcon_fda(\"path/to/file.fda\")\n# Import volume from Duke public dataset\nev = ep.import_duke_mat(\"path/to/file.mat\")\n# Import volume from RETOUCH challenge\nev = ep.import_retouch(\"path/to/volume_folder\")\n# Import HEYEX OCTA VOL export\nev_angio = ep.import_heyex_angio_vol(\"path/to/volume_folder\")\n</code></pre>"},{"location":"#spectralis-octa-oct-angiography-support","title":"Spectralis OCTA (OCT Angiography) Support","text":"<p><code>eyepy</code> is capable of reading and visualizing OCT Angiography (OCTA) data from Heidelberg Spectralis devices. You can explore and analyze both structural and angiography volumes using the same unified interface.</p>"},{"location":"#example-load-and-visualize-spectralis-octa-sample-data","title":"Example: Load and Visualize Spectralis OCTA Sample Data","text":"<p>The following example demonstrates how to load OCTA sample data, and plot the enface projections.</p> <p><pre><code>import eyepy as ep\nimport matplotlib.pyplot as plt\n\n# Load sample data\nangio_OD = ep.data.load(\"healthy_OD_Angio\")\nangio_OS = ep.data.load(\"healthy_OS_Angio\")\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 7))\nfor i, (angio, title) in enumerate(zip([angio_OD, angio_OS], [\"Right Eye (OD)\", \"Left Eye (OS)\"])):\n    # Show localizer with Angiography overlay for the complete retina\n    angio.plot(ax=axes[i], slabs=[\"RET\"])\n    axes[i].set_title(title)\n    axes[i].axis(\"off\")\n\nplt.tight_layout()\n</code></pre> </p>"},{"location":"#related-projects","title":"Related Projects:","text":"<ul> <li>eyeseg: A python package for segmentation of retinal layers and drusen in OCT data.</li> <li>OCT-Converter: Extract raw optical coherence tomography (OCT) and fundus data from proprietary file formats. (.fds/.fda/.e2e/.img/.oct/.dcm)</li> <li>eyelab: A GUI for annotation of OCT data based on eyepy</li> <li>Projects by the Translational Neuroimaging Laboratory</li> <li>LibOctData</li> <li>LibE2E</li> <li>OCT-Marker</li> <li>UOCTE Unofficial continuation of https://bitbucket.org/uocte/uocte</li> <li>OCTAnnotate</li> <li>heyexReader</li> <li>OCTExplorer Iowa Reference Algorithm</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use eyepy in your research, please cite it. You can find citation information and export BibTeX entries via the Zenodo record: </p>"},{"location":"#contributing","title":"Contributing","text":"<p>For details on contributing and setting up a development environment, see the Contributing Guide.</p>"},{"location":"changelog/","title":"CHANGELOG","text":""},{"location":"changelog/#v0122-2023-11-15","title":"v0.12.2 (2023-11-15)","text":""},{"location":"changelog/#build","title":"Build","text":"<ul> <li> <p>build(_quality.yaml): removes caching of poetry (<code>a7c20e1</code>)</p> </li> <li> <p>build(eyepy): updates versions (<code>23fec54</code>)</p> </li> <li> <p>build(eyepy): removes python 3.8 from testing matrix (<code>b2bcf7b</code>)</p> </li> <li> <p>build(eyepy): upgrades dependencies (<code>e66fd8b</code>)</p> </li> </ul>"},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li> <p>fix(_release.yaml): corrects python-semantic-release version (<code>f7171ba</code>)</p> </li> <li> <p>fix(eyemeta.py): convert dates to string for saving as json (<code>5d715cd</code>)</p> </li> </ul>"},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li> <p>refactor(eyevolume.py): changes skimage import of GeometricTransform (<code>31ce767</code>)</p> </li> <li> <p>refactor(EyeVolume): rename method from remove_pixel_annotations to remove_pixel_annotation (<code>6727a60</code>)</p> </li> </ul>"},{"location":"changelog/#v0121-2023-09-26","title":"v0.12.1 (2023-09-26)","text":""},{"location":"changelog/#ci","title":"Ci","text":"<ul> <li>ci(PythonSemanticRelease): update python semantic release to v8; minor change to README; added support for py3.11; updated dependencies (<code>d4e65a8</code>)</li> </ul>"},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>fix(vol_reader.py): get number of read layers from file context instead of assuming 17 layers. (<code>2b53a33</code>)</li> </ul>"},{"location":"changelog/#v0120-2023-05-31","title":"v0.12.0 (2023-05-31)","text":""},{"location":"changelog/#breaking","title":"Breaking","text":"<ul> <li>build(eyepy): switch from eyepie to eyepy as a package name on PyPI</li> </ul> <p>Thanks to @dillongwozdz for transfering the eyepy name to us.</p> <p>BREAKING CHANGE: (<code>8d07a17</code>)</p>"},{"location":"changelog/#ci_1","title":"Ci","text":"<ul> <li>ci(github/workflows): update github actions (setup-python to v4, checkout to v3, cache to v3) (<code>1727f51</code>)</li> </ul>"},{"location":"changelog/#v0113-2023-04-04","title":"v0.11.3 (2023-04-04)","text":""},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>docs(README.md;-cookbook.md): Add examples for importing data from different sources (<code>2a71e11</code>)</li> </ul>"},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>fix(eyepy.io): fixes duke layer heights import (<code>eb18f2a</code>)</li> </ul>"},{"location":"changelog/#v0112-2023-04-02","title":"v0.11.2 (2023-04-02)","text":""},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li> <p>fix(EyeVolume): fix saving, old method sometimes tried to recursively add the archive to the archive (<code>e6064cc</code>)</p> </li> <li> <p>fix(import_duke_mat): fixes age parsing from duke data (<code>ecbcbc2</code>)</p> </li> </ul>"},{"location":"changelog/#v0111-2023-03-31","title":"v0.11.1 (2023-03-31)","text":""},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>fix(EyeVolumeMeta): fixes saving issue by storing all dates as string in isoformat to avoid problems with dumping to json and loading (<code>3fc7424</code>)</li> </ul>"},{"location":"changelog/#v0110-2023-03-30","title":"v0.11.0 (2023-03-30)","text":""},{"location":"changelog/#feature","title":"Feature","text":"<ul> <li> <p>feat(io.init.py): adds support for topcon fda files (#12)</p> </li> <li> <p>NF: add basic support for fda files</p> </li> <li> <p>refactor(main-and-io-module-init-files): specify topcon as vendor in fda import function</p> </li> <li> <p>feat(io.init.py): add bscan metadata to returned eye volume</p> </li> </ul> <p>before the fda reader only parsed bscans and segmentation. These changes incorporate scaling and bscan position in fundus images.</p> <ul> <li>feat(io.init.py): add fundus image to eyevolume</li> </ul> <p>the changes allow to create a full EyeVolume with fundus image and metadata</p> <ul> <li>style(io.init.py): remove double quotes</li> </ul> <p>Co-authored-by: Olivier Morelle &lt;Oli4@users.noreply.github.com&gt; (<code>53f2908</code>)</p>"},{"location":"changelog/#v0100-2023-03-30","title":"v0.10.0 (2023-03-30)","text":""},{"location":"changelog/#ci_2","title":"Ci","text":"<ul> <li>ci(.github): add pre-commit checking to quality workflow and call quality workflow for pull requests (<code>9e47a09</code>)</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>docs(core.annotations): adds docstrings (<code>236c074</code>)</li> </ul>"},{"location":"changelog/#feature_1","title":"Feature","text":"<ul> <li>feat(core.plotting): adds a scale bar and a watermark to Bscan and Fundus visualizations (<code>0e3eaa0</code>)</li> </ul>"},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>fix(eyepy.core): fixes bscan_region and bscan_position plotting when plotting only a part of the fundus</li> </ul> <p>also adds new header_gif to the README (<code>2c88074</code>)</p> <ul> <li>fix(core.grids.py): fixes error related to python 3.8 not supporting new type annotation Dict-dict List-list (<code>3c6ba41</code>)</li> </ul>"},{"location":"changelog/#style","title":"Style","text":"<ul> <li>style(eyepy): applys improved pre-commit style guides</li> </ul> <p>adds dostrings formatting via docformatter \\n unifies single/double quotes \\n upgrades type hints to be pep585 compliant (<code>28b1b4c</code>)</p>"},{"location":"changelog/#v092-2023-03-17","title":"v0.9.2 (2023-03-17)","text":""},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li> <p>docs(eyepy.core): adds type annotations to all objects in the core subpackage (<code>ea1cb4c</code>)</p> </li> <li> <p>docs(annotations.py): adds type annotations to all objects in this module (<code>986f9bc</code>)</p> </li> </ul>"},{"location":"changelog/#fix_6","title":"Fix","text":"<ul> <li>fix(e2e_reader.py): makes exception formatting compatible with python &lt; 3.10 (<code>2c4cbb0</code>)</li> </ul>"},{"location":"changelog/#v091-2023-03-15","title":"v0.9.1 (2023-03-15)","text":""},{"location":"changelog/#ci_3","title":"Ci","text":"<ul> <li>ci(ci.yaml): set python version to 3.10 for building and deploying documentation (<code>b6feb0d</code>)</li> </ul>"},{"location":"changelog/#documentation_3","title":"Documentation","text":"<ul> <li>docs(README.md): clarify that the localizer is a fundus image (<code>4e41acd</code>)</li> </ul>"},{"location":"changelog/#fix_7","title":"Fix","text":"<ul> <li> <p>fix(e2e_reader.py): extract number of Bscans more reliably by using the number of slice substructures; Skip localizer affine transformation for now, because slodata is not always available; support reading single B-scan data (<code>1287a24</code>)</p> </li> <li> <p>fix(e2e_format.py): change the name of E2EFile to E2EFormat to avoid confustion with E2EFileStructure in e2e_reader.py (<code>01be6a0</code>)</p> </li> </ul>"},{"location":"changelog/#v090-2023-03-09","title":"v0.9.0 (2023-03-09)","text":""},{"location":"changelog/#breaking_1","title":"Breaking","text":"<ul> <li>feat(HeE2EReader): switch to construct_typed for describing structures; create file hierarchy when parsing the E2E file; add search functions to the HeE2eReader</li> </ul> <p>BREAKING CHANGE: (<code>45578a5</code>)</p>"},{"location":"changelog/#documentation_4","title":"Documentation","text":"<ul> <li>docs(documentation): improve documentation; rename Voxel/Area Annotation to PixelAnnotation for consistency (<code>ab38837</code>)</li> </ul>"},{"location":"changelog/#feature_2","title":"Feature","text":"<ul> <li>feat(eyepy.io.utils.py): add functions to search for integer/float values in binary data; set relative tolerance for Bscan distance to 4% (fixes sample data warning) (<code>96fd58b</code>)</li> </ul>"},{"location":"changelog/#fix_8","title":"Fix","text":"<ul> <li> <p>fix(HeE2eReader): fix issues with inspect after renaming classes (<code>891c79c</code>)</p> </li> <li> <p>fix(init.py): exclude init.py from isort to prevent circular import (<code>9254231</code>)</p> </li> <li> <p>fix(pyproject.toml): add imageio as dependency and umpgrade imagecodecs to latest version (<code>bef44a0</code>)</p> </li> </ul>"},{"location":"changelog/#v081-2023-02-22","title":"v0.8.1 (2023-02-22)","text":""},{"location":"changelog/#fix_9","title":"Fix","text":"<ul> <li>fix(pyproject.toml): increase allowed version range for numpy (fixes #10) (<code>c66f6f6</code>)</li> </ul>"},{"location":"changelog/#v080-2023-02-13","title":"v0.8.0 (2023-02-13)","text":""},{"location":"changelog/#build_1","title":"Build","text":"<ul> <li>build(pyproject.toml): add itk as optional dependency to read RETOUCH data and pygifsicle as dev dependency to optimize the header.gif (<code>ccf0d8e</code>)</li> </ul>"},{"location":"changelog/#documentation_5","title":"Documentation","text":"<ul> <li> <p>docs(README.md-/-Cookbook): Add header image to README (<code>7501dde</code>)</p> </li> <li> <p>docs(README-and-Cookbook): fix import of load function in examples (<code>e623c4b</code>)</p> </li> </ul>"},{"location":"changelog/#feature_3","title":"Feature","text":"<ul> <li> <p>feat(eyepy.core): reflect plotted region in x and y axis for both localizer and B-scan; check if bscan_region bscan position indicators are in plotting region (<code>2842424</code>)</p> </li> <li> <p>feat(eyepy.io): fix imagio warnings; raise ValueError for scan-pattern 2 and 5 instead of warning; set maxint to NAN when reading XML layers; fix bscan order in layer data (vol_reader) (<code>c4a88e7</code>)</p> </li> </ul>"},{"location":"changelog/#fix_10","title":"Fix","text":"<ul> <li> <p>fix(src/eyepy/io): convert very large layer heights indicating no valid layer to np.nan (<code>352a984</code>)</p> </li> <li> <p>fix(eyepy.core): make sure ticklabels match plotted image region for EyeEnfac ande EyeBscan plots (<code>f389f47</code>)</p> </li> <li> <p>fix(eyepy.core.utils.py): ignore nans in layers when computing drusen from layer heights (<code>3c4efcd</code>)</p> </li> <li> <p>fix(eyepy.core): set axis in all layer height maps to (n_bscans, width)</p> </li> </ul> <p>Layer in the sample were not correctly oriented due to a different axis order in the HeXMLReader (<code>3493b0e</code>)</p>"},{"location":"changelog/#style_1","title":"Style","text":"<ul> <li>style(eyepy/config.py): change default color of bscan region and bscan position indicators from green to limegreen because of better visibility (<code>3658a11</code>)</li> </ul>"},{"location":"changelog/#test","title":"Test","text":"<ul> <li>test(test_eyevolume.py): correct indexing of layer data</li> </ul> <p>The first axis (bscan axis) of the layer data was flipped to reflect B-scan indexing. Therefore layers have to be flipped now when computing drusen and projecting on the localizer. (<code>d186317</code>)</p>"},{"location":"changelog/#v070-2023-02-10","title":"v0.7.0 (2023-02-10)","text":""},{"location":"changelog/#breaking_2","title":"Breaking","text":"<ul> <li>refactor(eyepy): work in progress</li> </ul> <p>BREAKING CHANGE: (<code>c942c6b</code>)</p>"},{"location":"changelog/#ci_4","title":"Ci","text":"<ul> <li> <p>ci(pyproject.yaml): fix semantic release (<code>daaea19</code>)</p> </li> <li> <p>ci(ci.yaml): fix syntax (<code>c2647c6</code>)</p> </li> <li> <p>ci(ci.yaml): fix dependencies (<code>7d4eb5f</code>)</p> </li> <li> <p>ci(ci.yaml): fix mkdocs deployment dependencies (<code>a70a216</code>)</p> </li> <li> <p>ci(quality-check): upgrade poetry version (<code>aedd680</code>)</p> </li> </ul>"},{"location":"changelog/#documentation_6","title":"Documentation","text":"<ul> <li> <p>docs(README-and-Cookbook): clean up (<code>183b317</code>)</p> </li> <li> <p>docs(eyepy): add docstrings and cookbook examples (<code>3b6ce5d</code>)</p> </li> <li> <p>docs(formats): e2e documentation (<code>059d67b</code>)</p> </li> </ul>"},{"location":"changelog/#feature_4","title":"Feature","text":"<ul> <li>feat(HeE2eReader): read E2E volumes (<code>9094890</code>)</li> </ul>"},{"location":"changelog/#fix_11","title":"Fix","text":"<ul> <li> <p>fix(eyepy): do not use list and tuple for type annotations python 3.8 only supports List / Tuple (<code>cc6dfee</code>)</p> </li> <li> <p>fix(region-plotting): remove EllipsisType from allowed types for the region parameter since its not supported in python 3.8 (<code>fac7849</code>)</p> </li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>refactor(eyepy): Use isort with google style for imports and yapf for code formating (<code>47f9330</code>)</li> </ul>"},{"location":"changelog/#test_1","title":"Test","text":"<ul> <li> <p>test(eyevolume): skip save load test for now (<code>bd58274</code>)</p> </li> <li> <p>test(test_eyevolume): change delete to remove in function names (<code>4804dc9</code>)</p> </li> <li> <p>test(eyevolume): skip Vol writing for now (<code>cbdc97e</code>)</p> </li> </ul>"},{"location":"changelog/#v068-2022-09-15","title":"v0.6.8 (2022-09-15)","text":""},{"location":"changelog/#fix_12","title":"Fix","text":"<ul> <li>fix(eyepy): update pre-commit; remove itk from dependencies</li> </ul> <p>itk was used to read the RETOUCH dataset and might be added as an extra dependency (<code>0339fb6</code>)</p>"},{"location":"changelog/#refactor_2","title":"Refactor","text":"<ul> <li>refactor(EyeVolumeVoxelAnnotation): simplify code for plotting (<code>355e7f6</code>)</li> </ul>"},{"location":"changelog/#v067-2022-06-03","title":"v0.6.7 (2022-06-03)","text":""},{"location":"changelog/#fix_13","title":"Fix","text":"<ul> <li>fix(eyevolume.py): remove reformating of knot data in load - eyelab now does it if needed (<code>35060ab</code>)</li> </ul>"},{"location":"changelog/#v066-2022-06-03","title":"v0.6.6 (2022-06-03)","text":""},{"location":"changelog/#fix_14","title":"Fix","text":"<ul> <li>fix(eyevolume): auto convert old layer curves (<code>7842120</code>)</li> </ul>"},{"location":"changelog/#v065-2022-04-21","title":"v0.6.5 (2022-04-21)","text":""},{"location":"changelog/#fix_15","title":"Fix","text":"<ul> <li>fix(io/utils.py): check for parallel and equal distance B-scans (<code>c5d68d2</code>)</li> </ul>"},{"location":"changelog/#v064-2022-04-21","title":"v0.6.4 (2022-04-21)","text":""},{"location":"changelog/#fix_16","title":"Fix","text":"<ul> <li> <p>fix(lazy.py): fix shape of lazy volume (<code>34b944f</code>)</p> </li> <li> <p>fix(eyevolume.py): enable import of B-scans with varying distances by replacing the raised Error by a warning; support deleteion of annotations (<code>d8b4bb8</code>)</p> </li> </ul>"},{"location":"changelog/#test_2","title":"Test","text":"<ul> <li>test(test_grid.py): add tests for ETDRS grid creation (<code>c9c13d1</code>)</li> </ul>"},{"location":"changelog/#v063-2022-03-31","title":"v0.6.3 (2022-03-31)","text":""},{"location":"changelog/#fix_17","title":"Fix","text":"<ul> <li>fix(eyevolume.py): set default intensity transform if none is given (<code>16b44bc</code>)</li> </ul>"},{"location":"changelog/#unknown","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>e57a91e</code>)</li> </ul>"},{"location":"changelog/#v062-2022-03-31","title":"v0.6.2 (2022-03-31)","text":""},{"location":"changelog/#fix_18","title":"Fix","text":"<ul> <li>fix(eyevolume.py): add intensity_transform to the saved meta data</li> </ul> <p>this is required to correctly restore saved data with non-default intensity_transform. Custom intensity transform functions can not be saved currently. (<code>c6a2c68</code>)</p> <ul> <li>fix(import_retouch): transform intensities correctly</li> </ul> <p>Topcon and Cirrus data is stored as UCHAR while spectralis is stored as USHORT (<code>112d1cc</code>)</p>"},{"location":"changelog/#v061-2022-03-26","title":"v0.6.1 (2022-03-26)","text":""},{"location":"changelog/#documentation_7","title":"Documentation","text":"<ul> <li>docs(README.md): add DOI badge (<code>c4d046b</code>)</li> </ul>"},{"location":"changelog/#fix_19","title":"Fix","text":"<ul> <li>fix(pyproject.toml): set minimum python version to 3.7 for compatibility with pyinstaller docker container (<code>75c008c</code>)</li> </ul>"},{"location":"changelog/#v060-2022-03-25","title":"v0.6.0 (2022-03-25)","text":""},{"location":"changelog/#documentation_8","title":"Documentation","text":"<ul> <li>docs(README.md): add Related Projects section with reference to OCT-Converter (<code>c273e44</code>)</li> </ul>"},{"location":"changelog/#feature_5","title":"Feature","text":"<ul> <li> <p>feat(eyevolume): enable use of EyeVolume in eyelab (<code>8479628</code>)</p> </li> <li> <p>feat(eyevolume.py): enable custom intensity transformation for OCT data (<code>761dd5a</code>)</p> </li> </ul>"},{"location":"changelog/#v041-2022-02-17","title":"v0.4.1 (2022-02-17)","text":""},{"location":"changelog/#fix_20","title":"Fix","text":"<ul> <li>fix(EyeVolume): fix B-scan iteration; enable setting layer heights from EyeBscan (<code>f982d68</code>)</li> </ul>"},{"location":"changelog/#unknown_1","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>a63cdd8</code>)</li> </ul>"},{"location":"changelog/#v040-2022-02-17","title":"v0.4.0 (2022-02-17)","text":""},{"location":"changelog/#breaking_3","title":"Breaking","text":"<ul> <li>refactor(everything): Refactor for easier to maintain code</li> </ul> <p>CI based on Github workflows, EyeVolume class as a standard way for handling OCT volumes, support for HEXEX VOL/XML, Bscans from folder, DUKE and RETOUCH data</p> <p>BREAKING CHANGE: (<code>117ef89</code>)</p>"},{"location":"changelog/#v037-2022-01-31","title":"v0.3.7 (2022-01-31)","text":""},{"location":"changelog/#fix_21","title":"Fix","text":"<ul> <li>fix(base): fix error when plotting volumes without drusen; fix visibility of drusen projection (<code>9c08c72</code>)</li> </ul>"},{"location":"changelog/#unknown_2","title":"Unknown","text":"<ul> <li> <p>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>ed503da</code>)</p> </li> <li> <p>minor change (<code>eb337bd</code>)</p> </li> </ul>"},{"location":"changelog/#v036-2021-10-14","title":"v0.3.6 (2021-10-14)","text":""},{"location":"changelog/#fix_22","title":"Fix","text":"<ul> <li>fix(drusen.py): fix the drusen height filtering (<code>4d1b375</code>)</li> </ul>"},{"location":"changelog/#v035-2021-08-16","title":"v0.3.5 (2021-08-16)","text":""},{"location":"changelog/#fix_23","title":"Fix","text":"<ul> <li>fix(DefaultEyeQuantifier): enable radii change for default quantifier (<code>ca8aff3</code>)</li> </ul>"},{"location":"changelog/#unknown_3","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>de0aba3</code>)</li> </ul>"},{"location":"changelog/#v034-2021-08-16","title":"v0.3.4 (2021-08-16)","text":""},{"location":"changelog/#fix_24","title":"Fix","text":"<ul> <li>fix: fix the reference (<code>eadf100</code>)</li> </ul>"},{"location":"changelog/#v033-2021-08-16","title":"v0.3.3 (2021-08-16)","text":""},{"location":"changelog/#fix_25","title":"Fix","text":"<ul> <li>fix(io/heyex/xml_export): initalize empty LayerAnnotation if no annotation is provided (<code>6626467</code>)</li> </ul>"},{"location":"changelog/#unknown_4","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>d4dc744</code>)</li> </ul>"},{"location":"changelog/#v032-2021-08-16","title":"v0.3.2 (2021-08-16)","text":""},{"location":"changelog/#fix_26","title":"Fix","text":"<ul> <li>fix(eyepy/io/heyex): allow unknown heyex xml versions</li> </ul> <p>show a warning and use the base XML specification for HEYEX XML exports (<code>5c51b46</code>)</p>"},{"location":"changelog/#unknown_5","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>54e0a6c</code>)</li> </ul>"},{"location":"changelog/#v031-2021-05-18","title":"v0.3.1 (2021-05-18)","text":""},{"location":"changelog/#fix_27","title":"Fix","text":"<ul> <li>fix(base.py): fix layer mapping in case LayerAnnotation does not contain all layers (<code>5e8621e</code>)</li> </ul>"},{"location":"changelog/#unknown_6","title":"Unknown","text":"<ul> <li>Merge remote-tracking branch 'origin/master'</li> </ul>"},{"location":"changelog/#conflicts","title":"Conflicts:","text":""},{"location":"changelog/#eyepycoredrusenpy-569a9ed","title":"eyepy/core/drusen.py (<code>569a9ed</code>)","text":""},{"location":"changelog/#v030-2021-03-19","title":"v0.3.0 (2021-03-19)","text":""},{"location":"changelog/#feature_6","title":"Feature","text":"<ul> <li>feat(drusen.py): added new histogram based DrusenFinder and made it the new default</li> </ul> <p>The old default is renamed to DrusenFinderPolyFit. The new method estimates a single iRPE distance to the BM for the complete volume. We found that the iRPE found like this has a similar distance to the BM as the RPE in healthy regions hasto the BM. The iRPE computed by the old method has a larger difference to the BM. (<code>9a3e667</code>)</p>"},{"location":"changelog/#v026-2021-03-12","title":"v0.2.6 (2021-03-12)","text":""},{"location":"changelog/#fix_28","title":"Fix","text":"<ul> <li>fix(base.py): fixed bugs for oat (<code>7e10ab3</code>)</li> </ul>"},{"location":"changelog/#unknown_7","title":"Unknown","text":"<ul> <li> <p>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>64e6f46</code>)</p> </li> <li> <p>Layer annotation works with DB sync (<code>e676eec</code>)</p> </li> <li> <p>Upload and show line annotations (<code>7386893</code>)</p> </li> <li> <p>Lines and Areas Groups; Import of vol, xml and bscan folder; bug fixes; annotation view active image indicator; (<code>d858a6f</code>)</p> </li> </ul>"},{"location":"changelog/#v025-2021-02-11","title":"v0.2.5 (2021-02-11)","text":""},{"location":"changelog/#fix_29","title":"Fix","text":"<ul> <li>fix(docs): add requirements.txt for docs</li> </ul> <p>readthedocs nee to know the dependencies for building the documentation (<code>8008c63</code>)</p>"},{"location":"changelog/#v024-2021-02-11","title":"v0.2.4 (2021-02-11)","text":""},{"location":"changelog/#fix_30","title":"Fix","text":"<ul> <li> <p>fix(travis.yml): removed --user option (<code>f68df9e</code>)</p> </li> <li> <p>fix(travis.yml): switch to new pip version to properly resolve twine dependencies (<code>7215226</code>)</p> </li> </ul>"},{"location":"changelog/#unknown_8","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>d14ef68</code>)</li> </ul>"},{"location":"changelog/#v023-2021-02-11","title":"v0.2.3 (2021-02-11)","text":""},{"location":"changelog/#fix_31","title":"Fix","text":"<ul> <li>fix(docs): remove eyepy as requirement for building docs (<code>05d6293</code>)</li> </ul>"},{"location":"changelog/#v022-2021-02-11","title":"v0.2.2 (2021-02-11)","text":""},{"location":"changelog/#fix_32","title":"Fix","text":"<ul> <li>fix(setup.py-eyepy/init.py): make sure the version numbers match (<code>7357f11</code>)</li> </ul>"},{"location":"changelog/#style_2","title":"Style","text":"<ul> <li>style(project): run pre-commit hooks and cleaned documentation (<code>a882ad4</code>)</li> </ul>"},{"location":"changelog/#unknown_9","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>edd53a0</code>)</li> </ul>"},{"location":"changelog/#v021-2021-02-11","title":"v0.2.1 (2021-02-11)","text":""},{"location":"changelog/#fix_33","title":"Fix","text":"<ul> <li>fix(core.drusen.py): use logging module instead of prints in this package (<code>978fa11</code>)</li> </ul>"},{"location":"changelog/#v020-2021-02-11","title":"v0.2.0 (2021-02-11)","text":""},{"location":"changelog/#breaking_4","title":"Breaking","text":"<ul> <li>fix: changed enface to localizer in OCT object</li> </ul> <p>BREAKING CHANGE: (<code>bf6ecd2</code>)</p> <ul> <li>refactor(eyepy/core/base.py): rename enface to localizer in Oct object for more consistency</li> </ul> <p>BREAKING CHANGE: (<code>09f8746</code>)</p>"},{"location":"changelog/#unknown_10","title":"Unknown","text":"<ul> <li>Merge branch 'master' of github.com:MedVisBonn/eyepy (<code>710d6d8</code>)</li> </ul>"},{"location":"changelog/#v016-2021-02-10","title":"v0.1.6 (2021-02-10)","text":""},{"location":"changelog/#ci_5","title":"Ci","text":"<ul> <li> <p>ci(Travis-CI): changed supported versions and location of version string (<code>397deca</code>)</p> </li> <li> <p>ci: add changed files before commiting (<code>8e1cb24</code>)</p> </li> </ul>"},{"location":"changelog/#documentation_9","title":"Documentation","text":"<ul> <li>docs(readme): added eyepy logo to readme.rst and removed readme.md (<code>bc3e19d</code>)</li> </ul>"},{"location":"changelog/#fix_34","title":"Fix","text":"<ul> <li> <p>fix(.travis.yml): another fix (<code>79e3332</code>)</p> </li> <li> <p>fix(.travis.yml): fixed yaml problem (<code>28eac5e</code>)</p> </li> <li> <p>fix(ci-testing): test whether a fix triggers the travic ci build</p> </li> </ul> <p>no significant changes (<code>718e9ee</code>)</p>"},{"location":"changelog/#refactor_3","title":"Refactor","text":"<ul> <li> <p>refactor(registration): Added rigid registration of multimodal images based on mean phase images and HOG features. Also added an examplary notebook (<code>7ce9ebd</code>)</p> </li> <li> <p>refactor(project): added 2D rigid registration (<code>67f5908</code>)</p> </li> </ul>"},{"location":"changelog/#style_3","title":"Style","text":"<ul> <li>style: removed index.html files (<code>81bf883</code>)</li> </ul>"},{"location":"changelog/#unknown_11","title":"Unknown","text":"<ul> <li> <p>Another try (<code>a450ec6</code>)</p> </li> <li> <p>Changed project name from eyepy to eyepie for PyPi (<code>64313c4</code>)</p> </li> <li> <p>Setting up pypi upload (<code>88a6a33</code>)</p> </li> <li> <p>work in progress (<code>b6833a1</code>)</p> </li> <li> <p>Added annotation comparison (<code>1bb8f33</code>)</p> </li> <li> <p>small changes (<code>ae3b464</code>)</p> </li> <li> <p>unknown (<code>b518e0c</code>)</p> </li> <li> <p>Fixed drusen filters (<code>c265d6c</code>)</p> </li> <li> <p>Severall small fixes and improvements (<code>161ecb4</code>)</p> </li> <li> <p>many small improvements; drusen computation now in 4s instead of 90s (<code>cbae8db</code>)</p> </li> <li> <p>layer ploting with region works (<code>fb67ede</code>)</p> </li> <li> <p>minor change (<code>a1fa0bb</code>)</p> </li> <li> <p>default Annotation for B-Scan (<code>758d23f</code>)</p> </li> <li> <p>some changes (<code>8935ab4</code>)</p> </li> <li> <p>Default empty LayerAnnotation works (<code>72a6a43</code>)</p> </li> <li> <p>fix the layer annotation fix :/ (<code>fa5ee81</code>)</p> </li> <li> <p>Added default empty layer annotation and fixed Oct.layer (<code>5c8a395</code>)</p> </li> <li> <p>Assume square area for OCT if no enface and or no layer positions are given; Enabled changing the layer annotations (<code>5e244f0</code>)</p> </li> <li> <p>Added name to Bscan. If B-Scans are save as individual files, this is the respective filename, else it becomes a string version of the B-Scan index (<code>0b09ebe</code>)</p> </li> <li> <p>Merge remote-tracking branch 'public/master' (<code>dd352c6</code>)</p> </li> <li> <p>added layer_indices property to Bscan (<code>bd4f669</code>)</p> </li> <li> <p>Merge remote-tracking branch 'public/master' (<code>64db876</code>)</p> </li> <li> <p>Imports fixed (<code>cb2759a</code>)</p> </li> <li> <p>Merge remote-tracking branch 'public/master'</p> </li> </ul>"},{"location":"changelog/#conflicts_1","title":"Conflicts:","text":""},{"location":"changelog/#eyepycorebasepy-1b4de44","title":"eyepy/core/base.py (<code>1b4de44</code>)","text":"<ul> <li> <p>Rewrite Heyex vol and xml readers. Clean up (<code>f97da6e</code>)</p> </li> <li> <p>Merge remote-tracking branch 'public/master'</p> </li> </ul>"},{"location":"changelog/#conflicts_2","title":"Conflicts:","text":""},{"location":"changelog/#eyepycoreoctbasepy","title":"eyepy/core/octbase.py","text":""},{"location":"changelog/#eyepyioheyexhe_xmlpy-965bc45","title":"eyepy/io/heyex/he_xml.py (<code>965bc45</code>)","text":"<ul> <li> <p>minor fix (<code>b1b97f3</code>)</p> </li> <li> <p>minor fix (<code>266f837</code>)</p> </li> <li> <p>added drusen depth filter (<code>8acd827</code>)</p> </li> <li> <p>bumbed version (<code>5a1000a</code>)</p> </li> <li> <p>Added drusen saving in data_path/.eyepy folder. Added function to recompute drusen if needed with a custom drusenfinder (<code>40ed65d</code>)</p> </li> <li> <p>Merge remote-tracking branch 'origin/master' into dev</p> </li> </ul>"},{"location":"changelog/#conflicts_3","title":"Conflicts:","text":""},{"location":"changelog/#eyepycoredrusenpy-69a6f71","title":"eyepy/core/drusen.py (<code>69a6f71</code>)","text":"<ul> <li> <p>Drusen depth filter added (<code>d33f0d6</code>)</p> </li> <li> <p>layer_indices and enface filename (<code>2ee6f41</code>)</p> </li> <li> <p>Work in progress, adding reading functionallity for bscan only folders (<code>8d859c0</code>)</p> </li> <li> <p>Changed Repository (<code>5e0aa32</code>)</p> </li> <li> <p>Merge branch 'dev'</p> </li> </ul>"},{"location":"changelog/#conflicts_4","title":"Conflicts:","text":""},{"location":"changelog/#eyepypreprocessloggaborpy-1368604","title":"eyepy/preprocess/loggabor.py (<code>1368604</code>)","text":"<ul> <li> <p>Added DefaultEyeQuantifier and improved plotting (<code>a00b25a</code>)</p> </li> <li> <p>Minor fixes and clean up (<code>2ce4962</code>)</p> </li> <li> <p>Removed code duplication (<code>c02d2dd</code>)</p> </li> <li> <p>Added EyeQuantifier and DefaultEyeQuantifier for standard drusen quantification (<code>6b33b6f</code>)</p> </li> <li> <p>Added loader for sample data (<code>451586d</code>)</p> </li> <li> <p>Added DrusenFinder to octbase (<code>46ec78c</code>)</p> </li> <li> <p>Work in progress on the DrusenFinder (<code>bb69833</code>)</p> </li> <li> <p>When loading B-Scans assume image has 2 dimensions. In case it as 3 dimensions (last dimension for RGB) keep only the R array (<code>0290a7b</code>)</p> </li> <li> <p>minor fix (<code>04f8d6b</code>)</p> </li> <li> <p>Merge branch 'master' into merge_to_public</p> </li> </ul>"},{"location":"changelog/#conflicts_5","title":"Conflicts:","text":""},{"location":"changelog/#setuppy-b300bd6","title":"setup.py (<code>b300bd6</code>)","text":"<ul> <li> <p>added drusen metrics and fixed drusen computation (<code>1e38f65</code>)</p> </li> <li> <p>Drusen code is clean, tests missing (<code>c28de74</code>)</p> </li> <li> <p>Started to add drusen computation from layer segmentation. (<code>5e8d511</code>)</p> </li> <li> <p>Store only one channel of the loaded bscan (<code>b7d0827</code>)</p> </li> <li> <p>Added seaborn dependcy (<code>9e41356</code>)</p> </li> <li> <p>relaxed dependencies for now (<code>c2a3ed8</code>)</p> </li> <li> <p>initial commit (<code>c0cb0ca</code>)</p> </li> <li> <p>minor plotting changes (<code>ceb5fed</code>)</p> </li> <li> <p>fixed specification for vol files (<code>0afb7ee</code>)</p> </li> <li> <p>bug fixes and reorganization (<code>2a1dde1</code>)</p> </li> <li> <p>latest changes (<code>39ccccd</code>)</p> </li> <li> <p>old changes (<code>2ca90dc</code>)</p> </li> <li> <p>Added base classes for Oct and Bscan objects which define the interface and deliver basic plotting functionality (<code>a5f82df</code>)</p> </li> <li> <p>Fixed parsing B-Scans for the Heyex XML export (<code>70b101c</code>)</p> </li> <li> <p>read Heyex XML exports with the same class as the Heyex VOL export. This makes both exports accessible using the same interface (<code>b05b3a0</code>)</p> </li> <li> <p>memory mapped file for reading .vol (<code>37b31d5</code>)</p> </li> <li> <p>fixed comma (<code>efb4dc7</code>)</p> </li> <li> <p>Added support for reading segmentations from .vol (<code>5cebe5e</code>)</p> </li> <li> <p>Merge remote-tracking branch 'origin/master'</p> </li> </ul>"},{"location":"changelog/#conflicts_6","title":"Conflicts:","text":""},{"location":"changelog/#docsconfpy","title":"docs/conf.py","text":""},{"location":"changelog/#eyepyioinitpy","title":"eyepy/io/init.py","text":""},{"location":"changelog/#eyepyiobasepy","title":"eyepy/io/base.py","text":""},{"location":"changelog/#eyepyiohe_volpy-95eb730","title":"eyepy/io/he_vol.py (<code>95eb730</code>)","text":"<ul> <li> <p>HeyexOct docstring (<code>f539013</code>)</p> </li> <li> <p>Added sphinx extensions for numpy style docstrings (napoleon) and typehints (sphinx_autodoc_typehints) (<code>8faa2d7</code>)</p> </li> <li> <p>Documentation and clean up in progress (<code>8770649</code>)</p> </li> <li> <p>Rewrite vol import (<code>d9b138e</code>)</p> </li> <li> <p>changes to the filtergrid to use it more flexible (<code>5c3c0a7</code>)</p> </li> <li> <p>Another commit (<code>64e1d1b</code>)</p> </li> <li> <p>new approach (<code>9d883af</code>)</p> </li> <li> <p>registartion progress (<code>5705254</code>)</p> </li> <li> <p>log gabor completeted (<code>7f42ea6</code>)</p> </li> <li> <p>... (<code>f5b451a</code>)</p> </li> <li> <p>progress on registration (<code>8fb4755</code>)</p> </li> <li> <p>progress on log gabor (<code>51e5205</code>)</p> </li> <li> <p>work in progress register nir/cfp (<code>b09762d</code>)</p> </li> <li> <p>Project init (<code>ad34732</code>)</p> </li> <li> <p>Initial commit (<code>d1b9af2</code>)</p> </li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>If you want to contribute to eyepy, this is a guide on how to do it. We are happy to accept contributions from everyone. If you have any questions, please open an issue or contact us via email.</p>"},{"location":"contributing/#project-setup","title":"Project setup","text":"<p>This section describes the setup of the eyepy project, mainly for internal documentation purposes, but feel free to use it as a guide for your own projects.</p>"},{"location":"contributing/#dependency-management-and-packaging","title":"Dependency management and packaging","text":"<p>We use <code>uv</code> for dependency management and task running. Install <code>uv</code> in your environment (python -m pip install uv) and use the commands below.</p> <p>Install all dependencies (including development dependencies):</p> <pre><code>uv sync --all-groups\n</code></pre> <p>You can also install with pip/hatch if you prefer:</p> <pre><code>python -m pip install -e .[dev]\n</code></pre> <p>To run the tests in the project's virtual environment:</p> <pre><code>uv run pytest\n</code></pre> <p>Package builds and releases are handled by CI using hatchling and python-semantic-release.</p>"},{"location":"contributing/#code-formatting-and-linting","title":"Code formatting and linting","text":"<p>Do not spend your time on code formatting. We use yapf and isort to format the code automatically. You can run them via pre-commit hooks. See the section on pre-commit hooks for more information.</p> <ul> <li>Automatic code formatting with pre-commit (check-yaml, end-of-file-fixer, trailing-whitespace, isort, yapf[google], commitizen)</li> <li>Quality checks: run pre-commit hooks and pytest via GitHub Actions for every pull request and push to master</li> <li>Deployment for every push to master: semantic release for GitHub releases and PyPI deployment via GitHub Actions</li> <li>Build documentation with MkDocs and deploy it to [GitHub Pages] via GitHub Actions</li> </ul>"},{"location":"contributing/#semantic-commit-messages","title":"Semantic commit messages","text":"<ul> <li>Only allow commits with semantic commit messages via Commitizen</li> <li>Automatic version number increase based on semantic commit messages via Commitizen</li> </ul>"},{"location":"contributing/#setting-up-your-development-environment","title":"Setting up your development environment","text":""},{"location":"contributing/#forking-the-repository","title":"Forking the repository","text":"<p>First, fork the repository on GitHub to your own account. Then, clone your fork to your local machine:</p> <pre><code>git clone https://github.com/[YOUR_USERNAME]/eyepy.git\ncd eyepy\ngit checkout -b my-feature\n</code></pre>"},{"location":"contributing/#setting-up-the-development-environment","title":"Setting up the development environment","text":"<p>Install dependencies (including dev dependencies):</p> <pre><code>uv sync --all-groups\n\n# or (if you prefer pip/hatch):\npython -m pip install -e .[dev]\n</code></pre> <p>This will create a virtual environment and install all required and development dependencies.</p>"},{"location":"contributing/#making-and-committing-changes","title":"Making and committing changes","text":""},{"location":"contributing/#run-the-tests","title":"Run the tests","text":"<p>Before committing, make sure all tests pass:</p> <pre><code>uv run pytest\n</code></pre>"},{"location":"contributing/#install-and-run-the-pre-commit-hooks","title":"Install and run the pre-commit hooks","text":"<p>Install the pre-commit hooks (only needed once):</p> <pre><code>uv run pre-commit install\n</code></pre> <p>Run all hooks manually before committing:</p> <pre><code>uv run pre-commit run --all-files\n</code></pre> <p>pre-commit might change your files to match the code style. You have to add them again before committing. After installation, hooks will also run automatically on every <code>git commit</code>. Since the commit with Commitizen fails if the pre-commit hooks fails, run the hooks before committing.</p>"},{"location":"contributing/#commitizen-for-semantic-commit-messages","title":"Commitizen for semantic commit messages","text":"<p>We use Commitizen for semantic commit messages. To create a commit message interactively:</p> <pre><code>uv run cz commit\n</code></pre>"},{"location":"contributing/#building-and-previewing-the-documentation","title":"Building and previewing the documentation","text":"<p>To build and serve the documentation locally with live reload:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>Then open http://127.0.0.1:8000/ in your browser.</p>"},{"location":"contributing/#pushing-and-creating-a-pull-request","title":"Pushing and creating a pull request","text":""},{"location":"contributing/#push-to-your-repository","title":"Push to your repository","text":"<p>After committing, push your changes to your fork:</p> <pre><code>git push origin my-feature\n</code></pre>"},{"location":"contributing/#create-a-pull-request","title":"Create a pull request","text":"<p>Go to the original repository on GitHub and open a pull request from your branch. Please describe your changes and reference any related issues.</p> <p>If you have any questions, please open an issue at https://github.com/MedVisBonn/eyepy/issues. Thank you for contributing!</p>"},{"location":"cookbook/","title":"Cookbook","text":"<p>Here you learn how to use eyepy to perform common tasks.</p>"},{"location":"cookbook/#import-oct-data","title":"Import OCT data","text":"<p>Currently <code>eyepy</code> supports the HEYEX E2E, VOL and XML formats, as well as reading data from several public OCT datasets. All functions return a single <code>EyeVolume</code> object representing the data. E2E files may contain several OCT volumes. The import function only returns the first OCT volume in the file. If you want to read several volumes from a file use the HeE2eReader class. While you can use Reader objects to parse the data and access specific information, it is recommended to use when possible, the provided import functions to get <code>EyeVolume</code> object which are a convenient interface to the data that provides a unified interface to data imported from various sources.</p> <pre><code>import eyepy as ep\n# Import HEYEX E2E export\nev = ep.import_heyex_e2e(\"path/to/file.e2e\")\n# Import HEYEX XML export\nev = ep.import_heyex_xml(\"path/to/folder\")\n# Import HEYEX VOL export\nev = ep.import_heyex_vol(\"path/to/file.vol\")\n# Import Topcon FDA export (requires: pip install eyepy[fda])\nev = ep.import_topcon_fda(\"path/to/file.fda\")\n# Import volume from Duke public dataset\nev = ep.import_duke_mat(\"path/to/file.mat\")\n# Import volume form RETOUCH challenge (requires: pip install eyepy[itk])\nev = ep.import_retouch(\"path/to/volume_folder\")\n</code></pre> <p>Missing scale information</p> <p>For the E2E file the scale of both localizer axes as well as the B-scan x-axes has not been identified yet and is hardcoded. When importing B-scans from folders there is also no scale information available.</p> <p>When only B-scans exist in a folder <code>eyepy</code> might still be able to import them. B-scans are expected to be ordered and distributed with equal distance on a quadratic area.</p> <pre><code>import eyepy as ep\n# Import B-scans from folder\nev = ep.import_bscan_folder(\"path/to/folder\")\n</code></pre> <p>Public OCT datasets often have their own data formats. <code>eyepy</code> can import volumes from the AMD Dataset from Duke University and the RETOUCH Challenge.</p> <pre><code>import eyepy as ep\n# Import DUKE volume\nev = ep.import_duke_mat(\"path/to/volume.mat\")\n# Import RETOUCH volume\nev = ep.import_retouch(\"path/to/folder\")\n</code></pre> <p>When you don't hava a supported OCT volume at hand you can check out our sample dataset to get familiar with <code>eyepy</code>. <pre><code>from eyepy.data import load\n# Import HEYEX XML export\nev = load(\"drusen_patient\")\n</code></pre></p>"},{"location":"cookbook/#plot-localizer","title":"Plot Localizer","text":"<p>Most OCT volumes come with a localizer image. This image can be plotted using the <code>plot</code> method of the <code>EyeVolume</code> object:</p> <pre><code>ev.plot()\n</code></pre> <p>There are several options to customize the plot:     + show B-scan positions or region (<code>bscan_positions</code> and <code>bscan_region</code> parameters)     + show enface projections or quantifications of OCT voxel annotaions such as drusen (<code>projections</code> and <code>quantifications</code> parameters)     + show only a specific region of the localizer image (<code>region</code> parameter)</p> <p>The plotting function is documented here: [EyeVolume.plot][eyepy.core.EyeVolume.plot]</p> <p><code>region</code> parameter</p> <p>The region parameter produces unexpected results in combination with <code>bscan_positions</code> and <code>bscan_region</code> parameters</p>"},{"location":"cookbook/#plot-bscans","title":"Plot Bscans","text":"<p>B-scans can be plotted using the <code>plot</code> method of the <code>EyeBscan</code> object. You get <code>EyeBscan</code> objects by indexing the <code>EyeVolume</code> object or iterating over it. The following code plots the first B-scan of the volume together with the layer annotations for BM and RPE:</p> <pre><code>ev[0].plot(layers=[\"BM\", \"RPE\"])\n</code></pre> <p>The plotting function is documented here: [EyeBscan.plot][eyepy.core.EyeBscan.plot]</p>"},{"location":"cookbook/#modify-annotations","title":"Modify Annotations","text":""},{"location":"cookbook/#compute-drusen-from-layer-annotations","title":"Compute Drusen from Layer Annotations","text":"<p>Here we compute drusen for our sample data which has manual layer annotations for BM and RPE.</p> <pre><code>import eyepy as ep\n\n# Import example data\nev = ep.data.load(\"drusen_patient\")\n# Compute drusen\ndrusen_map = ep.drusen(ev.layers[\"RPE\"].data, ev.layers[\"BM\"].data, ev.shape, minimum_height=2)\n</code></pre>"},{"location":"cookbook/#add-remove-layer-annotations","title":"Add / Remove Layer Annotations","text":"<p>Often OCT volumes come with layer annotations. They are added to the <code>EyeVolume</code> object during the import, but you can also manipulate them yourself using the <code>add_layer_annotation</code> and <code>remove_layer_annotation</code> methods. The following code can be used to layer annotations to <code>EyeVolume</code> objects. The <code>name</code> parameter is used to identify the layer.</p> <pre><code>layer_heights = np.zeros(np.array(ev.shape)[[0,2]])\nev.add_layer_annotation(layer_heights, name=\"new_layer\")\n</code></pre> <p>To remove a layer annotation use the <code>remove_layer_annotation</code> method. The following code removes the layer annotation we added above.</p> <pre><code>ev.remove_layer_annotation(\"new_layer\")\n</code></pre>"},{"location":"cookbook/#add-remove-voxel-annotaitons","title":"Add / Remove Voxel Annotaitons","text":"<p>If you want to add voxel annotations to the EyeVolume object you can use the <code>add_pixel_annotation</code> method. The following code adds the drusen map we computed above to the EyeVolume object. The <code>name</code> parameter is used to identify the annotation.</p> <pre><code>ev.add_pixel_annotation(drusen_map, name=\"drusen\")\n</code></pre> <p>To remove an annotation use the <code>remove_pixel_annotation</code> method. The following code removes the drusen annotation we added above.</p> <pre><code>ev.remove_pixel_annotation(\"drusen\")\n</code></pre>"},{"location":"cookbook/#etdrs-and-custom-quantification-grids","title":"ETDRS and Custom Quantification Grids","text":"<p>Quantifications on circular grids such as the ETDRS grid are common to quantify imaging data of the eye. With <code>eyepy</code> you can easily compute quantifications on such grids. The following code computes a quantification grid for the drusen annotation we added above.</p> <pre><code>fig, axes = plt.subplots(1, 2, figsize=(5, 10))\n\n# Configure quantification grid for drusen quantification\nev.volume_maps[\"drusen\"].radii = [1.5, 2.5]\nev.volume_maps[\"drusen\"].n_sectors = [4, 8]\nev.volume_maps[\"drusen\"].offsets = [0, 45]\n\n# Plot drusen projection and quantification\nev.plot(ax=axes[0], projections=[\"drusen\"])\nev.plot(ax=axes[1], quantification=\"drusen\")\naxes[0].axis(\"off\")\naxes[1].axis(\"off\")\n</code></pre> <p>The result looks like this: On the left, the scale is the drusen height in voxel and on the right, the drusen volume in mm\u00b3</p> <p></p> <p>To access the quantification as a dictionary use <code>ev.volume_maps[\"drusen\"].quantification</code></p>"},{"location":"cookbook/#interact-with-individual-b-scans","title":"Interact with individual B-scans","text":"<p>If you index into an EyeVolume object you get EyeBscan objects. Annotations you added to the respective <code>EyeVolume</code> object are also available in the <code>EyeBscan</code> object and can be visualized easily. The following code plots the 40th B-scan of the volume together with the layer annotations for BM and RPE and the computed drusen annotation:</p> <pre><code>import numpy as np\n\nfig, ax = plt.subplots(1,1, figsize=(9,3))\nbscan = ev[40]\nbscan.plot(layers=[\"BM\", \"RPE\"], areas=[\"drusen\"], region=np.s_[150:300, :], ax=ax)\nax.axis(\"off\")\n</code></pre> <p></p>"},{"location":"formats/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Heidelberg E2E<ul> <li>E2E File Structures<ul> <li>he_e2e_structures/*md</li> </ul> </li> <li>E2E Types</li> <li>E2E Hierarchy</li> </ul> </li> <li>Heidelberg VOL</li> <li>Heidelberg XML</li> </ul>"},{"location":"formats/he_e2e/","title":"Heidelberg Engineering E2E Format","text":"<p>Missing documentation of the Heidelberg E2E format has caused frustration by many working with OCT data and several projects tried to make the data accessible. Here you learn how to conveniently access data from E2E files using our <code>HeE2eReader</code> and what we know about the format.</p>"},{"location":"formats/he_e2e/#get-to-know-your-data","title":"Get to know your data","text":"<p>One thing that makes it especially difficult to read data from E2E files is that E2E is a general container format that can contain 0 or more instances of different kinds of data. If you are interested how the data is stored you might want to continue here.</p> <p>For most users it is probably enough to print the <code>HeE2eReader</code> object to get an overview of Patients, Studies and Series stored in the file.</p> Print E2E file overview<pre><code>from eyepy.io import HeE2eReader\nprint(HeE2eReader(\"filename.E2E\")) # (1)\n</code></pre> <ol> <li> <p>Printing an HeE2eReader results in someting similar to this:</p> <pre><code>E2EFile\n\n\n    E2EPatient(321)\n\n\n    E2EStudy(1234)\n    Device: Heidelberg Retina Angiograph - Studyname: NAME\n\n        E2ESeries(50001) - Laterality: OD - B-scans: 241\n        Structure: Retina - Scanpattern: OCT ART Volume - Oct Modality: OCT - Enface Modality: IR\n\n        E2ESeries(50002) - Laterality: OD - B-scans: 25\n        Structure: Retina - Scanpattern: OCT ART Volume - Oct Modality: OCT - Enface Modality: IR\n</code></pre> </li> </ol>"},{"location":"formats/he_e2e/#access-data-that-can-be-parsed-to-eyevolume-objects","title":"Access data that can be parsed to <code>EyeVolume</code> objects","text":"<p>The <code>HeE2eReader</code> provides a convenient interface to access data stored in E2E files. Assuming that your E2E file contains one or more OCT volumes you can parse the volumes to <code>EyeVolume</code> objects using the following code:</p> <pre><code>from eyepy.io import HeE2eReader\n\nwith HeE2eReader(\"filename.E2E\") as e2e_reader: # (1)\n    volumes = e2e_reader.volume\n\nwith HeE2eReader(\"filename.E2E\", single=True) as e2e_reader: # (2)\n    volume = e2e_reader.volume\n</code></pre> <ol> <li><code>e2e_reader.volume</code> returns <code>List[EyeVolume]</code></li> <li><code>e2e_reader.volume</code> returns the first Series as <code>EyeVolume</code> object</li> </ol> <p>Warning</p> <ul> <li>Currently we can not read scale Information for the localizer images as well as the x-scale of the B-scans. Hence quantifications can not be transformed to metric units.</li> <li>Also we know that in the E2E file B-scans are not registered with each other. This B-scan registration information has also not been found yet. This might cause problems when downstream analysis expects B-scans to be registered.</li> </ul> <p>If you know how to read this information from the E2E file, please let us know by opening an issue</p>"},{"location":"formats/he_e2e/#access-other-data-stored-in-e2e-files","title":"Access other data stored in E2E files","text":"<p>Not everything stored in an E2E file is accessible through parsing to <code>EyeVolume</code> objects. If you are interested in accessing other data stored in the E2E file, you can use the file hierarchy created by the <code>HeE2eReader</code>. The structure of the build hieararchy is shown in the diagram below. The file hierarchy can be accessed through the <code>file_hierarchy</code> attribute of the <code>HeE2eReader</code> object. You can either traverse the hierarchy level by level or access all elements of a specific level at once using one of the following attributes:</p> <ul> <li><code>e2e_reader.patients</code> returns a list of all <code>E2EPatientStructure</code> objects</li> <li><code>e2e_reader.studies</code> returns a list of all <code>E2EStudyStructure</code> objects</li> <li><code>e2e_reader.series</code> returns a list of all <code>E2ESeriesStructure</code> objects</li> </ul> <p>First you might want to get an overview about the data stored in the hierarchy. Therefore you can use the following code:</p> <pre><code>from eyepy.io import HeE2eReader\n\nwith HeE2eReader(\"filename.E2E\") as e2e_reader:\n    print(e2e_reader.inspect(recursive=True)) # (1)\n</code></pre> <ol> <li>This method is basically an extended version of <code>print(HeE2eReader(\"filename.E2E\"))</code> that adds for every level of the hierarchy a table with information about the containded data.</li> </ol>"},{"location":"formats/he_e2e/#e2e-hierarchie","title":"E2E Hierarchie","text":"<pre><code>classDiagram\n    E2EFileStructure *-- E2EPatientStructure\n    E2EPatientStructure *-- E2EStudyStructure\n    E2EStudyStructure *-- E2ESeriesStructure\n    E2ESeriesStructure *-- E2ESliceStructure\n\n    E2EStructureMixin &lt;|-- E2EFileStructure\n    E2EStructureMixin &lt;|-- E2EPatientStructure\n    E2EStructureMixin &lt;|-- E2EStudyStructure\n    E2EStructureMixin &lt;|-- E2ESeriesStructure\n    E2EStructureMixin &lt;|-- E2ESliceStructure\n\n    class E2EStructureMixin{\n      - inspect(recursive, ind_prefix, tables)\n      - get_folder_data(folder_type, offset, data_construct)\n    }\n\n    class E2EFileStructure{\n      - folders: Dict[Union[TypesEnum, int], E2EFolder]\n      - substructure/patients: Dict[int, E2EPatientStructure]\n    }\n    class E2EPatientStructure{\n      - id: int\n      - folders: Dict[Union[TypesEnum, int], E2EFolder]\n      - substructure/studies: Dict[int, E2EStudyStructure]\n    }\n    class E2EStudyStructure{\n      - id: int\n      - folders: Dict[Union[TypesEnum, int], E2EFolder]\n      - substructure/series: Dict[int, E2ESeriesStructure]\n    }\n    class E2ESeriesStructure{\n      - id: int\n      - folders: Dict[Union[TypesEnum, int], E2EFolder]\n      - substructure/slices: Dict[int, E2ESlice]\n      - get_volume() -&gt; EyeVolume\n      - get_layers() -&gt; Dict[int, np.ndarray]\n      - get_localizer() -&gt; EyeEnface\n      - get_localizer_meta() -&gt; EyeEnfaceMeta\n      - get_meta() -&gt; EyeVolumeMeta\n      - get_bscan_meta() -&gt; List[EyeBscanMeta]\n    }\n    class E2ESliceStructure{\n      - id: int\n      - folders: Dict[Union[TypesEnum, int], E2EFolder]\n      - get_layers() -&gt; Dict[int, np.ndarray]\n      - get_image() -&gt; -&gt; np.ndarray\n      - get_meta() -&gt; EyeBscanMeta\n    }</code></pre> <p>If you have any further information on the E2E format or if you find any errors in this document, please let us know by opening an issue.</p> <p>Open questions and differences to other Heidelberg Formats</p> <ul> <li>B-scan positions in the E2E format are given relative to an origin roughly in the center of the localizer image. We assume that the positions are given as angles in degree since the absolute value of minimum and maximum position is very close to half the field of view. This is different to VOL and XML formats where positions are given in mm with the origin in the top left corner of the localizer image. Since some position values indicate that they are located outside of the localizer image, we might have to apply the localizer transformation to them as well after mapping them to pixel indices.</li> <li>VOL and XML exports store the localizer scaling, as well as the scaling of the B-scans. The VOL format even stores the distance between the B-scans which has to be calculated from the B-scans in the XML and currently also the E2E format. We did not find this scaling information in the E2E format yet and use a hardcoded value for now. The only scaling we found was the Y Scale of the B-scan.</li> </ul>"},{"location":"formats/he_e2e/#aknowledgements","title":"Aknowledgements","text":"<p>While building the E2E file reader, and investigating the format we took inspiration from several existing projects, which we would like to thank:</p> <ul> <li>OCT-Converter</li> <li>LibE2E</li> <li>uocte</li> <li>RETIMAT</li> </ul>"},{"location":"formats/he_vol/","title":"Heidelberg Engineering VOL Format","text":"<p>While eyepy can read most information from the VOL format, a comprehensive documentation is still missing. If you are interested in contributing to eyepy, documenting a file format is a great way to get started. If you are interested, contac us via GitHub by opening an issue.</p>"},{"location":"formats/he_xml/","title":"Heidelberg Engineering XML Format","text":"<p>While eyepy can read most information from the XML format, a comprehensive documentation is still missing. If you are interested in contributing to eyepy, documenting a file format is a great way to get started. If you are interested, contac us via GitHub by opening an issue.</p>"},{"location":"formats/he_e2e_hierarchy/E2EFileStructure/","title":"E2EFileStructure","text":"Type ID Content Size Description 0 9011"},{"location":"formats/he_e2e_hierarchy/E2EPatientStructure/","title":"E2EPatientStructure","text":"Type ID Content Size Description 9  Patient data Personal data of the patient. 131 bytes 17  Diagnose data. variable 29 31 52 9010"},{"location":"formats/he_e2e_hierarchy/E2ESeriesStructure/","title":"E2ESeriesStructure","text":"Type ID Content Size Description 2 3  Type 3. 96 bytes 11  Type 11. 27 bytes 54 59  Type 59. 27 bytes 61 62 1000 1001 1003 1008 9005  Examined structure Name of the examined structure. 264 bytes 9006  Scan pattern Bscan pattern used for the aquisition. 520 bytes 9007  Enface Modality Modality of the enface (eg IR) 520 bytes 9008  OCT Modality Modality of the OCT (eg OCT) 520 bytes 10005 10009 10010  Type 10010. variable 10011 10013  Type 10013. variable 10025  Localizer Metadata. 100 bytes 1073741824  Image data Stores various kinds of images. variable 1073751824 1073751825 1073751826"},{"location":"formats/he_e2e_hierarchy/E2ESliceStructure/","title":"E2ESliceStructure","text":"Type ID Content Size Description 2 3  Type 3. 96 bytes 5  Type 5. 59 bytes 39 40 10004  B-scan Metadata Metadata for a single B-scan. 428 bytes 10012  Type 10012. variable 10013  Type 10013. variable 10019  Layer Annotation Stores one layer for one Bscan. variable 10020 10032 1073741824  Image data Stores various kinds of images. variable 1073751824 1073751825 1073751826"},{"location":"formats/he_e2e_hierarchy/E2EStudyStructure/","title":"E2EStudyStructure","text":"Type ID Content Size Description 7  Measurements Global measurements of the eye. 68 bytes 10 13 30 53 58 1000 9000  Studyname Name of the study/visit. 264 bytes 9001  Device Name of the used device. 776 bytes"},{"location":"formats/he_e2e_hierarchy/SUMMARY/","title":"SUMMARY","text":"<ul> <li>E2EFileStructure</li> <li>E2EPatientStructure</li> <li>E2EStudyStructure</li> <li>E2ESeriesStructure</li> <li>E2ESliceStructure</li> </ul>"},{"location":"formats/he_e2e_structures/Chunk/","title":"Chunk","text":"Offset Name Size Parses to Description 0 chunk_header 52 Header Each chunk refers to the start position of the previous chunk (<code>prev</code> field) 52 folders variable List[FolderHeader] In the data we have seen each chunk has 512 folders with headers of size 44 variable jump variable int"},{"location":"formats/he_e2e_structures/ContainerHeader/","title":"ContainerHeader","text":"Offset Name Size Parses to Description 0 magic3 12 str 12 unknown0 4 int 16 header_pos 4 int Position of the header 20 pos 4 int Position of the data 24 size 4 int Size of the container 28 unknown1 4 int Always 0 (b'\\x00\\x00\\x00\\x00')? At least in our data 32 patient_id 4 int Patient ID 36 study_id 4 int Study ID 40 series_id 4 int Series ID 44 slice_id 4 int Slice ID, has to be divided by 2 to get the correct slice number 48 ind 2 int Takes only values 65333, 0 and 1 (b'\u00ff\u00ff', b'\u0000\u0000', b'\u0001\u0000') at least in our data - 0 for enface and 1 for bscan for image containers 50 unknown2 2 int Always 0 (b'\u0000\u0000')? At least in our data 52 type 4 TypesEnum Type ID of the contained data 56 unknown3 4 int Large integer that increases in steps of folder header size (=44) Maybe the folder header position in HEYEX database not in this file? - Possibly related to the folder header unknown4 value"},{"location":"formats/he_e2e_structures/DataContainer/","title":"DataContainer","text":"Offset Name Size Parses to Description 0 header 60 ContainerHeader 60 item variable Any There are many kinds of DataItems indicated by different type IDs in the folder/container header"},{"location":"formats/he_e2e_structures/E2EFormat/","title":"E2EFormat","text":"Offset Name Size Parses to Description 0 version 36 Version 36 header 52 Header The <code>prev</code> field in the main header refers to the start position of the last chunk 88 chunks variable List[Chunk] The number and size of the chunks depends on the data"},{"location":"formats/he_e2e_structures/FolderHeader/","title":"FolderHeader","text":"Offset Name Size Parses to Description 0 pos 4 int Position of the folder (In a chunk all 512 folder headers are stored sequentially, refering to the data that follows after this header block) 4 start 4 int Start of the data container, after the header block in the chunk 8 size 4 int Size of the data container 12 unknown0 4 int Always 0 (b'\u0000\u0000')? At leat in our data 16 patient_id 4 int Patient ID 20 study_id 4 int Study ID 24 series_id 4 int Series ID 28 slice_id 4 int Slice ID, has to be divided by 2 to get the correct slice number 32 ind 2 int 0 for enface and 1 for bscan for image containers 34 unknown1 2 int 36 type 4 TypesEnum Type ID of the contained data 40 unknown3 4 int Large integer possibly related to data_container.unknown5. Maybe the position in HEYEX DB?"},{"location":"formats/he_e2e_structures/Header/","title":"Header","text":"Offset Name Size Parses to Description 0 magic2 12 str 12 version 4 int 16 unknown0 20 List[int] 36 num_entries 4 int Number of entries in the chunk 40 current 4 int Position of the current chunk 44 prev 4 int Position of the previous chunk 48 unknown1 4 int"},{"location":"formats/he_e2e_structures/Version/","title":"Version","text":"Offset Name Size Parses to Description 0 name 12 str Name of the version 12 version 4 int Verion of the file 16 unknown0 20 List[int]"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/","title":"E2E File Structures","text":"<p>In contrast to the VOL and XML exports the E2E data may contain several OCT volumes and other data. The format might even allow for data from multiple patients in a single E2E file. Everything is stored in a general container structure that is described in the File Structure section.</p>"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#file-structure","title":"File Structure","text":"<p>The first bytes in an E2E file contain a version structure followed by a header structure. The header gives you access to the rest of the file by identifying the position of the last chunk of data. Each chunk has exactly 512 elements which we call folders.</p> Offset Name Size Parses to Description 0 version 36 Version 36 header 52 Header The <code>prev</code> field in the main header refers to the start position of the last chunk 88 chunks variable List[Chunk] The number and size of the chunks depends on the data"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#chunk","title":"Chunk","text":"<p>Every chunk has a header similar to the file header. A chunk then holds the headers of all contained folders sequentially, followed by data containers, that are referenced by the folder headers. A chunk can contain folders with data of different patients, studies, series, slices and types. Each folder contains data for a single (patient, study, series, slice, type) combination which is given in the folder header as well as the data container header. For the last chunk to have 512 folders, empty folders of <code>type=0</code> are appended.</p> Offset Name Size Parses to Description 0 chunk_header 52 Header Each chunk refers to the start position of the previous chunk (<code>prev</code> field) 52 folders variable List[FolderHeader] In the data we have seen each chunk has 512 folders with headers of size 44 variable jump variable int"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#data-container","title":"Data Container","text":"Offset Name Size Parses to Description 0 header 60 ContainerHeader 60 item variable Any There are many kinds of DataItems indicated by different type IDs in the folder/container header"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#data-items","title":"Data Items","text":"<p>While the most important data, images and annotations were identified, there are still many data items that are not understood. We choose to sort the found data items by the level of information they are likely to contain. Therefore we use the IDs provided in the ContainerHeader (patient ID, study ID, series ID and slice ID). We assume that as in our test data these IDs follow some rules in them beeing hierarchical. Having a study is only meaningful if there is a patient and having a series in a study requires a study. Finally a slice requires a series to be contained in.</p> <ol> <li>Hence, if a slice ID is given we assume that the data is slice specific.</li> <li>If this is not the case, but a series ID is given, the data is series specific.</li> <li>If this is not the case, but a study ID is given, the data is study specific.</li> <li>If this is not the case, but a patient ID is given, the data is patient specific.</li> <li>If no ID is given, the data is general or a filler.</li> </ol> <p>In the following sections we describe the data items we found in each level of the described hierarchy. If you have any further information, please open an issue on GitHub and let us know.</p>"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#slice-data","title":"Slice Data","text":"Type ID Content Size Description 2 3  Type 3. 96 bytes 5  Type 5. 59 bytes 39 40 10004  B-scan Metadata Metadata for a single B-scan. 428 bytes 10012  Type 10012. variable 10013  Type 10013. variable 10019  Layer Annotation Stores one layer for one Bscan. variable 10020 10032 1073741824  Image data Stores various kinds of images. variable 1073751824 1073751825 1073751826"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#series-data","title":"Series Data","text":"Type ID Content Size Description 2 3  Type 3. 96 bytes 11  Type 11. 27 bytes 54 59  Type 59. 27 bytes 61 62 1000 1001 1003 1008 9005  Examined structure Name of the examined structure. 264 bytes 9006  Scan pattern Bscan pattern used for the aquisition. 520 bytes 9007  Enface Modality Modality of the enface (eg IR) 520 bytes 9008  OCT Modality Modality of the OCT (eg OCT) 520 bytes 10005 10009 10010  Type 10010. variable 10011 10013  Type 10013. variable 10025  Localizer Metadata. 100 bytes 1073741824  Image data Stores various kinds of images. variable 1073751824 1073751825 1073751826"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#study-data","title":"Study Data","text":"Type ID Content Size Description 7  Measurements Global measurements of the eye. 68 bytes 10 13 30 53 58 1000 9000  Studyname Name of the study/visit. 264 bytes 9001  Device Name of the used device. 776 bytes"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#patient-data","title":"Patient Data","text":"Type ID Content Size Description 9  Patient data Personal data of the patient. 131 bytes 17  Diagnose data. variable 29 31 52 9010"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#general-data","title":"General Data","text":"Type ID Content Size Description 0 9011"},{"location":"formats/he_e2e_structures/he_e2e_structure_doc/#further-observations","title":"Further observations","text":"<ul> <li>Some type IDs for example the laterality type might be repeated. In our test data there is a case where the only difference between the folder headers of this laterality data is the value of the <code>unknown2</code> field which takes the values 0, 1 and 65535.</li> </ul>"},{"location":"formats/he_e2e_types/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Type3</li> <li>Type5</li> <li>Type7</li> <li>Type9</li> <li>Type11</li> <li>Type17</li> <li>Type59</li> <li>Type9000</li> <li>Type9001</li> <li>Type9005</li> <li>Type9006</li> <li>Type9007</li> <li>Type9008</li> <li>Type10004</li> <li>Type10010</li> <li>Type10012</li> <li>Type10013</li> <li>Type10019</li> <li>Type10025</li> <li>Type1073741824</li> </ul>"},{"location":"formats/he_e2e_types/Type10004/","title":"Type10004 (B-scan Metadata Metadata for a single B-scan.)","text":"<p>Size: 428 bytes </p> <p>Occurence: E2ESliceStructure</p> <p>The current Bscan-Meta structure builds on the implementation found in LibE2E.</p> Offset Name Size Parses to Description 0 unknown0 4 int 4 size_y 4 int Bscan height 8 size_x 4 int Bscan width 12 start_x 4 float Start X coordinate of Bscan 16 start_y 4 float Start Y coordinate of Bscan 20 end_x 4 float End X coordinate of Bscan 24 end_y 4 float End Y coordinate of Bscan 28 zero1 4 int 32 unknown1 4 float 36 scale_y 4 float Scale of Bscan y-axis (height) 40 unknown2 4 float 44 zero2 4 int 48 unknown3 8 List[float] 56 zero3 4 int 60 imgSizeWidth 4 int Might differ from size_x, and is probably the number of filled A-scans in the Bscan. Bscans sometimes have empty A-scans at the ends. 64 n_bscans 4 int Number of Bscans in the respective volume 68 aktImage 4 int Index of the current Bscan in the volume 72 scan_pattern 4 int Scan pattern of the volume. Does this corresponds to the scan pattterns in VOL and XML export? 76 center_x 4 float Exactly the average of start_x and end_x. 80 center_y 4 float Exactly the average of start_y and end_y. 84 unknown4 4 int Maybe the UTC bias? 88 acquisitionTime 8 int Acquisition time of Bscan 96 numAve 4 int Number of averages according to LibE2ENot coherent with XML export 100 quality 4 float Quality according to LibE2EDoes not match the quality value in the XML export which is an integer compared to a float here with value 0.84 for a complete volume. Maybe this is the focus length, at least it is similar to the value given in the XML (0.87) 104 unknown5 4 float"},{"location":"formats/he_e2e_types/Type10010/","title":"Type10010 (Type 10010.)","text":"<p>Size: variable </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 unknown 12 bytes 12 n_bscans 4 int"},{"location":"formats/he_e2e_types/Type10012/","title":"Type10012 (Type 10012.)","text":"<p>Size: variable </p> <p>Occurence: E2ESliceStructure</p> Offset Name Size Parses to Description 0 unknown0 28 bytes 28 value_1 4 float 32 unknown1 1 bytes 33 value_2 4 float"},{"location":"formats/he_e2e_types/Type10013/","title":"Type10013 (Type 10013.)","text":"<p>Size: variable </p> <p>Occurence: E2ESeriesStructure, E2ESliceStructure</p> Offset Name Size Parses to Description 0 unknown 12 bytes 12 n_bscans 4 int"},{"location":"formats/he_e2e_types/Type10019/","title":"Type10019 (Layer Annotation Stores one layer for one Bscan.)","text":"<p>Size: variable </p> <p>Occurence: E2ESliceStructure</p> Offset Name Size Parses to Description 0 unknown0 4 int 4 id 4 int ID of the layer 8 unknown1 4 int 12 width 4 int Width of the layer 16 data variable List[float] Layer annotation data"},{"location":"formats/he_e2e_types/Type10025/","title":"Type10025 (Localizer Metadata.)","text":"<p>Size: 100 bytes </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 unknown 24 bytes 24 windate 8 int 32 transform 24 List[float] Parameters of affine transformation"},{"location":"formats/he_e2e_types/Type1073741824/","title":"Type1073741824 (Image data Stores various kinds of images.)","text":"<p>Size: variable </p> <p>Occurence: E2ESeriesStructure, E2ESliceStructure</p> <p>Different kinds of images are stored in this structure. Currently we know the following types:</p> <ul> <li>33620481: LocalizerNIR (<code>int8u</code>)</li> <li>35652097: Bscan (<code>float16u</code>)</li> </ul> <p>The custom <code>float16u</code> used to store the Bscan data, has no sign, a 6-bit exponent und 10-bit mantissa.</p> Offset Name Size Parses to Description 0 size 4 int Size of the data 4 type 4 int Type of the data 8 n_values 4 int Number of values in the data 12 height 4 int Height of the image 16 width 4 int Width of the image 20 data variable Any Image data"},{"location":"formats/he_e2e_types/Type11/","title":"Type11 (Type 11.)","text":"<p>Size: 27 bytes </p> <p>Occurence: E2ESeriesStructure</p> <p>We don't know what this data is used for, only that the 15th byte indicates the laterality of the eye.</p> Offset Name Size Parses to Description 0 unknown 14 bytes 14 laterality 1 LateralityEnum"},{"location":"formats/he_e2e_types/Type17/","title":"Type17 (Diagnose data.)","text":"<p>Size: variable </p> <p>Occurence: E2EPatientStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type3/","title":"Type3 (Type 3.)","text":"<p>Size: 96 bytes </p> <p>Occurence: E2ESeriesStructure, E2ESliceStructure</p> <p>We don't know what this data is used for, only that the 5th byte indicates the laterality of the eye.</p> Offset Name Size Parses to Description 0 unknown 4 bytes 4 laterality 1 LateralityEnum"},{"location":"formats/he_e2e_types/Type5/","title":"Type5 (Type 5.)","text":"<p>Size: 59 bytes </p> <p>Occurence: E2ESliceStructure</p> <p>We don't know what this data is used for, only that the 3rd byte indicates the laterality of the eye.</p> Offset Name Size Parses to Description 0 unknown 2 bytes 2 laterality 1 LateralityEnum"},{"location":"formats/he_e2e_types/Type59/","title":"Type59 (Type 59.)","text":"<p>Size: 27 bytes </p> <p>Occurence: E2ESeriesStructure</p> <p>We don't know what this data is used for, only that the 14th byte indicates the laterality of the eye.</p> Offset Name Size Parses to Description 0 unknown 14 bytes 14 laterality 1 LateralityEnum"},{"location":"formats/he_e2e_types/Type7/","title":"Type7 (Measurements Global measurements of the eye.)","text":"<p>Size: 68 bytes </p> <p>Occurence: E2EStudyStructure</p> Offset Name Size Parses to Description 0 eye_side 1 LateralityEnum 1 c_curve_mm 8 float 9 refraction_dpt 8 float 17 cylinder_dpt 8 float 25 axis_deg 8 float 33 pupil_size_mm 8 float 41 iop_mmHg 8 float 49 vfield_mean 8 float 57 vfield_var 8 float 65 corrective_lens 2 int 67 rest 1 bytes"},{"location":"formats/he_e2e_types/Type9/","title":"Type9 (Patient data Personal data of the patient.)","text":"<p>Size: 131 bytes </p> <p>Occurence: E2EPatientStructure</p> Offset Name Size Parses to Description 0 firstname 31 str 31 surname 66 str 97 birthdate 4 int 101 sex 1 str 102 patient_id 25 str"},{"location":"formats/he_e2e_types/Type9000/","title":"Type9000 (Studyname Name of the study/visit.)","text":"<p>Size: 264 bytes </p> <p>Occurence: E2EStudyStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type9001/","title":"Type9001 (Device Name of the used device.)","text":"<p>Size: 776 bytes </p> <p>Occurence: E2EStudyStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type9005/","title":"Type9005 (Examined structure Name of the examined structure.)","text":"<p>Size: 264 bytes </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type9006/","title":"Type9006 (Scan pattern Bscan pattern used for the aquisition.)","text":"<p>Size: 520 bytes </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type9007/","title":"Type9007 (Enface Modality Modality of the enface (eg IR))","text":"<p>Size: 520 bytes </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"formats/he_e2e_types/Type9008/","title":"Type9008 (OCT Modality Modality of the OCT (eg OCT))","text":"<p>Size: 520 bytes </p> <p>Occurence: E2ESeriesStructure</p> Offset Name Size Parses to Description 0 n_strings 4 int 4 string_size 4 int 8 text variable List[str]"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>eyepy<ul> <li>core<ul> <li>annotations</li> <li>eyebscan</li> <li>eyeenface</li> <li>eyemeta</li> <li>eyevolume</li> <li>filter</li> <li>grids</li> <li>mask_compression</li> <li>plotting</li> <li>utils</li> </ul> </li> <li>data</li> <li>io<ul> <li>he<ul> <li>e2e_format</li> <li>e2e_reader</li> <li>vol_reader</li> <li>xml_reader</li> </ul> </li> <li>import_functions</li> <li>utils</li> </ul> </li> <li>quant<ul> <li>metrics</li> <li>regions</li> <li>spatial</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/src/eyepy/","title":"eyepy","text":""},{"location":"reference/src/eyepy/#eyepy","title":"<code>eyepy</code>","text":"<p>The eyepy top.</p> <ul> <li>EyeVolume</li> <li>EyeBscan</li> <li> <p>EyeEnface</p> </li> <li> <p>EyeBscanMeta</p> </li> <li>EyeEnfaceMeta</li> <li> <p>EyeVolumeMeta</p> </li> <li> <p>EyeVolumeLayerAnnotation</p> </li> <li> <p>EyeBscanLayerAnnotation</p> </li> <li> <p>EyeEnfacePixelAnnotation</p> </li> <li> <p>EyeVolumePixelAnnotation</p> </li> <li> <p>EyeVolumeSlabAnnotation</p> </li> <li> <p>PolygonAnnotation</p> </li> <li> <p>EyeEnfaceOpticDiscAnnotation</p> </li> <li> <p>EyeEnfaceFoveaAnnotation</p> </li> </ul>"},{"location":"reference/src/eyepy/core/","title":"core","text":""},{"location":"reference/src/eyepy/core/#eyepy.core","title":"<code>eyepy.core</code>","text":""},{"location":"reference/src/eyepy/core/annotations/","title":"annotations","text":""},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations","title":"<code>eyepy.core.annotations</code>","text":""},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanLayerAnnotation","title":"<code>EyeBscanLayerAnnotation(eyevolumelayerannotation, index)</code>","text":"<p>Layer annotation for a single B-scan.</p> <p>Parameters:</p> Name Type Description Default <code>eyevolumelayerannotation</code> <code>EyeVolumeLayerAnnotation</code> <p>EyeVolumeLayerAnnotation object</p> required <code>index</code> <code>int</code> <p>Index of the B-scan</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(self, eyevolumelayerannotation: EyeVolumeLayerAnnotation,\n             index: int) -&gt; None:\n    \"\"\"Layer annotation for a single B-scan.\n\n    Args:\n        eyevolumelayerannotation: EyeVolumeLayerAnnotation object\n        index: Index of the B-scan\n\n    Returns:\n        None\n    \"\"\"\n    self.eyevolumelayerannotation = eyevolumelayerannotation\n    self.volume = eyevolumelayerannotation.volume\n    self.index = index\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanLayerAnnotation.data","title":"<code>data</code>  <code>property</code> <code>writable</code>","text":"<p>Layer heights.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanLayerAnnotation.knots","title":"<code>knots</code>  <code>property</code> <code>writable</code>","text":"<p>Knots parameterizing the layer heights.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanLayerAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Name of the layer annotation.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanSlabAnnotation","title":"<code>EyeBscanSlabAnnotation(eyevolumeslabannotation, index)</code>","text":"<p>Slab annotation for a single B-scan.</p> <p>Parameters:</p> Name Type Description Default <code>eyevolumeslabannotation</code> <code>EyeVolumeSlabAnnotation</code> <p>EyeVolumeSlabAnnotation object</p> required <code>index</code> <code>int</code> <p>Index of the B-scan</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(self, eyevolumeslabannotation: EyeVolumeSlabAnnotation,\n             index: int) -&gt; None:\n    \"\"\"Slab annotation for a single B-scan.\n\n    Args:\n        eyevolumeslabannotation: EyeVolumeSlabAnnotation object\n        index: Index of the B-scan\n\n    Returns:\n        None\n    \"\"\"\n    self.eyevolumeslabannotation = eyevolumeslabannotation\n    self.volume = eyevolumeslabannotation.volume\n    self.index = index\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanSlabAnnotation.mask","title":"<code>mask</code>  <code>property</code> <code>writable</code>","text":"<p>Mask of the slab in the B-scan.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeBscanSlabAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Name of the slab annotation.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceFoveaAnnotation","title":"<code>EyeEnfaceFoveaAnnotation(polygon, shape=None)</code>","text":"<p>               Bases: <code>PolygonAnnotation</code></p> <p>Fovea annotation for enface images with center point detection.</p> <p>Inherits from PolygonAnnotation and adds fovea-specific features: - Simple center point calculation - Can be created from a small circular region</p> <p>The fovea is typically a small region, so the center is calculated as the mean of the polygon vertices.</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(self, polygon: npt.NDArray[np.float64],\n             shape: Optional[tuple[int, int]] = None) -&gt; None:\n    \"\"\"Initialize PolygonAnnotation from polygon vertices.\n\n    Args:\n        polygon: Nx2 array of (row, col) coordinates defining the polygon vertices\n        shape: Shape (height, width) of the image for mask generation. Optional,\n               can be used later if needed for mask generation.\n    \"\"\"\n    self._polygon = np.asarray(polygon, dtype=np.float64)\n    if self._polygon.ndim != 2 or self._polygon.shape[1] != 2:\n        raise ValueError('Polygon must be an Nx2 array of (row, col) coordinates')\n\n    self._shape = shape\n    self._cached_mask = None\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceFoveaAnnotation.center","title":"<code>center</code>  <code>property</code>","text":"<p>Get the center (row, col) of the fovea.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (center_row, center_col) calculated as the mean of polygon vertices</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceFoveaAnnotation.plot","title":"<code>plot(ax=None, offset=(0, 0), color='yellow', marker='+', markersize=12, markeredgewidth=2, **kwargs)</code>","text":"<p>Plot the fovea annotation on the given axes as a center marker.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes to plot on. If None, uses current axes (plt.gca())</p> <code>None</code> <code>offset</code> <code>tuple[float, float]</code> <p>(row_offset, col_offset) to apply to coordinates for region plotting</p> <code>(0, 0)</code> <code>color</code> <code>str</code> <p>Color of the fovea marker (default: 'yellow')</p> <code>'yellow'</code> <code>marker</code> <code>str</code> <p>Marker style (default: '+')</p> <code>'+'</code> <code>markersize</code> <code>float</code> <p>Size of the marker (default: 12)</p> <code>12</code> <code>markeredgewidth</code> <code>float</code> <p>Width of the marker edge (default: 2)</p> <code>2</code> <code>**kwargs</code> <p>Additional keyword arguments passed to ax.plot() for styling</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot(self, ax: Optional[plt.Axes] = None, offset: tuple[float, float] = (0, 0),\n         color: str = 'yellow', marker: str = '+', markersize: float = 12,\n         markeredgewidth: float = 2, **kwargs) -&gt; None:\n    \"\"\"Plot the fovea annotation on the given axes as a center marker.\n\n    Args:\n        ax: Matplotlib axes to plot on. If None, uses current axes (plt.gca())\n        offset: (row_offset, col_offset) to apply to coordinates for region plotting\n        color: Color of the fovea marker (default: 'yellow')\n        marker: Marker style (default: '+')\n        markersize: Size of the marker (default: 12)\n        markeredgewidth: Width of the marker edge (default: 2)\n        **kwargs: Additional keyword arguments passed to ax.plot() for styling\n\n    Returns:\n        None\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Combine default styling with user overrides\n    plot_kwargs = {\n        'color': color,\n        'marker': marker,\n        'markersize': markersize,\n        'markeredgewidth': markeredgewidth,\n        **kwargs\n    }\n\n    # Apply offset to center coordinates\n    row_offset, col_offset = offset\n    center = self.center\n    center_row = center[0] - row_offset\n    center_col = center[1] - col_offset\n\n    ax.plot(center_col, center_row, **plot_kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation","title":"<code>EyeEnfaceOpticDiscAnnotation(polygon, shape=None)</code>","text":"<p>               Bases: <code>PolygonAnnotation</code></p> <p>Optic disc annotation for enface images with ellipse fitting capabilities.</p> <p>Inherits from PolygonAnnotation and adds optic disc-specific features: - Creation from ellipse parameters - Fitted ellipse properties (center, width, height)</p> <p>The optic disc can be initialized from an ellipse, a polygon, or a semantic mask. Internally, it is stored as a polygon, but provides properties to access ellipse parameters fitted to the polygon.</p> <p>Initialize EyeEnfaceOpticDiscAnnotation from a polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>NDArray[float64]</code> <p>Nx2 array of (row, col) coordinates defining the polygon vertices</p> required <code>shape</code> <code>Optional[tuple[int, int]]</code> <p>Shape (height, width) of the image for mask generation. Optional,    can be used later if needed for mask generation.</p> <code>None</code> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(self, polygon: npt.NDArray[np.float64],\n             shape: Optional[tuple[int, int]] = None) -&gt; None:\n    \"\"\"Initialize EyeEnfaceOpticDiscAnnotation from a polygon.\n\n    Args:\n        polygon: Nx2 array of (row, col) coordinates defining the polygon vertices\n        shape: Shape (height, width) of the image for mask generation. Optional,\n               can be used later if needed for mask generation.\n    \"\"\"\n    super().__init__(polygon, shape)\n    self._cached_ellipse = None\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.center","title":"<code>center</code>  <code>property</code>","text":"<p>Get the center (row, col) of the fitted ellipse.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (center_row, center_col)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.height","title":"<code>height</code>  <code>property</code>","text":"<p>Get the vertical extent of the optic disc polygon.</p> <p>This measures the vertical (row-direction) size by finding the vertical line passing through the center that intersects the polygon.</p> <p>Returns:</p> Type Description <code>float</code> <p>Vertical extent (height) of the polygon through its center</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.width","title":"<code>width</code>  <code>property</code>","text":"<p>Get the horizontal extent of the optic disc polygon.</p> <p>This measures the horizontal (column-direction) size by finding the horizontal line passing through the center that intersects the polygon.</p> <p>Returns:</p> Type Description <code>float</code> <p>Horizontal extent (width) of the polygon through its center</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.from_ellipse","title":"<code>from_ellipse(center, minor_axis, major_axis, rotation=0.0, num_points=64, shape=None)</code>  <code>classmethod</code>","text":"<p>Create EyeEnfaceOpticDiscAnnotation from ellipse parameters.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>tuple[float, float]</code> <p>(row, col) coordinates of ellipse center</p> required <code>minor_axis</code> <code>float</code> <p>Length of the minor axis (shorter diameter)</p> required <code>major_axis</code> <code>float</code> <p>Length of the major axis (longer diameter)</p> required <code>rotation</code> <code>float</code> <p>Rotation angle in radians (rotates the ellipse axes)</p> <code>0.0</code> <code>num_points</code> <code>int</code> <p>Number of points to sample on the ellipse perimeter</p> <code>64</code> <code>shape</code> <code>Optional[tuple[int, int]]</code> <p>Shape (height, width) of the image for mask generation</p> <code>None</code> <p>Returns:</p> Type Description <code>'EyeEnfaceOpticDiscAnnotation'</code> <p>EyeEnfaceOpticDiscAnnotation instance</p> Note <p>Before rotation, the minor axis is aligned with the row direction (vertical) and the major axis is aligned with the col direction (horizontal).</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>@classmethod\ndef from_ellipse(cls, center: tuple[float, float], minor_axis: float, major_axis: float,\n                 rotation: float = 0.0, num_points: int = 64,\n                 shape: Optional[tuple[int, int]] = None) -&gt; 'EyeEnfaceOpticDiscAnnotation':\n    \"\"\"Create EyeEnfaceOpticDiscAnnotation from ellipse parameters.\n\n    Args:\n        center: (row, col) coordinates of ellipse center\n        minor_axis: Length of the minor axis (shorter diameter)\n        major_axis: Length of the major axis (longer diameter)\n        rotation: Rotation angle in radians (rotates the ellipse axes)\n        num_points: Number of points to sample on the ellipse perimeter\n        shape: Shape (height, width) of the image for mask generation\n\n    Returns:\n        EyeEnfaceOpticDiscAnnotation instance\n\n    Note:\n        Before rotation, the minor axis is aligned with the row direction (vertical)\n        and the major axis is aligned with the col direction (horizontal).\n    \"\"\"\n    # Generate points on ellipse perimeter\n    theta = np.linspace(0, 2 * np.pi, num_points, endpoint=False)\n\n    # Ellipse in standard position (row, col offsets)\n    # Minor axis along row direction, major axis along col direction\n    row_offset = (minor_axis / 2) * np.cos(theta)\n    col_offset = (major_axis / 2) * np.sin(theta)\n\n    # Apply rotation\n    cos_rot = np.cos(rotation)\n    sin_rot = np.sin(rotation)\n    row_rot = row_offset * cos_rot - col_offset * sin_rot\n    col_rot = row_offset * sin_rot + col_offset * cos_rot\n\n    # Translate to center\n    row_coords = row_rot + center[0]\n    col_coords = col_rot + center[1]\n\n    polygon = np.column_stack([row_coords, col_coords])\n    return cls(polygon=polygon, shape=shape)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.plot","title":"<code>plot(ax=None, offset=(0, 0), plot_contour=True, plot_area=False, contour_color='red', contour_linewidth=2, contour_linestyle='-', area_color=None, area_alpha=0.3, **kwargs)</code>","text":"<p>Plot the optic disc annotation on the given axes.</p> <p>Provides flexible visualization options including contour outline and/or filled area.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes to plot on. If None, uses current axes (plt.gca())</p> <code>None</code> <code>offset</code> <code>tuple[float, float]</code> <p>(row_offset, col_offset) to apply to polygon coordinates for region plotting</p> <code>(0, 0)</code> <code>plot_contour</code> <code>bool</code> <p>If True, plot the contour outline (default: True)</p> <code>True</code> <code>plot_area</code> <code>bool</code> <p>If True, plot the filled area (default: False)</p> <code>False</code> <code>contour_color</code> <code>str</code> <p>Color of the contour outline (default: 'red')</p> <code>'red'</code> <code>contour_linewidth</code> <code>float</code> <p>Line width of the contour outline (default: 2)</p> <code>2</code> <code>contour_linestyle</code> <code>str</code> <p>Line style of the contour outline (default: '-')</p> <code>'-'</code> <code>area_color</code> <code>Optional[str]</code> <p>Color of the filled area. If None, uses contour_color (default: None)</p> <code>None</code> <code>area_alpha</code> <code>float</code> <p>Alpha transparency of the filled area (default: 0.3)</p> <code>0.3</code> <code>**kwargs</code> <p>Additional keyword arguments. For contour-only plotting, passed to ax.plot().      For area plotting, can include 'edgecolor' and 'facecolor' for fine control.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot(self, ax: Optional[plt.Axes] = None, offset: tuple[float, float] = (0, 0),\n         plot_contour: bool = True, plot_area: bool = False,\n         contour_color: str = 'red', contour_linewidth: float = 2,\n         contour_linestyle: str = '-', area_color: Optional[str] = None,\n         area_alpha: float = 0.3, **kwargs) -&gt; None:\n    \"\"\"Plot the optic disc annotation on the given axes.\n\n    Provides flexible visualization options including contour outline and/or filled area.\n\n    Args:\n        ax: Matplotlib axes to plot on. If None, uses current axes (plt.gca())\n        offset: (row_offset, col_offset) to apply to polygon coordinates for region plotting\n        plot_contour: If True, plot the contour outline (default: True)\n        plot_area: If True, plot the filled area (default: False)\n        contour_color: Color of the contour outline (default: 'red')\n        contour_linewidth: Line width of the contour outline (default: 2)\n        contour_linestyle: Line style of the contour outline (default: '-')\n        area_color: Color of the filled area. If None, uses contour_color (default: None)\n        area_alpha: Alpha transparency of the filled area (default: 0.3)\n        **kwargs: Additional keyword arguments. For contour-only plotting, passed to ax.plot().\n                 For area plotting, can include 'edgecolor' and 'facecolor' for fine control.\n\n    Returns:\n        None\n\n    Example:\n        &gt;&gt;&gt; # Plot only contour (default)\n        &gt;&gt;&gt; optic_disc.plot(ax, contour_color='red', contour_linewidth=2)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot only filled area\n        &gt;&gt;&gt; optic_disc.plot(ax, plot_contour=False, plot_area=True, area_color='red', area_alpha=0.5)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Plot both contour and area\n        &gt;&gt;&gt; optic_disc.plot(ax, plot_contour=True, plot_area=True,\n        ...                 contour_color='darkred', area_color='red', area_alpha=0.3)\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Apply offset to polygon coordinates\n    row_offset, col_offset = offset\n    polygon = self._polygon.copy()\n    polygon[:, 0] -= row_offset\n    polygon[:, 1] -= col_offset\n\n    # Determine area color if not specified\n    if area_color is None:\n        area_color = contour_color\n\n    # Plot filled area if requested\n    if plot_area:\n        # Extract face/edge color from kwargs if provided, otherwise use our parameters\n        facecolor = kwargs.pop('facecolor', area_color)\n        edgecolor = kwargs.pop('edgecolor', contour_color if plot_contour else 'none')\n\n        # Use matplotlib's fill to create filled polygon\n        # polygon is (row, col), matplotlib expects (x, y) = (col, row)\n        ax.fill(polygon[:, 1], polygon[:, 0],\n               facecolor=facecolor,\n               edgecolor=edgecolor if plot_contour else 'none',\n               alpha=area_alpha,\n               linewidth=contour_linewidth if plot_contour else 0,\n               linestyle=contour_linestyle if plot_contour else '-')\n\n    # Plot contour if requested (and not already plotted as part of area)\n    elif plot_contour:\n        # Combine contour styling\n        contour_kwargs = {\n            'color': contour_color,\n            'linewidth': contour_linewidth,\n            'linestyle': contour_linestyle,\n            **kwargs\n        }\n\n        # Plot polygon outline (polygon is x, y, matplotlib expects x, y)\n        ax.plot(polygon[:, 1], polygon[:, 0], **contour_kwargs)\n        # Close the polygon\n        ax.plot([polygon[-1, 1], polygon[0, 1]],\n               [polygon[-1, 0], polygon[0, 0]], **contour_kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.plot--plot-only-contour-default","title":"Plot only contour (default)","text":"<p>optic_disc.plot(ax, contour_color='red', contour_linewidth=2)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.plot--plot-only-filled-area","title":"Plot only filled area","text":"<p>optic_disc.plot(ax, plot_contour=False, plot_area=True, area_color='red', area_alpha=0.5)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfaceOpticDiscAnnotation.plot--plot-both-contour-and-area","title":"Plot both contour and area","text":"<p>optic_disc.plot(ax, plot_contour=True, plot_area=True, ...                 contour_color='darkred', area_color='red', area_alpha=0.3)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfacePixelAnnotation","title":"<code>EyeEnfacePixelAnnotation(enface, data=None, meta=None, **kwargs)</code>","text":"<p>Pixel annotation for an enface image.</p> <p>Parameters:</p> Name Type Description Default <code>enface</code> <code>EyeEnface</code> <p>EyeEnface object</p> required <code>data</code> <code>Optional[NDArray[bool_]]</code> <p>Pixel annotation data</p> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <p>Metadata</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional metadata specified as keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(\n    self,\n    enface: EyeEnface,\n    data: Optional[npt.NDArray[np.bool_]] = None,\n    meta: Optional[dict] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Pixel annotation for an enface image.\n\n    Args:\n        enface: EyeEnface object\n        data: Pixel annotation data\n        meta: Metadata\n        **kwargs: Additional metadata specified as keyword arguments\n\n    Returns:\n        None\n    \"\"\"\n    self.enface = enface\n\n    if data is None:\n        self.data = np.full(self.enface.shape,\n                            fill_value=False,\n                            dtype=bool)\n    else:\n        self.data = data\n\n    if meta is None:\n        self.meta = kwargs\n    else:\n        self.meta = meta\n        self.meta.update(**kwargs)\n\n    if 'name' not in self.meta:\n        self.meta['name'] = 'Pixel Annotation'\n\n    # Set default color from config if not already specified\n    if 'color' not in self.meta:\n        self.meta['color'] = '#' + config.area_colors[self.meta['name']]\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeEnfacePixelAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Name of the pixel annotation.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeLayerAnnotation","title":"<code>EyeVolumeLayerAnnotation(volume, data=None, meta=None, **kwargs)</code>","text":"<p>Layer annotation for a single layer in an EyeVolume.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>EyeVolume</code> <p>EyeVolume object</p> required <code>data</code> <code>Optional[NDArray[float64]]</code> <p>2D array of shape (n_bscans, bscan_width) holding layer height values</p> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <p>dict with additional meta data</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>additional meta data specified as parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(\n    self,\n    volume: EyeVolume,\n    data: Optional[npt.NDArray[np.float64]] = None,\n    meta: Optional[dict] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Layer annotation for a single layer in an EyeVolume.\n\n    Args:\n        volume: EyeVolume object\n        data: 2D array of shape (n_bscans, bscan_width) holding layer height values\n        meta: dict with additional meta data\n        **kwargs: additional meta data specified as parameters\n\n    Returns:\n        None\n    \"\"\"\n    self.volume = volume\n    if data is None:\n        self.data = np.full((volume.size_z, volume.size_x), np.nan)\n    else:\n        self.data = data\n\n    if meta is None:\n        self.meta = kwargs\n    else:\n        self.meta = meta\n        self.meta.update(**kwargs)\n\n    # knots is a dict layername: list of curves where every curve is a list of knots\n    if 'knots' not in self.meta:\n        self.meta['knots'] = defaultdict(lambda: [])\n    elif type(self.meta['knots']) is dict:\n        self.meta['knots'] = defaultdict(lambda: [], self.meta['knots'])\n\n    if 'name' not in self.meta:\n        self.meta['name'] = 'Layer Annotation'\n\n    self.meta['current_color'] = config.layer_colors[self.name]\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeLayerAnnotation.knots","title":"<code>knots</code>  <code>property</code>","text":"<p>Knots parameterizing the layer.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeLayerAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Layer name.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeLayerAnnotation.layer_indices","title":"<code>layer_indices()</code>","text":"<p>Returns pixel indices of the layer in the volume.</p> <p>While the layer is stored as the offset from the bottom of the OCT volume, some applications require layer discretized to voxel positions. This method returns the layer as indices into the OCT volume.</p> <p>The indices can be used for example to create layer maps for semantic segmentation.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport eyepy as ep\n\neye_volume = ep.data.load(\"drusen_patient\")\nrpe_annotation = eye_volume.layers[\"RPE\"]\nrpe_indices = rpe_annotation.layer_indices()\nrpe_map = np.zeros(eye_volume.shape)\nrpe_map[rpe_indices] = 1\nplt.imshow(rpe_map[0]) # (1)\n</code></pre> <ol> <li>Visualize layer map for the first B-scan</li> </ol> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray, ndarray]</code> <p>A tuple with indices for the layers position in the volume - Tuple[bscan_indices, row_indices, column_indices]</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def layer_indices(self) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Returns pixel indices of the layer in the volume.\n\n    While the layer is stored as the offset from the bottom of the OCT volume, some applications require\n    layer discretized to voxel positions. This method returns the layer as indices into the OCT volume.\n\n    The indices can be used for example to create layer maps for semantic segmentation.\n\n    ```python\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import eyepy as ep\n\n    eye_volume = ep.data.load(\"drusen_patient\")\n    rpe_annotation = eye_volume.layers[\"RPE\"]\n    rpe_indices = rpe_annotation.layer_indices()\n    rpe_map = np.zeros(eye_volume.shape)\n    rpe_map[rpe_indices] = 1\n    plt.imshow(rpe_map[0]) # (1)\n    ```\n\n    1.  Visualize layer map for the first B-scan\n\n    Returns:\n        A tuple with indices for the layers position in the volume - Tuple[bscan_indices, row_indices, column_indices]\n    \"\"\"\n    layer = self.data[:, np.newaxis, :]\n    nan_indices = np.isnan(layer)\n    row_indices = np.rint(layer).astype(int)[~nan_indices]\n    x = np.ones(layer.shape)\n    x[nan_indices] = 0\n    bscan_indices, _, col_indices = np.nonzero(x)\n    return (bscan_indices, row_indices, col_indices)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation","title":"<code>EyeVolumePixelAnnotation(volume, data=None, meta=None, radii=(1.5, 2.5), n_sectors=(1, 4), offsets=(0, 45), center=None, **kwargs)</code>","text":"<p>Pixel annotation for an EyeVolume.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>EyeVolume</code> <p>EyeVolume object</p> required <code>data</code> <code>Optional[NDArray[bool_]]</code> <p>3D array of shape (n_bscans, bscan_height, bscan_width) holding boolean pixel annotations</p> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <p>dict with additional meta data</p> <code>None</code> <code>radii</code> <code>Iterable[float]</code> <p>radii for quantification on circular grid</p> <code>(1.5, 2.5)</code> <code>n_sectors</code> <code>Iterable[int]</code> <p>number of sectors for quantification on circular grid</p> <code>(1, 4)</code> <code>offsets</code> <code>Iterable[int]</code> <p>offsets from x axis for first sector, for quantification on circular grid</p> <code>(0, 45)</code> <code>center</code> <code>Optional[tuple[float, float]]</code> <p>center of circular grid for quantification</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>additional meta data specified as parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(\n    self,\n    volume: EyeVolume,\n    # Type hint for an optional boolean numpy array\n    data: Optional[npt.NDArray[np.bool_]] = None,\n    meta: Optional[dict] = None,\n    radii: Iterable[float] = (1.5, 2.5),\n    n_sectors: Iterable[int] = (1, 4),\n    offsets: Iterable[int] = (0, 45),\n    center: Optional[tuple[float, float]] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Pixel annotation for an EyeVolume.\n\n    Args:\n        volume: EyeVolume object\n        data: 3D array of shape (n_bscans, bscan_height, bscan_width) holding boolean pixel annotations\n        meta: dict with additional meta data\n        radii: radii for quantification on circular grid\n        n_sectors: number of sectors for quantification on circular grid\n        offsets: offsets from x axis for first sector, for quantification on circular grid\n        center: center of circular grid for quantification\n        **kwargs: additional meta data specified as parameters\n\n    Returns:\n        None\n    \"\"\"\n    self.volume = volume\n\n    if data is None:\n        self.data = np.full(self.volume.shape,\n                            fill_value=False,\n                            dtype=bool)\n    else:\n        self.data = data\n\n    self._masks = None\n    self._quantification = None\n\n    if meta is None:\n        self.meta = kwargs\n    else:\n        self.meta = meta\n        self.meta.update(**kwargs)\n\n    self.meta.update(\n        **{\n            'radii': radii,\n            'n_sectors': n_sectors,\n            'offsets': offsets,\n            'center': center,\n        })\n\n    if 'name' not in self.meta:\n        self.meta['name'] = 'Voxel Annotation'\n\n    # Set default color from config if not already specified\n    if 'color' not in self.meta:\n        self.meta['color'] = '#' + config.area_colors[self.meta['name']]\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.center","title":"<code>center</code>  <code>property</code> <code>writable</code>","text":"<p>Center of circular grid for quantification.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.enface","title":"<code>enface</code>  <code>property</code>","text":"<p>Transformed projection of the annotation to the enface plane.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.masks","title":"<code>masks</code>  <code>property</code>","text":"<p>Masks for quantification on circular grid.</p> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>A dictionary of masks with the keys being the names of the masks.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.n_sectors","title":"<code>n_sectors</code>  <code>property</code> <code>writable</code>","text":"<p>Number of sectors for quantification on circular grid.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Annotation name.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.offsets","title":"<code>offsets</code>  <code>property</code> <code>writable</code>","text":"<p>Offsets from x axis for first sector, for quantification on circular grid.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.projection","title":"<code>projection</code>  <code>property</code>","text":"<p>Projection of the annotation to the enface plane.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.quantification","title":"<code>quantification</code>  <code>property</code>","text":"<p>Quantification of the annotation on the specified circular grid.</p> <p>Returns:</p> Type Description <code>dict[str, Union[float, str]]</code> <p>A dictionary of quantifications with the keys being the names of the regions.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.radii","title":"<code>radii</code>  <code>property</code> <code>writable</code>","text":"<p>Radii for quantification on circular grid.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.plot","title":"<code>plot(ax=None, region=np.s_[:, :], cmap='Reds', vmin=None, vmax=None, cbar=True, alpha=1)</code>","text":"<p>Plot the annotation on the enface plane.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>matplotlib axes object</p> <code>None</code> <code>region</code> <code>Union[slice, tuple[slice, slice]]</code> <p>region of the enface projection to plot</p> <code>s_[:, :]</code> <code>cmap</code> <code>Union[str, Colormap]</code> <p>colormap</p> <code>'Reds'</code> <code>vmin</code> <code>Optional[float]</code> <p>minimum value for colorbar</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>maximum value for colorbar</p> <code>None</code> <code>cbar</code> <code>bool</code> <p>whether to plot a colorbar</p> <code>True</code> <code>alpha</code> <code>float</code> <p>alpha value for the annotation</p> <code>1</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot(\n    self,\n    ax: Optional[plt.Axes] = None,\n    region: Union[slice, tuple[slice, slice]] = np.s_[:, :],\n    cmap: Union[str, mpl.colors.Colormap] = 'Reds',\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    cbar: bool = True,\n    alpha: float = 1,\n) -&gt; None:\n    \"\"\"Plot the annotation on the enface plane.\n\n    Args:\n        ax: matplotlib axes object\n        region: region of the enface projection to plot\n        cmap: colormap\n        vmin: minimum value for colorbar\n        vmax: maximum value for colorbar\n        cbar: whether to plot a colorbar\n        alpha: alpha value for the annotation\n\n    Returns:\n        None\n    \"\"\"\n    enface_projection = self.enface\n\n    ax = plt.gca() if ax is None else ax\n\n    if vmin is None:\n        vmin = 1\n    if vmax is None:\n        vmax = max([enface_projection.max(), vmin])\n\n    enface_crop = enface_projection[region]\n    visible = np.zeros(enface_crop.shape)\n    visible[np.logical_and(vmin &lt;= enface_crop, enface_crop &lt;= vmax)] = 1\n\n    if cbar:\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes('right', size='5%', pad=0.05)\n        plt.colorbar(\n            cm.ScalarMappable(colors.Normalize(vmin=vmin, vmax=vmax),\n                              cmap=cmap),\n            cax=cax,\n        )\n\n    ax.imshow(\n        enface_crop,\n        alpha=visible * alpha,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumePixelAnnotation.plot_quantification","title":"<code>plot_quantification(ax=None, region=np.s_[:, :], alpha=0.5, vmin=None, vmax=None, cbar=True, cmap='YlOrRd')</code>","text":"<p>Plot circular grid quantification of the annotation (like ETDRS)</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes to plot on</p> <code>None</code> <code>region</code> <code>Union[slice, tuple[slice, slice]]</code> <p>Region to plot</p> <code>s_[:, :]</code> <code>alpha</code> <code>float</code> <p>Alpha value of the mask</p> <code>0.5</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for the colorbar</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for the colorbar</p> <code>None</code> <code>cbar</code> <code>bool</code> <p>Whether to plot a colorbar</p> <code>True</code> <code>cmap</code> <code>Union[str, Colormap]</code> <p>Colormap to use</p> <code>'YlOrRd'</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot_quantification(\n    self,\n    ax: Optional[plt.Axes] = None,\n    region: Union[slice, tuple[slice, slice]] = np.s_[:, :],\n    alpha: float = 0.5,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    cbar: bool = True,\n    cmap: Union[str, mpl.colors.Colormap] = 'YlOrRd',\n) -&gt; None:\n    \"\"\"Plot circular grid quantification of the annotation (like ETDRS)\n\n    Args:\n        ax: Matplotlib axes to plot on\n        region: Region to plot\n        alpha: Alpha value of the mask\n        vmin: Minimum value for the colorbar\n        vmax: Maximum value for the colorbar\n        cbar: Whether to plot a colorbar\n        cmap: Colormap to use\n\n    Returns:\n        None\n    \"\"\"\n\n    ax = plt.gca() if ax is None else ax\n\n    mask_img = np.zeros(self.volume.localizer.shape, dtype=float)[region]\n    visible = np.zeros_like(mask_img)\n    for mask_name in self.masks.keys():\n        mask_img += (self.masks[mask_name][region] *\n                     self.quantification[mask_name + ' [mm\u00b3]'])\n        visible += self.masks[mask_name][region]\n\n    vmin = mask_img[visible.astype(int)].min() if vmin is None else vmin\n    vmax = max([mask_img.max(), vmin]) if vmax is None else vmax\n\n    if cbar:\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes('right', size='5%', pad=0.05)\n        plt.colorbar(\n            cm.ScalarMappable(colors.Normalize(vmin=vmin, vmax=vmax),\n                              cmap=cmap),\n            cax=cax,\n        )\n\n    ax.imshow(\n        mask_img,\n        alpha=visible * alpha,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation","title":"<code>EyeVolumeSlabAnnotation(volume, meta=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>volume</code> <code>EyeVolume</code> <p>An EyeVolume object</p> required <code>meta</code> <code>Optional[dict]</code> <p>dict with additional meta data</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>additional meta data as keyword arguments</p> <code>{}</code> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(\n    self,\n    volume: EyeVolume,\n    meta: Optional[dict] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"\n\n    Args:\n        volume: An EyeVolume object\n        meta: dict with additional meta data\n        **kwargs: additional meta data as keyword arguments\n    \"\"\"\n    self.volume = volume\n    self._mask = None\n\n    if meta is None:\n        self.meta = kwargs\n    else:\n        self.meta = meta\n        self.meta.update(**kwargs)\n\n    # Set default values if not provided\n    if 'name' not in self.meta:\n        self.meta['name'] = 'OCTA Slab'\n\n    # Ensure layer references are present\n    if 'top_layer' not in self.meta:\n        self.meta['top_layer'] = None\n    if 'bottom_layer' not in self.meta:\n        self.meta['bottom_layer'] = None\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.bottom_layer","title":"<code>bottom_layer</code>  <code>property</code> <code>writable</code>","text":"<p>Bottom layer name/acronym.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.enface","title":"<code>enface</code>  <code>property</code>","text":"<p>Transformed projection of the annotation to the enface plane.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.mask","title":"<code>mask</code>  <code>property</code>","text":"<p>Mask of the slab in the volume.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.name","title":"<code>name</code>  <code>property</code> <code>writable</code>","text":"<p>Slab name.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.projection","title":"<code>projection</code>  <code>property</code>","text":"<p>Projection of the data within the slab mask to the enface plane.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.top_layer","title":"<code>top_layer</code>  <code>property</code> <code>writable</code>","text":"<p>Top layer name/acronym.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.apply_contrast","title":"<code>apply_contrast(enface, contrast)</code>","text":"<p>Apply contrast to the enface projection.</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def apply_contrast(self, enface: np.ndarray, contrast: float) -&gt; np.ndarray:\n    \"\"\"Apply contrast to the enface projection.\"\"\"\n    if contrast &lt;= 0:\n        logger.warning(f'Invalid contrast value: {contrast}. Using default contrast of 4.')\n        contrast = 4\n\n    return np.clip(enface / contrast, 0, 1.0)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.EyeVolumeSlabAnnotation.plot","title":"<code>plot(ax=None, region=np.s_[:, :], cmap='Greys_r', vmin=None, vmax=None, cbar=False, alpha=1, contrast=None, par=None, transform=False, **kwargs)</code>","text":"<p>Plot the annotation on the enface plane.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>matplotlib axes object</p> <code>None</code> <code>region</code> <code>Union[slice, tuple[slice, slice]]</code> <p>region of the enface projection to plot</p> <code>s_[:, :]</code> <code>cmap</code> <code>Union[str, Colormap]</code> <p>colormap</p> <code>'Greys_r'</code> <code>vmin</code> <code>Optional[float]</code> <p>minimum value for colorbar</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>maximum value for colorbar</p> <code>None</code> <code>cbar</code> <code>bool</code> <p>whether to plot a colorbar</p> <code>False</code> <code>alpha</code> <code>float</code> <p>alpha value for the annotation</p> <code>1</code> <code>contrast</code> <code>Union[int, Literal['auto']]</code> <p>contrast value for the annotation</p> <code>None</code> <code>par</code> <code>bool</code> <p>whether to apply Projection Artifact Removal (PAR) to the enface projection</p> <code>None</code> <code>transform</code> <code>bool</code> <p>whether to apply the localizer transform to the enface projection</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot(\n    self,\n    ax: Optional[plt.Axes] = None,\n    region: Union[slice, tuple[slice, slice]] = np.s_[:, :],\n    cmap: Union[str, mpl.colors.Colormap] = 'Greys_r',\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    cbar: bool = False,\n    alpha: float = 1,\n    contrast: Union[int, Literal['auto']] = None,\n    par: bool = None,\n    transform: bool = False,\n    **kwargs\n) -&gt; None:\n    \"\"\"Plot the annotation on the enface plane.\n\n    Args:\n        ax: matplotlib axes object\n        region: region of the enface projection to plot\n        cmap: colormap\n        vmin: minimum value for colorbar\n        vmax: maximum value for colorbar\n        cbar: whether to plot a colorbar\n        alpha: alpha value for the annotation\n        contrast: contrast value for the annotation\n        par: whether to apply Projection Artifact Removal (PAR) to the enface projection\n        transform: whether to apply the localizer transform to the enface projection\n\n    Returns:\n        None\n    \"\"\"\n    if par is None:\n        par = SLAB_PROJECTION_DEFAULTS.get(self.name, {}).get('PAR', False)\n\n    enface_projection = self.enface(par) if transform else self.projection(par)\n\n    if contrast is None:\n        contrast = SLAB_PROJECTION_DEFAULTS.get(self.name, {}).get('contrast', 'auto')\n    if contrast == 'auto':\n        contrast = self.iqr_contrast(self.projection(par), kwargs.get('factor', 1.5))\n    elif not isinstance(contrast, (int, float)) or contrast &lt;= 0:\n        logger.warning(\n            f'Invalid contrast value: {contrast}. Using default contrast of 4.')\n        contrast = 4\n    else:\n        contrast = int(contrast)\n\n    enface_crop = self.apply_contrast(enface_projection[region], contrast)\n\n    ax = plt.gca() if ax is None else ax\n\n    if vmin is None:\n        vmin = 0\n    if vmax is None:\n        vmax = np.nanmax([np.nanmax(enface_crop), vmin])\n\n    visible = np.zeros(enface_crop.shape)\n    visible[np.logical_and(vmin &lt; enface_crop, enface_crop &lt;= vmax)] = 1\n\n    if cbar:\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes('right', size='5%', pad=0.05)\n        plt.colorbar(\n            cm.ScalarMappable(colors.Normalize(vmin=vmin, vmax=vmax),\n                              cmap=cmap),\n            cax=cax,\n        )\n\n    ax.imshow(\n        enface_crop,\n        alpha=visible * alpha,\n        cmap=cmap,\n        vmin=vmin,\n        vmax=vmax,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation","title":"<code>PolygonAnnotation(polygon, shape=None)</code>","text":"<p>Immutable polygon annotation with transformation methods.</p> <p>This is a base class for polygon-based annotations like optic disc, macula, lesions, etc. The polygon is stored internally and transformations return new instances.</p> <p>Coordinate System: All coordinates are in (row, col) format consistent with NumPy array indexing and scikit-image conventions. Row corresponds to the vertical axis (y-direction), and col corresponds to the horizontal axis (x-direction).</p> <p>Initialize PolygonAnnotation from polygon vertices.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>NDArray[float64]</code> <p>Nx2 array of (row, col) coordinates defining the polygon vertices</p> required <code>shape</code> <code>Optional[tuple[int, int]]</code> <p>Shape (height, width) of the image for mask generation. Optional,    can be used later if needed for mask generation.</p> <code>None</code> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def __init__(self, polygon: npt.NDArray[np.float64],\n             shape: Optional[tuple[int, int]] = None) -&gt; None:\n    \"\"\"Initialize PolygonAnnotation from polygon vertices.\n\n    Args:\n        polygon: Nx2 array of (row, col) coordinates defining the polygon vertices\n        shape: Shape (height, width) of the image for mask generation. Optional,\n               can be used later if needed for mask generation.\n    \"\"\"\n    self._polygon = np.asarray(polygon, dtype=np.float64)\n    if self._polygon.ndim != 2 or self._polygon.shape[1] != 2:\n        raise ValueError('Polygon must be an Nx2 array of (row, col) coordinates')\n\n    self._shape = shape\n    self._cached_mask = None\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.mask","title":"<code>mask</code>  <code>property</code>","text":"<p>Generate semantic segmentation mask from polygon.</p> <p>Returns:</p> Type Description <code>NDArray[bool_]</code> <p>Binary mask of shape self.shape</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If shape is not set</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.polygon","title":"<code>polygon</code>  <code>property</code>","text":"<p>Get the polygon representation as Nx2 array of (row, col) coordinates.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Get the image shape used for mask generation.</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.from_mask","title":"<code>from_mask(mask)</code>  <code>classmethod</code>","text":"<p>Create PolygonAnnotation from a semantic segmentation mask.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask where True indicates annotated pixels</p> required <p>Returns:</p> Type Description <code>'PolygonAnnotation'</code> <p>PolygonAnnotation instance with shape set to mask.shape</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>@classmethod\ndef from_mask(cls, mask: npt.NDArray[np.bool_]) -&gt; 'PolygonAnnotation':\n    \"\"\"Create PolygonAnnotation from a semantic segmentation mask.\n\n    Args:\n        mask: Binary mask where True indicates annotated pixels\n\n    Returns:\n        PolygonAnnotation instance with shape set to mask.shape\n    \"\"\"\n    # Find contours in the mask\n    contours = measure.find_contours(mask.astype(np.float64), level=0.5)\n\n    if len(contours) == 0:\n        raise ValueError('No contours found in mask')\n\n    # Take the largest contour (returns row, col)\n    largest_contour = max(contours, key=len)\n\n    return cls(polygon=largest_contour, shape=mask.shape)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.plot","title":"<code>plot(ax=None, offset=(0, 0), **kwargs)</code>","text":"<p>Plot the polygon outline on the given axes.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes. If None, uses current axes (plt.gca())</p> <code>None</code> <code>offset</code> <code>tuple[float, float]</code> <p>(row_offset, col_offset) to adjust polygon position before plotting</p> <code>(0, 0)</code> <code>**kwargs</code> <p>Additional keyword arguments passed to ax.plot()</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def plot(self, ax: Optional[plt.Axes] = None, offset: tuple[float, float] = (0, 0),\n         **kwargs) -&gt; None:\n    \"\"\"Plot the polygon outline on the given axes.\n\n    Args:\n        ax: Matplotlib axes. If None, uses current axes (plt.gca())\n        offset: (row_offset, col_offset) to adjust polygon position before plotting\n        **kwargs: Additional keyword arguments passed to ax.plot()\n\n    Returns:\n        None\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Apply offset to polygon coordinates\n    row_offset, col_offset = offset\n    polygon = self._polygon.copy()\n    polygon[:, 0] -= row_offset\n    polygon[:, 1] -= col_offset\n\n    # Plot polygon outline (matplotlib expects x, y, so swap col, row)\n    ax.plot(polygon[:, 1], polygon[:, 0], **kwargs)\n    # Close the polygon\n    ax.plot([polygon[-1, 1], polygon[0, 1]],\n           [polygon[-1, 0], polygon[0, 0]], **kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.rotate","title":"<code>rotate(angle, center=None)</code>","text":"<p>Return a new PolygonAnnotation with rotated polygon.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>Rotation angle in radians (positive = counter-clockwise)</p> required <code>center</code> <code>Optional[tuple[float, float]]</code> <p>Center point (row, col) for rotation. If None, uses the polygon's centroid.</p> <code>None</code> <p>Returns:</p> Type Description <code>'PolygonAnnotation'</code> <p>New PolygonAnnotation instance with rotated polygon</p> Example <p>ann_rotated = ann.rotate(np.pi / 4)  # Rotate 45 degrees counter-clockwise</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def rotate(self, angle: float, center: Optional[tuple[float, float]] = None) -&gt; 'PolygonAnnotation':\n    \"\"\"Return a new PolygonAnnotation with rotated polygon.\n\n    Args:\n        angle: Rotation angle in radians (positive = counter-clockwise)\n        center: Center point (row, col) for rotation. If None, uses the polygon's centroid.\n\n    Returns:\n        New PolygonAnnotation instance with rotated polygon\n\n    Example:\n        &gt;&gt;&gt; ann_rotated = ann.rotate(np.pi / 4)  # Rotate 45 degrees counter-clockwise\n    \"\"\"\n    # Create rotation matrix\n    cos_angle = np.cos(angle)\n    sin_angle = np.sin(angle)\n    rotation_matrix = np.array([\n        [cos_angle, -sin_angle],\n        [sin_angle, cos_angle]\n    ])\n\n    return self.transform(rotation_matrix, center=center)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.scale","title":"<code>scale(factor, center=None)</code>","text":"<p>Return a new PolygonAnnotation with scaled polygon.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>float</code> <p>Scaling factor (e.g., 1.5 for 150% size, 0.5 for 50% size)</p> required <code>center</code> <code>Optional[tuple[float, float]]</code> <p>Center point (row, col) for scaling. If None, uses the polygon's centroid.</p> <code>None</code> <p>Returns:</p> Type Description <code>'PolygonAnnotation'</code> <p>New PolygonAnnotation instance with scaled polygon</p> Example <p>ann_larger = ann.scale(1.5)  # 50% larger ann_smaller = ann.scale(0.5)  # 50% smaller</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def scale(self, factor: float, center: Optional[tuple[float, float]] = None) -&gt; 'PolygonAnnotation':\n    \"\"\"Return a new PolygonAnnotation with scaled polygon.\n\n    Args:\n        factor: Scaling factor (e.g., 1.5 for 150% size, 0.5 for 50% size)\n        center: Center point (row, col) for scaling. If None, uses the polygon's centroid.\n\n    Returns:\n        New PolygonAnnotation instance with scaled polygon\n\n    Example:\n        &gt;&gt;&gt; ann_larger = ann.scale(1.5)  # 50% larger\n        &gt;&gt;&gt; ann_smaller = ann.scale(0.5)  # 50% smaller\n    \"\"\"\n    # Create scaling matrix\n    scale_matrix = np.array([\n        [factor, 0],\n        [0, factor]\n    ])\n\n    return self.transform(scale_matrix, center=center)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.transform","title":"<code>transform(matrix, center=None)</code>","text":"<p>Return a new PolygonAnnotation with affine-transformed polygon.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray[float64]</code> <p>2x2 affine transformation matrix or 2x3 matrix (last column is translation)</p> required <code>center</code> <code>Optional[tuple[float, float]]</code> <p>Center point (row, col) for transformation. If None, uses the polygon's centroid.    Only used if matrix is 2x2 (ignored for 2x3 matrices with translation).</p> <code>None</code> <p>Returns:</p> Type Description <code>'PolygonAnnotation'</code> <p>New PolygonAnnotation instance with transformed polygon</p> Example Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def transform(self, matrix: npt.NDArray[np.float64],\n              center: Optional[tuple[float, float]] = None) -&gt; 'PolygonAnnotation':\n    \"\"\"Return a new PolygonAnnotation with affine-transformed polygon.\n\n    Args:\n        matrix: 2x2 affine transformation matrix or 2x3 matrix (last column is translation)\n        center: Center point (row, col) for transformation. If None, uses the polygon's centroid.\n               Only used if matrix is 2x2 (ignored for 2x3 matrices with translation).\n\n    Returns:\n        New PolygonAnnotation instance with transformed polygon\n\n    Example:\n        &gt;&gt;&gt; # Shear transformation\n        &gt;&gt;&gt; shear_matrix = np.array([[1, 0.5], [0, 1]])\n        &gt;&gt;&gt; ann_sheared = ann.transform(shear_matrix)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Combined scale and translate\n        &gt;&gt;&gt; matrix = np.array([[1.5, 0, 10], [0, 1.5, 20]])  # scale 1.5x, translate (10, 20)\n        &gt;&gt;&gt; ann_transformed = ann.transform(matrix)\n    \"\"\"\n    if matrix.shape == (2, 3):\n        # Affine transformation with translation\n        # Extract rotation/scale part and translation\n        transform_matrix = matrix[:, :2]\n        translation = matrix[:, 2]\n\n        # polygon is (row, col), matrix also expects (row, col)\n        transformed = self._polygon @ transform_matrix.T + translation\n        result = transformed\n\n    elif matrix.shape == (2, 2):\n        # Pure linear transformation (rotation, scale, shear)\n        if center is None:\n            center = self._polygon.mean(axis=0)\n\n        # Translate to origin\n        centered = self._polygon - np.array(center)\n\n        # polygon is (row, col), matrix also expects (row, col)\n        transformed = centered @ matrix.T\n\n        # Translate back\n        result = transformed + np.array(center)\n    else:\n        raise ValueError('Matrix must be 2x2 or 2x3')\n\n    return self.__class__(result, shape=self._shape)\n</code></pre>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.transform--shear-transformation","title":"Shear transformation","text":"<p>shear_matrix = np.array([[1, 0.5], [0, 1]]) ann_sheared = ann.transform(shear_matrix)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.transform--combined-scale-and-translate","title":"Combined scale and translate","text":"<p>matrix = np.array([[1.5, 0, 10], [0, 1.5, 20]])  # scale 1.5x, translate (10, 20) ann_transformed = ann.transform(matrix)</p>"},{"location":"reference/src/eyepy/core/annotations/#eyepy.core.annotations.PolygonAnnotation.translate","title":"<code>translate(drow, dcol)</code>","text":"<p>Return a new PolygonAnnotation with translated polygon.</p> <p>Parameters:</p> Name Type Description Default <code>drow</code> <code>float</code> <p>Translation offset in the row direction (vertical). Positive moves downward.</p> required <code>dcol</code> <code>float</code> <p>Translation offset in the col direction (horizontal). Positive moves rightward.</p> required <p>Returns:</p> Type Description <code>'PolygonAnnotation'</code> <p>New PolygonAnnotation instance with translated polygon</p> Example <p>ann_moved = ann.translate(10, 20)  # Move 10 pixels down, 20 pixels right</p> Source code in <code>src/eyepy/core/annotations.py</code> <pre><code>def translate(self, drow: float, dcol: float) -&gt; 'PolygonAnnotation':\n    \"\"\"Return a new PolygonAnnotation with translated polygon.\n\n    Args:\n        drow: Translation offset in the row direction (vertical). Positive moves downward.\n        dcol: Translation offset in the col direction (horizontal). Positive moves rightward.\n\n    Returns:\n        New PolygonAnnotation instance with translated polygon\n\n    Example:\n        &gt;&gt;&gt; ann_moved = ann.translate(10, 20)  # Move 10 pixels down, 20 pixels right\n    \"\"\"\n    # Create translation matrix (2x3 format with translation vector)\n    translation_matrix = np.array([\n        [1, 0, drow],\n        [0, 1, dcol]\n    ])\n\n    return self.transform(translation_matrix)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyebscan/","title":"eyebscan","text":""},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan","title":"<code>eyepy.core.eyebscan</code>","text":""},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan","title":"<code>EyeBscan(volume, index)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>volume</code> <code>EyeVolume</code> <p>The EyeVolume this B-scan belongs to</p> required <code>index</code> <code>int</code> <p>The index of this B-scan in the EyeVolume</p> required Source code in <code>src/eyepy/core/eyebscan.py</code> <pre><code>def __init__(self, volume: EyeVolume, index: int) -&gt; None:\n    \"\"\"\n\n    Args:\n        volume: The EyeVolume this B-scan belongs to\n        index: The index of this B-scan in the EyeVolume\n    \"\"\"\n    self.index = index\n    self.volume = volume\n\n    # Create a dict to access layers by their name for this B-scan.\n    self.layers = DynamicDefaultDict(lambda x: EyeBscanLayerAnnotation(\n        self.volume.layers[x], self.index))\n    self.area_maps = DynamicDefaultDict(\n        lambda x: self.volume.volume_maps[x].data[self.index])\n    self.slabs = DynamicDefaultDict(lambda x: EyeBscanSlabAnnotation(\n        self.volume.slabs[x], self.index))\n</code></pre>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns the B-scan data as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>B-scan data as numpy array</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.meta","title":"<code>meta</code>  <code>property</code>","text":"<p>Return the metadata for this B-scan.</p> <p>Returns:</p> Type Description <code>EyeBscanMeta</code> <p>Meta information about the B-scan</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.scale_x","title":"<code>scale_x</code>  <code>property</code>","text":"<p>Scale of the B-scan in x direction.</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.scale_y","title":"<code>scale_y</code>  <code>property</code>","text":"<p>Scale of the B-scan in y direction.</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Shape of the B-scan data.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>Shape tuple (B-scan height, B-scan width)</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.size_x","title":"<code>size_x</code>  <code>property</code>","text":"<p>Size of the B-scan in x direction.</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.size_y","title":"<code>size_y</code>  <code>property</code>","text":"<p>Size of the B-scan in y direction.</p>"},{"location":"reference/src/eyepy/core/eyebscan/#eyepy.core.eyebscan.EyeBscan.plot","title":"<code>plot(ax=None, layers=False, areas=False, slabs=False, layer_kwargs=None, area_kwargs=None, slab_kwargs=None, annotations_only=False, region=np.s_[:, :], scalebar='botleft', scalebar_kwargs=None, watermark=True)</code>","text":"<p>Plot B-scan.</p> <p>Annotations such as layers and areas can be overlaid on the image. With plt.legend() you can add a legend for the shown annotations</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If not provided plot on the current axes (plt.gca()).</p> <code>None</code> <code>layers</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all layers (default: <code>False</code>). If a list of strings is given, plot the layers with the given names.</p> <code>False</code> <code>areas</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all areas (default: <code>False</code>). If a list of strings is given, plot the areas with the given names.</p> <code>False</code> <code>slabs</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all slabs (default: <code>False</code>). If a list of strings is given, plot the slabs with the given names.</p> <code>False</code> <code>annotations_only</code> <code>bool</code> <p>If <code>True</code> do not plot the B-scan image</p> <code>False</code> <code>region</code> <code>tuple[slice, slice]</code> <p>Region of the localizer to plot (default: <code>np.s_[:, :]</code>)</p> <code>s_[:, :]</code> <code>layer_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for customizing the OCT layers. If <code>None</code> default values are used which are {\"linewidth\": 1, \"linestyle\": \"-\"}</p> <code>None</code> <code>area_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for customizing area annotions on the B-scan If <code>None</code> default values are used which are {\"alpha\": 0.5}</p> <code>None</code> <code>slab_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for customizing slab annotations on the B-scan If <code>None</code> default values are used which are {\"alpha\": 0.5}</p> <code>None</code> <code>scalebar</code> <code>Union[bool, str]</code> <p>Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or <code>False</code> (default: \"botleft\"). If <code>True</code> the scalebar is placed in the bottom left corner. You can custumize the scalebar using the <code>scalebar_kwargs</code> argument.</p> <code>'botleft'</code> <code>scalebar_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Optional keyword arguments for customizing the scalebar. Check the documentation of plot_scalebar for more information.</p> <code>None</code> <code>watermark</code> <code>bool</code> <p>If <code>True</code> plot a watermark on the image (default: <code>True</code>). When removing the watermark, please consider to cite eyepy in your publication.</p> <code>True</code> <p>Returns:     None</p> Source code in <code>src/eyepy/core/eyebscan.py</code> <pre><code>def plot(\n    self,\n    ax: Optional[plt.Axes] = None,\n    layers: Union[bool, list[str]] = False,\n    areas: Union[bool, list[str]] = False,\n    slabs: Union[bool, list[str]] = False,\n    #ascans=None,\n    layer_kwargs: Optional[dict] = None,\n    area_kwargs: Optional[dict] = None,\n    slab_kwargs: Optional[dict] = None,\n    #ascan_kwargs=None,\n    annotations_only: bool = False,\n    region: tuple[slice, slice] = np.s_[:, :],\n    scalebar: Union[bool, str] = 'botleft',\n    scalebar_kwargs: Optional[dict[str, Any]] = None,\n    watermark: bool = True,\n) -&gt; None:\n    \"\"\"Plot B-scan.\n\n    Annotations such as layers and areas can be overlaid on the image. With plt.legend() you can add a legend for the shown annotations\n\n    Args:\n        ax: Axes to plot on. If not provided plot on the current axes (plt.gca()).\n        layers: If `True` plot all layers (default: `False`). If a list of strings is given, plot the layers with the given names.\n        areas: If `True` plot all areas (default: `False`). If a list of strings is given, plot the areas with the given names.\n        slabs: If `True` plot all slabs (default: `False`). If a list of strings is given, plot the slabs with the given names.\n        annotations_only: If `True` do not plot the B-scan image\n        region: Region of the localizer to plot (default: `np.s_[:, :]`)\n        layer_kwargs: Optional keyword arguments for customizing the OCT layers. If `None` default values are used which are {\"linewidth\": 1, \"linestyle\": \"-\"}\n        area_kwargs: Optional keyword arguments for customizing area annotions on the B-scan If `None` default values are used which are {\"alpha\": 0.5}\n        slab_kwargs: Optional keyword arguments for customizing slab annotations on the B-scan If `None` default values are used which are {\"alpha\": 0.5}\n        scalebar: Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or `False` (default: \"botleft\"). If `True` the scalebar is placed in the bottom left corner. You can custumize the scalebar using the `scalebar_kwargs` argument.\n        scalebar_kwargs: Optional keyword arguments for customizing the scalebar. Check the documentation of [plot_scalebar][eyepy.core.plotting.plot_scalebar] for more information.\n        watermark: If `True` plot a watermark on the image (default: `True`). When removing the watermark, please consider to cite eyepy in your publication.\n    Returns:\n        None\n    \"\"\"\n    ax = plt.gca() if ax is None else ax\n\n    # Complete region index expression\n    y_start = region[0].start if region[0].start is not None else 0\n    y_stop = region[0].stop if region[0].stop is not None else self.shape[0]\n    x_start = region[1].start if region[1].start is not None else 0\n    x_stop = region[1].stop if region[1].stop is not None else self.shape[1]\n\n    region = np.s_[y_start:y_stop, x_start:x_stop]\n\n    if not layers:\n        layers = []\n    elif layers is True:\n        layers = list(self.volume.layers.keys())\n\n    if not areas:\n        areas = []\n    elif areas is True:\n        areas = list(self.volume.volume_maps.keys())\n\n    if not slabs:\n        slabs = []\n    elif slabs is True:\n        slabs = list(self.volume.slabs.keys())\n        # Exclude 'RET' slab from the list of slabs to plot\n        slabs = [s for s in slabs if s != 'RET']\n\n    #if ascans is None:\n    #    ascans = []\n    #elif ascans is True:\n    #    ascans = self.ascan_maps.keys()\n\n    if layer_kwargs is None:\n        layer_kwargs = config.layer_kwargs\n    else:\n        layer_kwargs = {**config.layer_kwargs, **layer_kwargs}\n\n    if area_kwargs is None:\n        area_kwargs = config.area_kwargs\n    else:\n        area_kwargs = {**config.area_kwargs, **area_kwargs}\n\n    if slab_kwargs is None:\n        slab_kwargs = config.slab_kwargs\n    else:\n        slab_kwargs = {**config.slab_kwargs, **slab_kwargs}\n\n    #if ascan_kwargs is None:\n    #    ascan_kwargs = config.area_kwargs\n    #else:\n    #    ascan_kwargs = {**config.ascan_kwargs, **ascan_kwargs}\n\n    if not annotations_only:\n        ax.imshow(self.data[region], cmap='gray')\n\n    #for ascan_annotation in ascans:\n    #    data = self.ascan_maps[ascan_annotation]\n    #    data = np.repeat(np.reshape(data, (1, -1)), self.shape[0], axis=0)\n    #    visible = np.zeros(data.shape)\n    #    visible[data] = 1.0\n    #    ax.imshow(data[region],\n    #              alpha=visible[region] * ascan_kwargs[\"alpha\"],\n    #              cmap=\"Reds\")\n\n    for area in areas:\n        data = self.area_maps[area][region]\n        visible = np.zeros(data.shape, dtype=bool)\n        visible[data != 0] = 1.0\n\n        meta = self.volume.volume_maps[area].meta\n        color = meta['color'] if 'color' in meta else 'red'\n        color = mcolors.to_rgba(color)\n        # create a 0 radius circle patch as dummy for the area label\n        patch = mpatches.Circle((0, 0), radius=0, color=color, label=area)\n        ax.add_patch(patch)\n\n        # Create plot_data by tiling the color vector over the plotting shape\n        plot_data = np.tile(np.array(color), data.shape + (1, ))\n        # Now turn the alpha channel 0 where the mask is 0 and adjust the remaining alpha\n        plot_data[..., 3] *= visible * area_kwargs['alpha']\n\n        ax.imshow(\n            plot_data,\n            interpolation='none',\n        )\n    for layer in layers:\n        color = config.layer_colors[layer]\n\n        layer_data = self.layers[layer].data\n        # Adjust layer height to plotted region\n        layer_data = layer_data - region[0].start\n        # Remove layer if outside of region\n        layer_data = layer_data[region[1].start:region[1].stop]\n        layer_data[layer_data &lt; 0] = 0\n        region_height = region[0].stop - region[0].start\n        layer_data[layer_data &gt; region_height] = region_height\n\n        ax.plot(\n            layer_data,\n            color='#' + color,\n            label=layer,\n            **layer_kwargs,\n        )\n    if slabs:\n        # Create a composite RGB image\n        composite = np.zeros((*self.data[region].shape[:2], 3))\n        overlap_count = np.zeros(self.data[region].shape[:2])\n\n        for slab in slabs:\n            color = config.slab_colors[slab]\n            color_rgb = mcolors.to_rgb('#' + color)\n\n            slab_mask = self.slabs[slab].mask\n            slab_mask = slab_mask[region]\n\n            # Add to composite where mask is True\n            mask_indices = slab_mask &gt; 0\n            composite[mask_indices, :] += np.array(color_rgb)\n            overlap_count[mask_indices] += 1\n\n        # Normalize by the actual number of overlapping slabs per pixel\n        valid_pixels = overlap_count &gt; 0\n        composite[valid_pixels, :] /= overlap_count[valid_pixels, np.newaxis]\n\n        alpha = slab_kwargs.pop('alpha', 0.5)\n\n        # Add alpha channel to composite\n        composite_with_alpha = np.zeros((*composite.shape[:2], 4))\n        composite_with_alpha[..., :3] = composite\n        composite_with_alpha[..., 3] = valid_pixels * alpha\n\n        # pop alpha from slab_kwargs since we already added it to the composite\n        slab_kwargs.pop('alpha', None)\n        ax.imshow(composite_with_alpha,\n                  **slab_kwargs)\n\n    # Make sure tick labels match the image region\n    y_start = region[0].start if region[0].start is not None else 0\n    x_start = region[1].start if region[1].start is not None else 0\n    y_end = region[0].stop if region[0].stop is not None else self.shape[0]\n    x_end = region[1].stop if region[1].stop is not None else self.shape[1]\n\n    # Ticks are not clipped to the image region. Clip them here.\n    yticks = ax.get_yticks()\n    yticks = yticks[np.nonzero(\n        np.logical_and(yticks &gt;= 0, yticks &lt;= y_end - y_start - 1))]\n    xticks = ax.get_xticks()\n    xticks = xticks[np.nonzero(\n        np.logical_and(xticks &gt;= 0, xticks &lt;= x_end - x_start - 1))]\n\n    # Set clipped ticks (this is only necessary because we change the labels later)\n    ax.set_yticks(yticks)\n    ax.set_xticks(xticks)\n\n    # Set labels to ticks + start of the region as an offset\n    ax.set_yticklabels([str(int(t + y_start)) for t in yticks])\n    ax.set_xticklabels([str(int(t + x_start)) for t in xticks])\n\n    if scalebar:\n        if scalebar_kwargs is None:\n            scalebar_kwargs = {}\n\n        scale_unit = self.volume.meta['scale_unit']\n        scalebar_kwargs = {\n            **{\n                'scale': (self.scale_x, self.scale_y),\n                'scale_unit': scale_unit\n            },\n            **scalebar_kwargs\n        }\n\n        if not 'pos' in scalebar_kwargs:\n            sx = x_end - x_start\n            sy = y_end - y_start\n\n            if scalebar is True:\n                scalebar = 'botleft'\n\n            if scalebar == 'botleft':\n                scalebar_kwargs['pos'] = (sx - 0.95 * sx, 0.95 * sy)\n            elif scalebar == 'botright':\n                scalebar_kwargs['pos'] = (0.95 * sx, 0.95 * sy)\n                scalebar_kwargs['flip_x'] = True\n            elif scalebar == 'topleft':\n                scalebar_kwargs['pos'] = (sx - 0.95 * sx, 0.05 * sy)\n                scalebar_kwargs['flip_y'] = True\n            elif scalebar == 'topright':\n                scalebar_kwargs['pos'] = (0.95 * sx, 0.05 * sy)\n                scalebar_kwargs['flip_x'] = True\n                scalebar_kwargs['flip_y'] = True\n\n        plot_scalebar(ax=ax, **scalebar_kwargs)\n\n    if watermark:\n        plot_watermark(ax)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/","title":"eyeenface","text":""},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface","title":"<code>eyepy.core.eyeenface</code>","text":""},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface","title":"<code>EyeEnface(data, meta, optic_disc=None, fovea=None)</code>","text":"<p>Enface (2D projection) image with optional anatomical annotations.</p> <p>Coordinate System Convention: EyeEnface uses (row, col) image pixel coordinates: - row: vertical axis, increases downward (corresponds to y) - col: horizontal axis, increases rightward (corresponds to x)</p> <p>All image operations (scaling, translation, rotation) work in this space. Physical coordinates (x, y) in millimeters are converted to (col, row) format when needed for internal calculations.</p> <p>Annotations (optic disc, fovea, pixel annotations) are stored and transformed in (row, col) coordinates.</p> <p>Initialize EyeEnface.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray[int64]</code> <p>Enface image data</p> required <code>meta</code> <code>EyeEnfaceMeta</code> <p>Metadata for the enface image</p> required <code>optic_disc</code> <code>Optional[EyeEnfaceOpticDiscAnnotation]</code> <p>Optional EyeEnfaceOpticDiscAnnotation</p> <code>None</code> <code>fovea</code> <code>Optional[EyeEnfaceFoveaAnnotation]</code> <p>Optional EyeEnfaceFoveaAnnotation</p> <code>None</code> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def __init__(self, data: npt.NDArray[np.int64],\n             meta: EyeEnfaceMeta,\n             optic_disc: Optional[EyeEnfaceOpticDiscAnnotation] = None,\n             fovea: Optional[EyeEnfaceFoveaAnnotation] = None) -&gt; None:\n    \"\"\"Initialize EyeEnface.\n\n    Args:\n        data: Enface image data\n        meta: Metadata for the enface image\n        optic_disc: Optional EyeEnfaceOpticDiscAnnotation\n        fovea: Optional EyeEnfaceFoveaAnnotation\n    \"\"\"\n    self.data = data\n    self._area_maps = []\n    self.meta = meta\n    self._optic_disc = optic_disc\n    self._fovea = fovea\n\n    # Validate and set laterality if both optic disc and fovea are provided\n    if optic_disc is not None and fovea is not None:\n        self._infer_and_validate_laterality()\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.area_maps","title":"<code>area_maps</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.fovea","title":"<code>fovea</code>  <code>property</code> <code>writable</code>","text":"<p>Get the fovea annotation.</p> <p>Returns:</p> Type Description <code>Optional[EyeEnfaceFoveaAnnotation]</code> <p>The fovea annotation or None if not set</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.laterality","title":"<code>laterality</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.optic_disc","title":"<code>optic_disc</code>  <code>property</code> <code>writable</code>","text":"<p>Get the optic disc annotation.</p> <p>Returns:</p> Type Description <code>Optional[EyeEnfaceOpticDiscAnnotation]</code> <p>The optic disc annotation or None if not set</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.scale_unit","title":"<code>scale_unit</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.scale_x","title":"<code>scale_x</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.scale_y","title":"<code>scale_y</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.size_x","title":"<code>size_x</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.size_y","title":"<code>size_y</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.add_area_annotation","title":"<code>add_area_annotation(area_map=None, meta=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>area_map</code> <code>Optional[NDArray[bool_]]</code> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <code>None</code> <code>**kwargs</code> <code>Any</code> <code>{}</code> <p>Returns:</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def add_area_annotation(self,\n                        area_map: Optional[npt.NDArray[np.bool_]] = None,\n                        meta: Optional[dict] = None,\n                        **kwargs: Any) -&gt; EyeEnfacePixelAnnotation:\n    \"\"\"\n\n    Args:\n        area_map:\n        meta:\n        **kwargs:\n\n    Returns:\n\n    \"\"\"\n    if meta is None:\n        meta = {}\n    meta.update(**kwargs)\n    area_annotation = EyeEnfacePixelAnnotation(self, area_map, meta)\n    self._area_maps.append(area_annotation)\n    return area_annotation\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.plot","title":"<code>plot(ax=None, region=np.s_[:, :], scalebar='botleft', scalebar_kwargs=None, watermark=True, areas=True, plot_optic_disc=True, plot_fovea=True, area_kwargs=None, optic_disc_kwargs=None, fovea_kwargs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If not provided plot on the current axes (plt.gca()).</p> <code>None</code> <code>region</code> <code>tuple[slice, slice]</code> <p>Region of the localizer to plot (default: <code>np.s_[:, :]</code>)</p> <code>s_[:, :]</code> <code>scalebar</code> <code>Union[bool, str]</code> <p>Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or <code>False</code> (default: \"botleft\"). If <code>True</code> the scalebar is placed in the bottom left corner. You can custumize the scalebar using the <code>scalebar_kwargs</code> argument.</p> <code>'botleft'</code> <code>scalebar_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Optional keyword arguments for customizing the scalebar. Check the documentation of plot_scalebar for more information.</p> <code>None</code> <code>watermark</code> <code>bool</code> <p>If <code>True</code> plot a watermark on the image (default: <code>True</code>). When removing the watermark, please consider to cite eyepy in your publication.</p> <code>True</code> <code>areas</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all area annotations (default: <code>True</code>). If a list of strings is given, plot the area annotations with the given names.</p> <code>True</code> <code>plot_optic_disc</code> <code>bool</code> <p>If <code>True</code> and optic_disc is available, plot the optic disc annotation (default: <code>True</code>).</p> <code>True</code> <code>plot_fovea</code> <code>bool</code> <p>If <code>True</code> and fovea is available, plot the fovea annotation (default: <code>True</code>).</p> <code>True</code> <code>area_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Optional keyword arguments for customizing the area annotations (alpha, etc.).</p> <code>None</code> <code>optic_disc_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Optional keyword arguments for customizing the optic disc plot (color, linewidth, etc.).</p> <code>None</code> <code>fovea_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Optional keyword arguments for customizing the fovea plot (color, marker, markersize, etc.).</p> <code>None</code> <p>Returns:     None</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def plot(\n    self,\n    ax: Optional[plt.Axes] = None,\n    region: tuple[slice, slice] = np.s_[:, :],\n    scalebar: Union[bool, str] = 'botleft',\n    scalebar_kwargs: Optional[dict[str, Any]] = None,\n    watermark: bool = True,\n    areas: Union[bool, list[str]] = True,\n    plot_optic_disc: bool = True,\n    plot_fovea: bool = True,\n    area_kwargs: Optional[dict[str, Any]] = None,\n    optic_disc_kwargs: Optional[dict[str, Any]] = None,\n    fovea_kwargs: Optional[dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"\n\n    Args:\n        ax: Axes to plot on. If not provided plot on the current axes (plt.gca()).\n        region: Region of the localizer to plot (default: `np.s_[:, :]`)\n        scalebar: Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or `False` (default: \"botleft\"). If `True` the scalebar is placed in the bottom left corner. You can custumize the scalebar using the `scalebar_kwargs` argument.\n        scalebar_kwargs: Optional keyword arguments for customizing the scalebar. Check the documentation of [plot_scalebar][eyepy.core.plotting.plot_scalebar] for more information.\n        watermark: If `True` plot a watermark on the image (default: `True`). When removing the watermark, please consider to cite eyepy in your publication.\n        areas: If `True` plot all area annotations (default: `True`). If a list of strings is given, plot the area annotations with the given names.\n        plot_optic_disc: If `True` and optic_disc is available, plot the optic disc annotation (default: `True`).\n        plot_fovea: If `True` and fovea is available, plot the fovea annotation (default: `True`).\n        area_kwargs: Optional keyword arguments for customizing the area annotations (alpha, etc.).\n        optic_disc_kwargs: Optional keyword arguments for customizing the optic disc plot (color, linewidth, etc.).\n        fovea_kwargs: Optional keyword arguments for customizing the fovea plot (color, marker, markersize, etc.).\n    Returns:\n        None\n\n    \"\"\"\n    ax = plt.gca() if ax is None else ax\n    vmin = np.min(self.data)\n    vmax = np.max(self.data)\n\n    ax.imshow(self.data[region], cmap='gray', vmin=vmin, vmax=vmax)\n\n    # Make sure tick labels match the image region\n    y_start = region[0].start if region[0].start is not None else 0\n    x_start = region[1].start if region[1].start is not None else 0\n    y_end = region[0].stop if region[0].stop is not None else self.size_y\n    x_end = region[1].stop if region[1].stop is not None else self.size_x\n\n    # Ticks are not clipped to the image region. Clip them here.\n    yticks = ax.get_yticks()\n    yticks = yticks[np.nonzero(\n        np.logical_and(yticks &gt;= 0, yticks &lt;= y_end - y_start - 1))]\n    xticks = ax.get_xticks()\n    xticks = xticks[np.nonzero(\n        np.logical_and(xticks &gt;= 0, xticks &lt;= x_end - x_start - 1))]\n\n    # Set clipped ticks (this is only necessary because we change the labels later)\n    ax.set_yticks(yticks)\n    ax.set_xticks(xticks)\n\n    # Set labels to ticks + start of the region as an offset\n    ax.set_yticklabels([str(int(t + y_start)) for t in yticks])\n    ax.set_xticklabels([str(int(t + x_start)) for t in xticks])\n\n    if scalebar:\n        if scalebar_kwargs is None:\n            scalebar_kwargs = {}\n\n        scale_unit = self.meta['scale_unit']\n        scalebar_kwargs = {\n            **{\n                'scale': (self.scale_x, self.scale_y),\n                'scale_unit': scale_unit\n            },\n            **scalebar_kwargs\n        }\n\n        if not 'pos' in scalebar_kwargs:\n            sx = x_end - x_start\n            sy = y_end - y_start\n\n            if scalebar is True:\n                scalebar = 'botleft'\n\n            if scalebar == 'botleft':\n                scalebar_kwargs['pos'] = (sx - 0.95 * sx, 0.95 * sy)\n            elif scalebar == 'botright':\n                scalebar_kwargs['pos'] = (0.95 * sx, 0.95 * sy)\n                scalebar_kwargs['flip_x'] = True\n            elif scalebar == 'topleft':\n                scalebar_kwargs['pos'] = (sx - 0.95 * sx, 0.05 * sy)\n                scalebar_kwargs['flip_y'] = True\n            elif scalebar == 'topright':\n                scalebar_kwargs['pos'] = (0.95 * sx, 0.05 * sy)\n                scalebar_kwargs['flip_x'] = True\n                scalebar_kwargs['flip_y'] = True\n\n        plot_scalebar(ax=ax, **scalebar_kwargs)\n\n    if watermark:\n        plot_watermark(ax)\n\n    # Handle areas parameter\n    if not areas:\n        areas_to_plot = []\n    elif areas is True:\n        areas_to_plot = list(self.area_maps.keys())\n    else:\n        areas_to_plot = areas\n\n    # Set default area_kwargs if not provided\n    if area_kwargs is None:\n        area_kwargs = {'alpha': 0.5}\n\n    # Plot area annotations\n    for area_name in areas_to_plot:\n        if area_name not in self.area_maps:\n            continue\n\n        area_annotation = self.area_maps[area_name]\n        data = area_annotation.data[region]\n        visible = np.zeros(data.shape, dtype=bool)\n        visible[data != 0] = 1.0\n\n        # Get color from metadata or use default\n        meta = area_annotation.meta\n        color = meta.get('color', 'red')\n        color = mcolors.to_rgba(color)\n\n        # Create a 0 radius circle patch as dummy for the area label\n        patch = mpatches.Circle((0, 0), radius=0, color=color, label=area_name)\n        ax.add_patch(patch)\n\n        # Create plot_data by tiling the color vector over the plotting shape\n        plot_data = np.tile(np.array(color), data.shape + (1, ))\n        # Now turn the alpha channel 0 where the mask is 0 and adjust the remaining alpha\n        plot_data[..., 3] *= visible * area_kwargs.get('alpha', 0.5)\n\n        ax.imshow(\n            plot_data,\n            interpolation='none',\n        )\n\n    # Plot optic disc if available\n    if plot_optic_disc and self.optic_disc is not None:\n        if optic_disc_kwargs is None:\n            optic_disc_kwargs = {}\n\n        # Calculate region offset\n        y_start = region[0].start if region[0].start is not None else 0\n        x_start = region[1].start if region[1].start is not None else 0\n\n        # Delegate to the optic disc's plot method\n        self.optic_disc.plot(ax=ax, offset=(x_start, y_start), **optic_disc_kwargs)\n\n    # Plot fovea if available\n    if plot_fovea and self.fovea is not None:\n        if fovea_kwargs is None:\n            fovea_kwargs = {}\n\n        # Calculate region offset\n        y_start = region[0].start if region[0].start is not None else 0\n        x_start = region[1].start if region[1].start is not None else 0\n\n        # Delegate to the fovea's plot method\n        self.fovea.plot(ax=ax, offset=(x_start, y_start), **fovea_kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.rotate","title":"<code>rotate(angle, center=None, order=1, mode='constant', cval=0.0)</code>","text":"<p>Rotate the enface image and all annotations.</p> <p>Returns a new EyeEnface instance with rotated image data and transformed annotations. The original EyeEnface remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>Rotation angle in degrees (positive = counter-clockwise)</p> required <code>center</code> <code>Optional[tuple[float, float]]</code> <p>Center of rotation (row, col). If None, uses image center</p> <code>None</code> <code>order</code> <code>int</code> <p>The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)</p> <code>1</code> <code>mode</code> <code>str</code> <p>How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')</p> <code>'constant'</code> <code>cval</code> <code>float</code> <p>Value used for points outside the boundaries if mode='constant'</p> <code>0.0</code> <p>Returns:</p> Type Description <code>'EyeEnface'</code> <p>New EyeEnface instance with rotated data and annotations</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def rotate(self, angle: float, center: Optional[tuple[float, float]] = None,\n           order: int = 1, mode: str = 'constant', cval: float = 0.0) -&gt; 'EyeEnface':\n    \"\"\"Rotate the enface image and all annotations.\n\n    Returns a new EyeEnface instance with rotated image data and transformed annotations.\n    The original EyeEnface remains unchanged.\n\n    Args:\n        angle: Rotation angle in degrees (positive = counter-clockwise)\n        center: Center of rotation (row, col). If None, uses image center\n        order: The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)\n        mode: How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')\n        cval: Value used for points outside the boundaries if mode='constant'\n\n    Returns:\n        New EyeEnface instance with rotated data and annotations\n    \"\"\"\n    if center is None:\n        center = (self.shape[0] / 2, self.shape[1] / 2)\n\n    # Build rotation matrix in (row, col) coordinates for counter-clockwise rotation\n    # Standard mathematical rotation: positive angle = counter-clockwise\n    # The standard counter-clockwise rotation matrix is:\n    # [[cos(\u03b8), -sin(\u03b8)], [sin(\u03b8), cos(\u03b8)]]\n    # But with (row, col) format where row increases downward (y-axis flipped),\n    # we need: [[cos(\u03b8), sin(\u03b8)], [-sin(\u03b8), cos(\u03b8)]] to get counter-clockwise rotation\n    center_row, center_col = center\n    angle_rad = np.deg2rad(angle)\n    cos_a = np.cos(angle_rad)\n    sin_a = np.sin(angle_rad)\n\n    # Rotation matrix for (row, col) format with counter-clockwise rotation around (center_row, center_col)\n    matrix_rowcol = np.array([\n        [cos_a, -sin_a, center_row - cos_a * center_row + sin_a * center_col],\n        [sin_a, cos_a, center_col - sin_a * center_row - cos_a * center_col],\n        [0, 0, 1]\n    ])\n\n    return self.transform(matrix_rowcol, order=order, mode=mode, cval=cval)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.scale","title":"<code>scale(scale_y, scale_x, order=1, mode='constant', cval=0.0)</code>","text":"<p>Scale the enface image and all annotations.</p> <p>Returns a new EyeEnface instance with scaled image data and transformed annotations. The original EyeEnface remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>scale_y</code> <code>float</code> <p>Scaling factor for the y-axis</p> required <code>scale_x</code> <code>float</code> <p>Scaling factor for the x-axis</p> required <code>order</code> <code>int</code> <p>The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)</p> <code>1</code> <code>mode</code> <code>str</code> <p>How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')</p> <code>'constant'</code> <code>cval</code> <code>float</code> <p>Value used for points outside the boundaries if mode='constant'</p> <code>0.0</code> <p>Returns:</p> Type Description <code>'EyeEnface'</code> <p>New EyeEnface instance with scaled data and annotations</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def scale(self, scale_y: float, scale_x: float,\n          order: int = 1, mode: str = 'constant', cval: float = 0.0) -&gt; 'EyeEnface':\n    \"\"\"Scale the enface image and all annotations.\n\n    Returns a new EyeEnface instance with scaled image data and transformed annotations.\n    The original EyeEnface remains unchanged.\n\n    Args:\n        scale_y: Scaling factor for the y-axis\n        scale_x: Scaling factor for the x-axis\n        order: The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)\n        mode: How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')\n        cval: Value used for points outside the boundaries if mode='constant'\n\n    Returns:\n        New EyeEnface instance with scaled data and annotations\n    \"\"\"\n    # Create affine transformation matrix for scaling\n    matrix = np.array([\n        [scale_y, 0, 0],\n        [0, scale_x, 0],\n        [0, 0, 1]\n    ])\n\n    # Calculate output shape\n    output_shape = (int(self.shape[0] * scale_y), int(self.shape[1] * scale_x))\n\n    return self.transform(matrix, output_shape=output_shape, order=order, mode=mode, cval=cval)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.standard_rotation","title":"<code>standard_rotation(order=1, mode='constant', cval=0.0)</code>","text":"<p>Rotate the enface to align optic disc and fovea centers horizontally.</p> <p>This method rotates the image so that the optic disc and fovea centers lie on the same horizontal line. The rotation is performed around the midpoint between the OD and fovea, preserving their relative positions. The rotation direction depends on the laterality: - For right eyes (OD): optic disc on the right, fovea on the left - For left eyes (OS): optic disc on the left, fovea on the right</p> <p>This creates a standardized orientation useful for comparison across different images.</p> <p>Requires both optic_disc and fovea annotations to be present.</p> <p>Parameters:</p> Name Type Description Default <code>order</code> <code>int</code> <p>The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)</p> <code>1</code> <code>mode</code> <code>str</code> <p>How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')</p> <code>'constant'</code> <code>cval</code> <code>float</code> <p>Value used for points outside the boundaries if mode='constant'</p> <code>0.0</code> <p>Returns:</p> Type Description <code>'EyeEnface'</code> <p>New EyeEnface instance with standardized rotation</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If optic_disc or fovea annotations are missing</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def standard_rotation(self, order: int = 1, mode: str = 'constant', cval: float = 0.0) -&gt; 'EyeEnface':\n    \"\"\"Rotate the enface to align optic disc and fovea centers horizontally.\n\n    This method rotates the image so that the optic disc and fovea centers lie on the\n    same horizontal line. The rotation is performed around the midpoint between the OD\n    and fovea, preserving their relative positions. The rotation direction depends on\n    the laterality:\n    - For right eyes (OD): optic disc on the right, fovea on the left\n    - For left eyes (OS): optic disc on the left, fovea on the right\n\n    This creates a standardized orientation useful for comparison across different images.\n\n    Requires both optic_disc and fovea annotations to be present.\n\n    Args:\n        order: The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)\n        mode: How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')\n        cval: Value used for points outside the boundaries if mode='constant'\n\n    Returns:\n        New EyeEnface instance with standardized rotation\n\n    Raises:\n        ValueError: If optic_disc or fovea annotations are missing\n    \"\"\"\n    if self._optic_disc is None:\n        raise ValueError('standard_rotation requires optic_disc annotation')\n    if self._fovea is None:\n        raise ValueError('standard_rotation requires fovea annotation')\n\n    # Get centers of optic disc and fovea\n    od_center = self.optic_disc.center\n    fovea_center = self.fovea.center\n\n    # Determine laterality from metadata or infer from positions\n    laterality = self.meta.get('laterality', None)\n\n    # Calculate vector from OD to fovea (in row, col coordinates)\n    # center returns (row, col) tuples\n    d_row = fovea_center[0] - od_center[0]\n    d_col = fovea_center[1] - od_center[1]\n\n    # Calculate the current angle of the OD-to-fovea line\n    # In (row, col) space, horizontal line has d_row=0, so angle from horizontal is arctan2(d_row, d_col)\n    # Positive angle means counter-clockwise from positive column direction (pointing right)\n    current_angle_rad = np.arctan2(d_row, d_col)\n\n    # Determine target angle based on laterality (in row, col coordinates)\n    # For OD (right eye): OD on right, fovea on left -&gt; line points left (180\u00b0)\n    # For OS (left eye): OD on left, fovea on right -&gt; line points right (0\u00b0)\n    if laterality is not None:\n        laterality_upper = str(laterality).upper()\n        if laterality_upper in ['OD', 'R', 'RIGHT']:\n            target_angle_rad = np.pi  # Pointing left\n        elif laterality_upper in ['OS', 'L', 'LEFT']:\n            target_angle_rad = 0.0  # Pointing right\n        else:\n            # Unknown laterality, default to horizontal alignment with fovea to the right\n            target_angle_rad = 0.0\n    else:\n        # No laterality info, align horizontally with fovea to the right\n        target_angle_rad = 0.0\n\n    # Calculate rotation angle needed\n    rotation_angle_rad = target_angle_rad - current_angle_rad\n\n    # Normalize to [-\u03c0, \u03c0] to take the shortest rotation path\n    rotation_angle_rad = np.arctan2(np.sin(rotation_angle_rad), np.cos(rotation_angle_rad))\n    rotation_angle_deg = np.rad2deg(rotation_angle_rad)\n\n    # Rotate around the midpoint between OD and fovea to keep them centered\n    # This preserves their relative position better than rotating around image center\n    midpoint_row = (od_center[0] + fovea_center[0]) / 2\n    midpoint_col = (od_center[1] + fovea_center[1]) / 2\n    center = (midpoint_row, midpoint_col)\n\n    return self.rotate(-rotation_angle_deg, center=center, order=order, mode=mode, cval=cval)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.transform","title":"<code>transform(matrix, output_shape=None, order=1, mode='constant', cval=0.0)</code>","text":"<p>Apply an affine transformation to the enface image and all annotations.</p> <p>Returns a new EyeEnface instance with transformed image data and annotations. The original EyeEnface remains unchanged. The metadata is updated to reflect any scaling in the transformation.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray[float64]</code> <p>3x3 affine transformation matrix in homogeneous coordinates or 2x3 matrix</p> required <code>output_shape</code> <code>Optional[tuple[int, int]]</code> <p>Shape of the output image (height, width). If None, uses input shape</p> <code>None</code> <code>order</code> <code>int</code> <p>The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)</p> <code>1</code> <code>mode</code> <code>str</code> <p>How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')</p> <code>'constant'</code> <code>cval</code> <code>float</code> <p>Value used for points outside the boundaries if mode='constant'</p> <code>0.0</code> <p>Returns:</p> Type Description <code>'EyeEnface'</code> <p>New EyeEnface instance with transformed data and annotations</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def transform(self, matrix: npt.NDArray[np.float64],\n              output_shape: Optional[tuple[int, int]] = None,\n              order: int = 1, mode: str = 'constant', cval: float = 0.0) -&gt; 'EyeEnface':\n    \"\"\"Apply an affine transformation to the enface image and all annotations.\n\n    Returns a new EyeEnface instance with transformed image data and annotations.\n    The original EyeEnface remains unchanged. The metadata is updated to reflect\n    any scaling in the transformation.\n\n    Args:\n        matrix: 3x3 affine transformation matrix in homogeneous coordinates or 2x3 matrix\n        output_shape: Shape of the output image (height, width). If None, uses input shape\n        order: The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)\n        mode: How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')\n        cval: Value used for points outside the boundaries if mode='constant'\n\n    Returns:\n        New EyeEnface instance with transformed data and annotations\n    \"\"\"\n    if output_shape is None:\n        output_shape = self.shape\n\n    # Convert 3x3 to 2x3 for annotations if needed\n    if matrix.shape == (3, 3):\n        # Matrix is in (row, col) format - use directly for annotations\n        annotation_matrix = matrix[:2, :]\n    elif matrix.shape == (2, 3):\n        annotation_matrix = matrix\n    else:\n        raise ValueError('Matrix must be 3x3 or 2x3')\n\n    # For image transformation with skimage, we need to convert to (x, y) format\n    # skimage's AffineTransform works with (x, y) format, not (row, col)\n    # So we need to swap the matrix dimensions: swap rows and columns\n    if matrix.shape == (2, 3):\n        # Convert 2x3 to 3x3\n        full_matrix = np.vstack([matrix, [0, 0, 1]])\n    else:\n        full_matrix = matrix\n\n    # Convert from (row, col) to (x, y) by swapping the matrix rows/cols\n    # If M transforms (row, col) -&gt; (row', col'), then for (x, y) = (col, row):\n    # [row']   [a  b  tx]   [row]       [col']   [b  a  ty]   [col]\n    # [col'] = [c  d  ty] * [col]  =&gt;   [row'] = [d  c  tx] * [row]\n    skimage_matrix = np.array([\n        [full_matrix[1, 1], full_matrix[1, 0], full_matrix[1, 2]],\n        [full_matrix[0, 1], full_matrix[0, 0], full_matrix[0, 2]],\n        [0, 0, 1]\n    ])\n\n    # Extract scaling factors from the transformation matrix\n    # The scaling factors are the norms of the first two columns\n    scale_y = np.linalg.norm(annotation_matrix[:, 0])\n    scale_x = np.linalg.norm(annotation_matrix[:, 1])\n\n    # Create updated metadata with adjusted scale_x and scale_y\n    # When the image is scaled up, each pixel represents less physical distance\n    # Only update metadata if it's a real EyeEnfaceMeta object, not a mock\n    if isinstance(self.meta, EyeEnfaceMeta):\n        # Real EyeEnfaceMeta object - use the copy() method\n        updated_meta = self.meta.copy()\n        if 'scale_x' in updated_meta:\n            updated_meta['scale_x'] = updated_meta['scale_x'] / scale_x\n        if 'scale_y' in updated_meta:\n            updated_meta['scale_y'] = updated_meta['scale_y'] / scale_y\n    else:\n        # Mock or other type - just reuse it\n        updated_meta = self.meta\n\n    # Create AffineTransform from matrix\n    # Note: scikit-image uses inverse matrix convention\n    tform = transform.AffineTransform(matrix=skimage_matrix)\n\n    # Transform the image data\n    transformed_data = transform.warp(\n        self.data,\n        tform.inverse,\n        output_shape=output_shape,\n        order=order,\n        mode=mode,\n        cval=cval,\n        preserve_range=True\n    ).astype(self.data.dtype)\n\n    # Transform annotations\n    transformed_optic_disc = self._optic_disc.transform(annotation_matrix) if self._optic_disc is not None else None\n    transformed_fovea = self._fovea.transform(annotation_matrix) if self._fovea is not None else None\n\n    # Create new EyeEnface instance with updated metadata\n    new_enface = EyeEnface(\n        data=transformed_data,\n        meta=updated_meta,\n        optic_disc=transformed_optic_disc,\n        fovea=transformed_fovea\n    )\n\n    # Transform area maps\n    for area_map in self._area_maps:\n        if area_map.data is not None:\n            transformed_area_data = transform.warp(\n                area_map.data.astype(float),\n                tform.inverse,\n                output_shape=output_shape,\n                order=0,  # Use nearest neighbor for binary masks\n                mode=mode,\n                cval=cval,\n                preserve_range=True\n            ).astype(bool)\n        else:\n            transformed_area_data = None\n\n        new_area_map = EyeEnfacePixelAnnotation(\n            new_enface,\n            transformed_area_data,\n            area_map.meta.copy()\n        )\n        new_enface._area_maps.append(new_area_map)\n\n    return new_enface\n</code></pre>"},{"location":"reference/src/eyepy/core/eyeenface/#eyepy.core.eyeenface.EyeEnface.translate","title":"<code>translate(drow, dcol, order=1, mode='constant', cval=0.0)</code>","text":"<p>Translate the enface image and all annotations.</p> <p>Returns a new EyeEnface instance with translated image data and transformed annotations. The original EyeEnface remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>drow</code> <code>float</code> <p>Translation offset in the row direction (vertical, pixels)</p> required <code>dcol</code> <code>float</code> <p>Translation offset in the col direction (horizontal, pixels)</p> required <code>order</code> <code>int</code> <p>The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)</p> <code>1</code> <code>mode</code> <code>str</code> <p>How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')</p> <code>'constant'</code> <code>cval</code> <code>float</code> <p>Value used for points outside the boundaries if mode='constant'</p> <code>0.0</code> <p>Returns:</p> Type Description <code>'EyeEnface'</code> <p>New EyeEnface instance with translated data and annotations</p> Source code in <code>src/eyepy/core/eyeenface.py</code> <pre><code>def translate(self, drow: float, dcol: float,\n              order: int = 1, mode: str = 'constant', cval: float = 0.0) -&gt; 'EyeEnface':\n    \"\"\"Translate the enface image and all annotations.\n\n    Returns a new EyeEnface instance with translated image data and transformed annotations.\n    The original EyeEnface remains unchanged.\n\n    Args:\n        drow: Translation offset in the row direction (vertical, pixels)\n        dcol: Translation offset in the col direction (horizontal, pixels)\n        order: The order of interpolation (0=nearest, 1=bilinear, 3=bicubic, default: 1)\n        mode: How to handle values outside the boundaries ('constant', 'nearest', 'reflect', 'wrap')\n        cval: Value used for points outside the boundaries if mode='constant'\n\n    Returns:\n        New EyeEnface instance with translated data and annotations\n    \"\"\"\n    # Create affine transformation matrix for translation\n    # Matrix format: [[1, 0, drow], [0, 1, dcol], [0, 0, 1]]\n    matrix = np.array([\n        [1, 0, drow],\n        [0, 1, dcol],\n        [0, 0, 1]\n    ])\n\n    return self.transform(matrix, order=order, mode=mode, cval=cval)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/","title":"eyemeta","text":""},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta","title":"<code>eyepy.core.eyemeta</code>","text":""},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeBscanMeta","title":"<code>EyeBscanMeta(start_pos, end_pos, pos_unit, **kwargs)</code>","text":"<p>               Bases: <code>EyeMeta</code></p> <p>A dict with required keys to hold meta data for OCT B-scans.</p> <p>Parameters:</p> Name Type Description Default <code>start_pos</code> <code>tuple[float, float]</code> <p>B-scan start position on the enface (x, y) in physical coordinates, not pixel indices</p> required <code>end_pos</code> <code>tuple[float, float]</code> <p>B-scan end position on the enface (x, y) in physical coordinates, not pixel indices</p> required <code>pos_unit</code> <code>str</code> <p>Unit of the positions (e.g., 'mm')</p> required <code>**kwargs</code> <code>Any</code> <p>Additional metadata</p> <code>{}</code> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def __init__(\n    self,\n    start_pos: tuple[float, float],\n    end_pos: tuple[float, float],\n    pos_unit: str,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"A dict with required keys to hold meta data for OCT B-scans.\n\n    Args:\n        start_pos: B-scan start position on the enface (x, y) in physical coordinates, not pixel indices\n        end_pos: B-scan end position on the enface (x, y) in physical coordinates, not pixel indices\n        pos_unit: Unit of the positions (e.g., 'mm')\n        **kwargs: Additional metadata\n    \"\"\"\n    start_pos = tuple(start_pos)\n    end_pos = tuple(end_pos)\n    super().__init__(start_pos=start_pos,\n                     end_pos=end_pos,\n                     pos_unit=pos_unit,\n                     **kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeEnfaceMeta","title":"<code>EyeEnfaceMeta(scale_x, scale_y, scale_unit, **kwargs)</code>","text":"<p>               Bases: <code>EyeMeta</code></p> <p>A dict with required keys to hold meta data for enface images of the eye.</p> <p>Parameters:</p> Name Type Description Default <code>scale_x</code> <code>float</code> <p>Horizontal scale of the enface pixels</p> required <code>scale_y</code> <code>float</code> <p>Vertical scale of the enface pixels</p> required <code>scale_unit</code> <code>str</code> <p>Unit of the scale. e.g. \u00b5m if scale is given in \u00b5m/pixel</p> required <code>**kwargs</code> <code>Any</code> <code>{}</code> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def __init__(self, scale_x: float, scale_y: float, scale_unit: str,\n             **kwargs: Any) -&gt; None:\n    \"\"\"A dict with required keys to hold meta data for enface images of the\n    eye.\n\n    Args:\n        scale_x: Horizontal scale of the enface pixels\n        scale_y: Vertical scale of the enface pixels\n        scale_unit: Unit of the scale. e.g. \u00b5m if scale is given in \u00b5m/pixel\n        **kwargs:\n    \"\"\"\n    super().__init__(scale_x=scale_x,\n                     scale_y=scale_y,\n                     scale_unit=scale_unit,\n                     **kwargs)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeEnfaceMeta.copy","title":"<code>copy()</code>","text":"<p>Create a shallow copy of this enface metadata object.</p> <p>Creates a new instance with the same metadata. Note that this is a shallow copy - the dictionary values themselves are not deeply copied. This is typically sufficient since metadata values are usually primitives (int, float, str) or immutable objects (datetime).</p> <p>Returns:</p> Type Description <code>'EyeEnfaceMeta'</code> <p>New EyeEnfaceMeta instance with the same data</p> Example <p>meta = EyeEnfaceMeta(scale_x=10.0, scale_y=10.0, scale_unit='\u00b5m') copied = meta.copy() copied['scale_x'] = 20.0 print(meta['scale_x'])  # Still 10.0</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def copy(self) -&gt; 'EyeEnfaceMeta':\n    \"\"\"Create a shallow copy of this enface metadata object.\n\n    Creates a new instance with the same metadata. Note that this is a\n    shallow copy - the dictionary values themselves are not deeply copied.\n    This is typically sufficient since metadata values are usually\n    primitives (int, float, str) or immutable objects (datetime).\n\n    Returns:\n        New EyeEnfaceMeta instance with the same data\n\n    Example:\n        &gt;&gt;&gt; meta = EyeEnfaceMeta(scale_x=10.0, scale_y=10.0, scale_unit='\u00b5m')\n        &gt;&gt;&gt; copied = meta.copy()\n        &gt;&gt;&gt; copied['scale_x'] = 20.0\n        &gt;&gt;&gt; print(meta['scale_x'])  # Still 10.0\n    \"\"\"\n    return self.__class__(**dict(self._store))\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeEnfaceMeta.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create an EyeEnfaceMeta instance from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing metadata key-value pairs</p> required <p>Returns:</p> Type Description <code>'EyeEnfaceMeta'</code> <p>New EyeEnfaceMeta instance</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; 'EyeEnfaceMeta':\n    \"\"\"Create an EyeEnfaceMeta instance from a dictionary.\n\n    Args:\n        data: Dictionary containing metadata key-value pairs\n\n    Returns:\n        New EyeEnfaceMeta instance\n    \"\"\"\n    for key in ['visit_date', 'exam_time']:\n        if key in data.keys() and data[key] is not None:\n            data[key] = datetime.datetime.fromisoformat(data[key])\n    return cls(**data)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeMeta","title":"<code>EyeMeta(*args, **kwargs)</code>","text":"<p>               Bases: <code>MutableMapping</code></p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <code>()</code> <code>**kwargs</code> <code>Any</code> <code>{}</code> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"\n\n    Args:\n        *args:\n        **kwargs:\n    \"\"\"\n    self._store = dict()\n    self.update(dict(*args, **kwargs))  # use the free update to set keys\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeMeta.as_dict","title":"<code>as_dict()</code>","text":"<p>Return a copy of the metadata as a regular dictionary.</p> <p>Datetime objects are converted to ISO format strings.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing all metadata key-value pairs</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"Return a copy of the metadata as a regular dictionary.\n\n    Datetime objects are converted to ISO format strings.\n\n    Returns:\n        Dictionary containing all metadata key-value pairs\n    \"\"\"\n    data = self._store.copy()\n\n    for key in data:\n        if isinstance(data[key], datetime.datetime):\n            data[key] = data[key].isoformat()\n    return data\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeMeta.copy","title":"<code>copy()</code>","text":"<p>Create a shallow copy of this metadata object.</p> <p>Creates a new instance with the same metadata. Note that this is a shallow copy - the dictionary values themselves are not deeply copied. This is typically sufficient since metadata values are usually primitives (int, float, str) or immutable objects (datetime).</p> <p>This is useful when creating modified versions of metadata without affecting the original, particularly during image transformations.</p> <p>Returns:</p> Type Description <code>'EyeMeta'</code> <p>New EyeMeta instance with the same data</p> Example <p>original_meta = EyeMeta(key1='value1', key2='value2') copied_meta = original_meta.copy() copied_meta['key1'] = 'modified' print(original_meta['key1'])  # Still 'value1'</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def copy(self) -&gt; 'EyeMeta':\n    \"\"\"Create a shallow copy of this metadata object.\n\n    Creates a new instance with the same metadata. Note that this is a\n    shallow copy - the dictionary values themselves are not deeply copied.\n    This is typically sufficient since metadata values are usually\n    primitives (int, float, str) or immutable objects (datetime).\n\n    This is useful when creating modified versions of metadata\n    without affecting the original, particularly during image\n    transformations.\n\n    Returns:\n        New EyeMeta instance with the same data\n\n    Example:\n        &gt;&gt;&gt; original_meta = EyeMeta(key1='value1', key2='value2')\n        &gt;&gt;&gt; copied_meta = original_meta.copy()\n        &gt;&gt;&gt; copied_meta['key1'] = 'modified'\n        &gt;&gt;&gt; print(original_meta['key1'])  # Still 'value1'\n    \"\"\"\n    return self.__class__(**dict(self._store))\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeVolumeMeta","title":"<code>EyeVolumeMeta(scale_z, scale_x, scale_y, scale_unit, bscan_meta, **kwargs)</code>","text":"<p>               Bases: <code>EyeMeta</code></p> <p>A dict with required keys to hold meta data for OCT volumes.</p> <p>Parameters:</p> Name Type Description Default <code>scale_z</code> <code>float</code> <p>Distance between neighbouring B-scans</p> required <code>scale_x</code> <code>float</code> <p>Horizontal scale of the B-scan pixels</p> required <code>scale_y</code> <code>float</code> <p>Vertical scale of the B-scan pixels</p> required <code>scale_unit</code> <code>str</code> <p>Unit of the scale. e.g. \u00b5m if scale is given in \u00b5m/pixel</p> required <code>bscan_meta</code> <code>list[EyeBscanMeta]</code> <p>A list holding an EyeBscanMeta object for every B-scan of the volume</p> required <code>**kwargs</code> <code>Any</code> <code>{}</code> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def __init__(\n    self,\n    scale_z: float,\n    scale_x: float,\n    scale_y: float,\n    scale_unit: str,\n    bscan_meta: list[EyeBscanMeta],\n    **kwargs: Any,\n):\n    \"\"\"A dict with required keys to hold meta data for OCT volumes.\n\n    Args:\n        scale_z: Distance between neighbouring B-scans\n        scale_x: Horizontal scale of the B-scan pixels\n        scale_y: Vertical scale of the B-scan pixels\n        scale_unit: Unit of the scale. e.g. \u00b5m if scale is given in \u00b5m/pixel\n        bscan_meta: A list holding an EyeBscanMeta object for every B-scan of the volume\n        **kwargs:\n    \"\"\"\n    super().__init__(\n        scale_z=scale_z,\n        scale_x=scale_x,\n        scale_y=scale_y,\n        scale_unit=scale_unit,\n        bscan_meta=bscan_meta,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeVolumeMeta.as_dict","title":"<code>as_dict()</code>","text":"<p>Returns:</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n\n    Returns:\n\n    \"\"\"\n    data = super().as_dict()\n    data['bscan_meta'] = [bm.as_dict() for bm in data['bscan_meta']]\n    return data\n</code></pre>"},{"location":"reference/src/eyepy/core/eyemeta/#eyepy.core.eyemeta.EyeVolumeMeta.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyemeta.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; 'EyeVolumeMeta':\n    \"\"\"\n\n    Args:\n        data:\n\n    Returns:\n\n    \"\"\"\n    data['bscan_meta'] = [EyeBscanMeta(**d) for d in data['bscan_meta']]\n    return cls(**data)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/","title":"eyevolume","text":""},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume","title":"<code>eyepy.core.eyevolume</code>","text":""},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume","title":"<code>EyeVolume(data, meta=None, localizer=None, transformation=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArray[float32]</code> <p>A 3D numpy array containing the OCT data in shape (n_bscans, bscan_height, bscan_width)</p> required <code>meta</code> <code>Optional[EyeVolumeMeta]</code> <p>Optional EyeVolumeMeta object.</p> <code>None</code> <code>localizer</code> <code>Optional[EyeEnface]</code> <code>None</code> <code>transformation</code> <code>Optional[_GeometricTransform]</code> <code>None</code> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def __init__(\n    self,\n    data: npt.NDArray[np.float32],\n    meta: Optional[EyeVolumeMeta] = None,\n    localizer: Optional[EyeEnface] = None,\n    transformation: Optional[_GeometricTransform] = None,\n) -&gt; None:\n    \"\"\"\n\n    Args:\n        data: A 3D numpy array containing the OCT data in shape (n_bscans, bscan_height, bscan_width)\n        meta: Optional [EyeVolumeMeta][eyepy.core.eyemeta.EyeVolumeMeta] object.\n        localizer:\n        transformation:\n    \"\"\"\n    self._raw_data = data\n    self._data = None\n    self._data_par = None\n\n    self._bscans = {}\n\n    if meta is None:\n        self.meta = self._default_meta(self._raw_data)\n    else:\n        self.meta = meta\n    if 'intensity_transform' not in self.meta:\n        self.meta['intensity_transform'] = 'default'\n    if 'par_algorithm' not in self.meta:\n        self.meta['par_algorithm'] = 'default'\n\n    self.set_intensity_transform(self.meta['intensity_transform'])\n    self.set_par_algorithm(self.meta['par_algorithm'])\n\n    self._slabs = []\n    self._layers = []\n    self._volume_maps = []\n    self._ascan_maps = []\n\n    if transformation is None:\n        self.localizer_transform = self._estimate_transform()\n    else:\n        self.localizer_transform = transformation\n\n    if localizer is None:\n        self.localizer = self._default_localizer(self.data)\n    else:\n        self.localizer = localizer\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.data","title":"<code>data</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.data_par","title":"<code>data_par</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.laterality","title":"<code>laterality</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.layers","title":"<code>layers</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.scale","title":"<code>scale</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.scale_unit","title":"<code>scale_unit</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.scale_x","title":"<code>scale_x</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.scale_y","title":"<code>scale_y</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.scale_z","title":"<code>scale_z</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.shape","title":"<code>shape</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.size_x","title":"<code>size_x</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.size_y","title":"<code>size_y</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.size_z","title":"<code>size_z</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.slabs","title":"<code>slabs</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.volume_maps","title":"<code>volume_maps</code>  <code>property</code>","text":"<p>Returns:</p>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.__getitem__","title":"<code>__getitem__(index)</code>","text":"<pre><code>__getitem__(index: SupportsIndex) -&gt; EyeBscan\n</code></pre><pre><code>__getitem__(index: slice) -&gt; list[EyeBscan]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>Union[SupportsIndex, slice]</code> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def __getitem__(\n        self, index: Union[SupportsIndex,\n                           slice]) -&gt; Union[list[EyeBscan], EyeBscan]:\n    \"\"\"\n\n    Args:\n        index:\n\n    Returns:\n\n    \"\"\"\n    # The B-Scan at the given index.\n    if isinstance(index, slice):\n        return [self[i] for i in range(*index.indices(len(self)))]\n    elif isinstance(index, int):\n        if index &lt; 0:\n            index = len(self) + index\n\n        if index &lt; len(self):\n            try:\n                # Return B-scan with type annotation\n                return self._bscans[index]\n            except KeyError:\n                self._bscans[index] = EyeBscan(self, index)\n                return self._bscans[index]\n        else:\n            raise IndexError()\n    else:\n        raise TypeError()\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.__len__","title":"<code>__len__()</code>","text":"<p>The number of B-Scans.</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"The number of B-Scans.\"\"\"\n    return self.shape[0]\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.add_layer_annotation","title":"<code>add_layer_annotation(height_map=None, meta=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>height_map</code> <code>Optional[NDArray[float64]]</code> <p>Height in shape (n_Bscans, Bscan_width) The first index refers to the bottom most B-scan</p> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <p>name, current_color, and knots</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <code>{}</code> <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def add_layer_annotation(self,\n                         height_map: Optional[npt.NDArray[\n                             np.float64]] = None,\n                         meta: Optional[dict] = None,\n                         **kwargs: Any) -&gt; EyeVolumeLayerAnnotation:\n    \"\"\"\n\n    Args:\n        height_map: Height in shape (n_Bscans, Bscan_width) The first index refers to the bottom most B-scan\n        meta: name, current_color, and knots\n        **kwargs:\n\n    Returns:\n\n    \"\"\"\n    if meta is None:\n        meta = {}\n    meta.update(**kwargs)\n    layer_annotation = EyeVolumeLayerAnnotation(self, height_map, **meta)\n    self._layers.append(layer_annotation)\n    return layer_annotation\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.add_pixel_annotation","title":"<code>add_pixel_annotation(voxel_map=None, meta=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>voxel_map</code> <code>Optional[NDArray[bool_]]</code> <code>None</code> <code>meta</code> <code>Optional[dict]</code> <code>None</code> <code>**kwargs</code> <code>Any</code> <code>{}</code> <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def add_pixel_annotation(self,\n                         voxel_map: Optional[npt.NDArray[np.bool_]] = None,\n                         meta: Optional[dict] = None,\n                         **kwargs: Any) -&gt; EyeVolumePixelAnnotation:\n    \"\"\"\n\n    Args:\n        voxel_map:\n        meta:\n        **kwargs:\n\n    Returns:\n\n    \"\"\"\n    if meta is None:\n        meta = {}\n    meta.update(**kwargs)\n    voxel_annotation = EyeVolumePixelAnnotation(self, voxel_map, **meta)\n    self._volume_maps.append(voxel_annotation)\n    return voxel_annotation\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.add_slab_annotation","title":"<code>add_slab_annotation(meta=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>meta</code> <code>Optional[dict]</code> <p>Metadata for the slab annotation</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>EyeVolumeSlabAnnotation</code> <code>EyeVolumeSlabAnnotation</code> <p>The created slab annotation</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def add_slab_annotation(self,\n                        meta: Optional[dict] = None,\n                        **kwargs: Any) -&gt; EyeVolumeSlabAnnotation:\n    \"\"\"\n\n    Args:\n        meta: Metadata for the slab annotation\n        **kwargs: Additional keyword arguments\n\n    Returns:\n        EyeVolumeSlabAnnotation: The created slab annotation\n    \"\"\"\n    if meta is None:\n        meta = {}\n    meta.update(**kwargs)\n    slab_annotation = EyeVolumeSlabAnnotation(self, **meta)\n    self._slabs.append(slab_annotation)\n    return slab_annotation\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load an EyeVolume from a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the zip file to load</p> required <p>Returns:</p> Name Type Description <code>EyeVolume</code> <code>'EyeVolume'</code> <p>The loaded EyeVolume object</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>@classmethod\ndef load(cls, path: Union[str, Path]) -&gt; 'EyeVolume':\n    \"\"\"Load an EyeVolume from a zip file.\n\n    Args:\n        path: Path to the zip file to load\n\n    Returns:\n        EyeVolume: The loaded EyeVolume object\n    \"\"\"\n    path = Path(path)\n\n    with zipfile.ZipFile(path, 'r') as zipf:\n        # Load raw volume and meta\n        with zipf.open('raw_volume.npy') as f:\n            data = np.load(io.BytesIO(f.read()))\n        with zipf.open('meta.json') as f:\n            volume_meta = EyeVolumeMeta.from_dict(json.load(f))\n\n        # Load Volume Annotations\n        voxel_annotations = []\n        voxels_meta = []\n        try:\n            # Try loading new individual format first\n            # Count how many individual maps we have\n            i = 0\n            while True:\n                try:\n                    # Try compressed format\n                    with zipf.open(f'annotations/voxels/voxel_map_{i}.bin') as f:\n                        compressed_data = f.read()\n                    with zipf.open(f'annotations/voxels/voxel_map_{i}_meta.json') as f:\n                        meta_dict = json.load(f)\n                    if isinstance(meta_dict, dict) and 'compression_meta' in meta_dict:\n                        # New format with compression metadata\n                        mask = decompress_boolean_mask(compressed_data, meta_dict['compression_meta'])\n                        voxel_annotations.append(mask)\n                        voxels_meta.append(meta_dict['annotation_meta'])\n                    else:\n                        # Shouldn't happen, but fallback\n                        voxel_annotations.append(decompress_boolean_mask(compressed_data, meta_dict))\n                        voxels_meta.append(meta_dict)\n                    i += 1\n                except KeyError:\n                    # Try npy format\n                    try:\n                        with zipf.open(f'annotations/voxels/voxel_map_{i}.npy') as f:\n                            mask = np.load(io.BytesIO(f.read()))\n                        with zipf.open(f'annotations/voxels/voxel_map_{i}_meta.json') as f:\n                            voxels_meta.append(json.load(f))\n                        voxel_annotations.append(mask)\n                        i += 1\n                    except KeyError:\n                        # No more individual maps\n                        break\n\n            # If no individual maps found, try old stacked format\n            if len(voxel_annotations) == 0:\n                try:\n                    with zipf.open('annotations/voxels/voxel_maps.npy') as f:\n                        voxel_stack = np.load(io.BytesIO(f.read()))\n                    with zipf.open('annotations/voxels/meta.json') as f:\n                        voxels_meta = json.load(f)\n                    # Convert stacked array to individual annotations\n                    voxel_annotations = [voxel_stack[i] for i in range(voxel_stack.shape[0])]\n                except KeyError:\n                    voxel_annotations = []\n                    voxels_meta = []\n        except KeyError:\n            voxel_annotations = []\n            voxels_meta = []\n\n        # Load layers\n        try:\n            with zipf.open('annotations/layers/layer_heights.npy') as f:\n                layer_annotations = np.load(io.BytesIO(f.read()))\n            with zipf.open('annotations/layers/meta.json') as f:\n                layers_meta = json.load(f)\n\n            # Clean knots\n            for i, layer_meta in enumerate(layers_meta):\n                if 'knots' in layer_meta:\n                    knots = layer_meta['knots']\n                    knots = {int(i): knots[i] for i in knots}\n                    layer_meta['knots'] = knots\n        except KeyError:\n            layer_annotations = []\n            layers_meta = []\n\n        # Load slabs\n        try:\n            with zipf.open('annotations/slabs/meta.json') as f:\n                slabs_meta = json.load(f)\n        except KeyError:\n            slabs_meta = []\n\n        # Load Localizer and meta\n        with zipf.open('localizer/localizer.npy') as f:\n            localizer_data = np.load(io.BytesIO(f.read()))\n        with zipf.open('localizer/meta.json') as f:\n            localizer_meta = EyeEnfaceMeta.from_dict(json.load(f))\n\n        # Load Optic Disc annotation if it exists\n        optic_disc = None\n        try:\n            from eyepy.core.annotations import EyeEnfaceOpticDiscAnnotation\n            with zipf.open('localizer/annotations/optic_disc/polygon.npy') as f:\n                polygon = np.load(io.BytesIO(f.read()))\n            shape = None\n            try:\n                with zipf.open('localizer/annotations/optic_disc/shape.json') as f:\n                    shape = tuple(json.load(f))\n            except KeyError:\n                pass\n            optic_disc = EyeEnfaceOpticDiscAnnotation(polygon=polygon, shape=shape)\n        except KeyError:\n            pass\n\n        # Load Fovea annotation if it exists\n        fovea = None\n        try:\n            from eyepy.core.annotations import EyeEnfaceFoveaAnnotation\n            with zipf.open('localizer/annotations/fovea/polygon.npy') as f:\n                polygon = np.load(io.BytesIO(f.read()))\n            shape = None\n            try:\n                with zipf.open('localizer/annotations/fovea/shape.json') as f:\n                    shape = tuple(json.load(f))\n            except KeyError:\n                pass\n            fovea = EyeEnfaceFoveaAnnotation(polygon=polygon, shape=shape)\n        except KeyError:\n            pass\n\n        localizer = EyeEnface(data=localizer_data, meta=localizer_meta,\n                             optic_disc=optic_disc, fovea=fovea)\n\n        # Load Localizer Annotations\n        pixel_annotations = []\n        pixels_meta = []\n        try:\n            # Try loading new individual format first\n            # Count how many individual maps we have\n            i = 0\n            while True:\n                try:\n                    # Try compressed format\n                    with zipf.open(f'localizer/annotations/pixel/pixel_map_{i}.bin') as f:\n                        compressed_data = f.read()\n                    with zipf.open(f'localizer/annotations/pixel/pixel_map_{i}_meta.json') as f:\n                        meta_dict = json.load(f)\n                    if isinstance(meta_dict, dict) and 'compression_meta' in meta_dict:\n                        # New format with compression metadata\n                        mask = decompress_boolean_mask(compressed_data, meta_dict['compression_meta'])\n                        pixel_annotations.append(mask)\n                        pixels_meta.append(meta_dict['annotation_meta'])\n                    else:\n                        # Shouldn't happen, but fallback\n                        pixel_annotations.append(decompress_boolean_mask(compressed_data, meta_dict))\n                        pixels_meta.append(meta_dict)\n                    i += 1\n                except KeyError:\n                    # Try npy format\n                    try:\n                        with zipf.open(f'localizer/annotations/pixel/pixel_map_{i}.npy') as f:\n                            mask = np.load(io.BytesIO(f.read()))\n                        with zipf.open(f'localizer/annotations/pixel/pixel_map_{i}_meta.json') as f:\n                            pixels_meta.append(json.load(f))\n                        pixel_annotations.append(mask)\n                        i += 1\n                    except KeyError:\n                        # No more individual maps\n                        break\n\n            # If no individual maps found, try old stacked format\n            if len(pixel_annotations) == 0:\n                try:\n                    with zipf.open('localizer/annotations/pixel/pixel_maps.npy') as f:\n                        pixel_stack = np.load(io.BytesIO(f.read()))\n                    with zipf.open('localizer/annotations/pixel/meta.json') as f:\n                        pixels_meta = json.load(f)\n                    # Convert stacked array to individual annotations\n                    pixel_annotations = [pixel_stack[i] for i in range(pixel_stack.shape[0])]\n                except KeyError:\n                    pixel_annotations = []\n                    pixels_meta = []\n\n            for i, pixel_meta in enumerate(pixels_meta):\n                localizer.add_area_annotation(pixel_annotations[i],\n                                              pixel_meta)\n        except KeyError:\n            pass\n\n        # Load localizer transform if it exists, otherwise compute it\n        try:\n            with zipf.open('localizer/transform_params.npy') as f:\n                transform_params = np.load(io.BytesIO(f.read()))\n            transformation = transform.AffineTransform(matrix=transform_params)\n        except KeyError:\n            # Backward compatibility: compute transform if not saved\n            from eyepy.io.utils import _compute_localizer_oct_transform\n            transformation = _compute_localizer_oct_transform(\n                volume_meta, localizer_meta, data.shape)\n\n        ev = cls(\n            data=data,\n            meta=volume_meta,\n            localizer=localizer,\n            transformation=transformation,\n        )\n        for meta, annotation in zip(layers_meta, layer_annotations):\n            ev.add_layer_annotation(annotation, meta)\n\n        for meta in slabs_meta:\n            ev.add_slab_annotation(meta)\n\n        for meta, annotation in zip(voxels_meta, voxel_annotations):\n            ev.add_pixel_annotation(annotation, meta)\n\n    return ev\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.plot","title":"<code>plot(ax=None, projections=False, slabs=False, bscan_region=False, bscan_positions=False, quantification=None, region=np.s_[:, :], annotations_only=False, projection_kwargs=None, slab_kwargs=None, line_kwargs=None, scalebar='botleft', scalebar_kwargs=None, watermark=True)</code>","text":"<p>Plot an annotated OCT localizer image.</p> <p>If the volume does not provide a localizer image an enface projection of the OCT volume is used instead.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Axes to plot on. If not provided plot on the current axes (plt.gca()).</p> <code>None</code> <code>projections</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all projections (default: <code>False</code>). If a list of strings is given, plot the projections with the given names. Projections are 2D enface views on oct volume annotations such as drusen.</p> <code>False</code> <code>slabs</code> <code>Union[bool, list[str]]</code> <p>If <code>True</code> plot all slab projections (default: <code>False</code>). If a list of strings is given, plot the slabs with the given names. Slab projections are 2D enface views on OCTA volume annotations such as NFLVP or SVP.</p> <code>False</code> <code>bscan_region</code> <code>bool</code> <p>If <code>True</code> plot the region B-scans are located in (default: <code>False</code>)</p> <code>False</code> <code>bscan_positions</code> <code>Union[bool, list[int]]</code> <p>If <code>True</code> plot positions of all B-scan (default: <code>False</code>). If a list of integers is given, plot the B-scans with the respective indices. Indexing starts at the bottom of the localizer.</p> <code>False</code> <code>quantification</code> <code>Optional[str]</code> <p>Name of the OCT volume annotations to plot a quantification for (default: <code>None</code>). Quantifications are performed on circular grids.</p> <code>None</code> <code>region</code> <code>tuple[slice, slice]</code> <p>Region of the localizer to plot (default: <code>np.s_[...]</code>)</p> <code>s_[:, :]</code> <code>annotations_only</code> <code>bool</code> <p>If <code>True</code> localizer image is not plotted (defaualt: <code>False</code>)</p> <code>False</code> <code>projection_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for the projection plots. If <code>None</code> default values are used (default: <code>None</code>). If a dictionary is given, the keys are the projection names and the values are dictionaries of keyword arguments.</p> <code>None</code> <code>slab_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for the slab plots. If <code>None</code> default values are used (default: <code>None</code>). If a dictionary is given, the keys are the slab names and the values are dictionaries of keyword arguments.</p> <code>None</code> <code>line_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for customizing the lines to show B-scan region and positions plots. If <code>None</code> default values are used which are {\"linewidth\": 0.2, \"linestyle\": \"-\", \"color\": \"green\"}</p> <code>None</code> <code>scalebar</code> <code>Union[bool, str]</code> <p>Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or <code>False</code> (default: \"botleft\"). If <code>True</code> the scalebar is placed in the bottom left corner. You can custumize the scalebar using the <code>scalebar_kwargs</code> argument.</p> <code>'botleft'</code> <code>scalebar_kwargs</code> <code>Optional[dict]</code> <p>Optional keyword arguments for customizing the scalebar. Check the documentation of plot_scalebar for more information.</p> <code>None</code> <code>watermark</code> <code>bool</code> <p>If <code>True</code> plot a watermark on the image (default: <code>True</code>). When removing the watermark, please consider to cite eyepy in your publication.</p> <code>True</code> <p>Returns:     None</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def plot(\n    self,\n    ax: Optional[plt.Axes] = None,\n    projections: Union[bool, list[str]] = False,\n    slabs: Union[bool, list[str]] = False,\n    bscan_region: bool = False,\n    bscan_positions: Union[bool, list[int]] = False,\n    quantification: Optional[str] = None,\n    region: tuple[slice, slice] = np.s_[:, :],\n    annotations_only: bool = False,\n    projection_kwargs: Optional[dict] = None,\n    slab_kwargs: Optional[dict] = None,\n    line_kwargs: Optional[dict] = None,\n    scalebar: Union[bool, str] = 'botleft',\n    scalebar_kwargs: Optional[dict] = None,\n    watermark: bool = True,\n) -&gt; None:\n    \"\"\"Plot an annotated OCT localizer image.\n\n    If the volume does not provide a localizer image an enface projection of the OCT volume is used instead.\n\n    Args:\n        ax: Axes to plot on. If not provided plot on the current axes (plt.gca()).\n        projections: If `True` plot all projections (default: `False`). If a list of strings is given, plot the projections with the given names. Projections are 2D enface views on oct volume annotations such as drusen.\n        slabs: If `True` plot all slab projections (default: `False`). If a list of strings is given, plot the slabs with the given names. Slab projections are 2D enface views on OCTA volume annotations such as NFLVP or SVP.\n        bscan_region: If `True` plot the region B-scans are located in (default: `False`)\n        bscan_positions: If `True` plot positions of all B-scan (default: `False`). If a list of integers is given, plot the B-scans with the respective indices. Indexing starts at the bottom of the localizer.\n        quantification: Name of the OCT volume annotations to plot a quantification for (default: `None`). Quantifications are performed on circular grids.\n        region: Region of the localizer to plot (default: `np.s_[...]`)\n        annotations_only: If `True` localizer image is not plotted (defaualt: `False`)\n        projection_kwargs: Optional keyword arguments for the projection plots. If `None` default values are used (default: `None`). If a dictionary is given, the keys are the projection names and the values are dictionaries of keyword arguments.\n        slab_kwargs: Optional keyword arguments for the slab plots. If `None` default values are used (default: `None`). If a dictionary is given, the keys are the slab names and the values are dictionaries of keyword arguments.\n        line_kwargs: Optional keyword arguments for customizing the lines to show B-scan region and positions plots. If `None` default values are used which are {\"linewidth\": 0.2, \"linestyle\": \"-\", \"color\": \"green\"}\n        scalebar: Position of the scalebar, one of \"topright\", \"topleft\", \"botright\", \"botleft\" or `False` (default: \"botleft\"). If `True` the scalebar is placed in the bottom left corner. You can custumize the scalebar using the `scalebar_kwargs` argument.\n        scalebar_kwargs: Optional keyword arguments for customizing the scalebar. Check the documentation of [plot_scalebar][eyepy.core.plotting.plot_scalebar] for more information.\n        watermark: If `True` plot a watermark on the image (default: `True`). When removing the watermark, please consider to cite eyepy in your publication.\n    Returns:\n        None\n    \"\"\"\n\n    # Complete region index expression\n    y_start = region[0].start if region[0].start is not None else 0\n    y_stop = region[0].stop if region[\n        0].stop is not None else self.localizer.shape[0]\n    x_start = region[1].start if region[1].start is not None else 0\n    x_stop = region[1].stop if region[\n        1].stop is not None else self.localizer.shape[1]\n\n    region = np.s_[y_start:y_stop, x_start:x_stop]\n\n    if ax is None:\n        ax = plt.gca()\n\n    if not annotations_only:\n        self.localizer.plot(ax=ax,\n                            region=region,\n                            scalebar=scalebar,\n                            scalebar_kwargs=scalebar_kwargs,\n                            watermark=watermark)\n\n    if projections is True:\n        projections = list(self.volume_maps.keys())\n    elif not projections:\n        projections = []\n\n    if slabs is True:\n        slabs = list(self.slabs.keys())\n    elif not slabs:\n        slabs = []\n\n    if projection_kwargs is None:\n        projection_kwargs = defaultdict(lambda: {})\n    for name in projections:\n        if name not in projection_kwargs.keys():\n            projection_kwargs[name] = {}\n        self.volume_maps[name].plot(ax=ax,\n                                    region=region,\n                                    **projection_kwargs[name])\n\n    if slab_kwargs is None:\n        slab_kwargs = defaultdict(lambda: {})\n    for name in slabs:\n        if name not in slab_kwargs.keys():\n            slab_kwargs[name] = {}\n        self.slabs[name].plot(ax=ax,\n                              region=region,\n                              transform=True,\n                              **slab_kwargs[name])\n\n    if line_kwargs is None:\n        line_kwargs = config.line_kwargs\n    else:\n        line_kwargs = {**config.line_kwargs, **line_kwargs}\n\n    if bscan_positions:\n        self._plot_bscan_positions(\n            ax=ax,\n            bscan_positions=bscan_positions,\n            region=region,\n            line_kwargs=line_kwargs,\n        )\n    if bscan_region:\n        self._plot_bscan_region(region=region,\n                                ax=ax,\n                                line_kwargs=line_kwargs)\n\n    if quantification:\n        self.volume_maps[quantification].plot_quantification(region=region,\n                                                             ax=ax)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.remove_layer_annotation","title":"<code>remove_layer_annotation(name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def remove_layer_annotation(self, name: str) -&gt; None:\n    \"\"\"\n\n    Args:\n        name:\n\n    Returns:\n\n    \"\"\"\n    for i, layer in enumerate(self._layers):\n        if layer.name == name:\n            self._layers.pop(i)\n\n    # Remove references from B-scans\n    for bscan in self:\n        if name in bscan.layers:\n            bscan.layers.pop(name)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.remove_pixel_annotation","title":"<code>remove_pixel_annotation(name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def remove_pixel_annotation(self, name: str) -&gt; None:\n    \"\"\"\n\n    Args:\n        name:\n\n    Returns:\n\n    \"\"\"\n    for i, voxel_map in enumerate(self._volume_maps):\n        if voxel_map.name == name:\n            self._volume_maps.pop(i)\n\n    # Remove references from B-scans\n    for bscan in self:\n        if name in bscan.area_maps:\n            bscan.area_maps.pop(name)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.remove_slab_annotation","title":"<code>remove_slab_annotation(name)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def remove_slab_annotation(self, name: str) -&gt; None:\n    \"\"\"\n\n    Args:\n        name:\n\n    Returns:\n\n    \"\"\"\n    for i, slab in enumerate(self._slabs):\n        if slab.name == name:\n            self._slabs.pop(i)\n\n    # Remove references from B-scans\n    for bscan in self:\n        if name in bscan.slabs:\n            bscan.slabs.pop(name)\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.save","title":"<code>save(path, compress=False)</code>","text":"<p>Save the EyeVolume to a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path where the file will be saved</p> required <code>compress</code> <code>bool</code> <p>Whether to compress the file. Compression reduces file size by 35-45% but takes at least 10x longer.      Default is False for fast saves. Set to True to reduce file size with zip compress level 1. (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def save(self, path: Union[str, Path], compress: bool = False) -&gt; None:\n    \"\"\"Save the EyeVolume to a zip file.\n\n    Args:\n        path: Path where the file will be saved\n        compress: Whether to compress the file. Compression reduces file size by 35-45% but takes at least 10x longer.\n                 Default is False for fast saves. Set to True to reduce file size with zip compress level 1. (default: False)\n\n    Returns:\n        None\n    \"\"\"\n    path = Path(path)\n\n    compression_type = zipfile.ZIP_DEFLATED if compress else zipfile.ZIP_STORED\n    compress_level = 1 if compress else None\n\n    with zipfile.ZipFile(path, 'w', compression_type, compresslevel=compress_level) as zipf:\n        # Save OCT volume as npy and meta as json\n        volume_bytes = io.BytesIO()\n        np.save(volume_bytes, self._raw_data)\n        zipf.writestr('raw_volume.npy', volume_bytes.getvalue())\n\n        meta_dict = self.meta.as_dict()\n        if meta_dict['intensity_transform'] == 'custom':\n            warnings.warn(\n                'Custom intensity transforms can not be saved.')\n            meta_dict['intensity_transform'] = 'default'\n        zipf.writestr('meta.json', json.dumps(meta_dict))\n\n        # Save Volume Annotations (individually to preserve data types)\n        if len(self._volume_maps) &gt; 0:\n            for i, v in enumerate(self._volume_maps):\n                # For boolean arrays, use compressed packbits format\n                if is_boolean_array(v.data):\n                    compressed_data, compression_meta = compress_boolean_mask(v.data)\n                    zipf.writestr(f'annotations/voxels/voxel_map_{i}.bin', compressed_data)\n                    zipf.writestr(\n                        f'annotations/voxels/voxel_map_{i}_meta.json',\n                        json.dumps({\n                            'annotation_meta': v.meta,\n                            'compression_meta': compression_meta,\n                        })\n                    )\n                else:\n                    # For non-boolean arrays, save as npy\n                    voxel_bytes = io.BytesIO()\n                    np.save(voxel_bytes, v.data)\n                    zipf.writestr(f'annotations/voxels/voxel_map_{i}.npy', voxel_bytes.getvalue())\n                    zipf.writestr(\n                        f'annotations/voxels/voxel_map_{i}_meta.json',\n                        json.dumps(v.meta)\n                    )\n\n        # Save layer annotations\n        if len(self._layers) &gt; 0:\n            layer_data_bytes = io.BytesIO()\n            np.save(\n                layer_data_bytes,\n                np.stack([l.data for l in self._layers]),\n            )\n            zipf.writestr('annotations/layers/layer_heights.npy', layer_data_bytes.getvalue())\n            zipf.writestr(\n                'annotations/layers/meta.json',\n                json.dumps([l.meta for l in self._layers])\n            )\n\n        # Save slab annotations\n        if len(self._slabs) &gt; 0:\n            zipf.writestr(\n                'annotations/slabs/meta.json',\n                json.dumps([s.meta for s in self._slabs])\n            )\n\n        # Save Localizer\n        localizer_bytes = io.BytesIO()\n        np.save(localizer_bytes, self.localizer.data)\n        zipf.writestr('localizer/localizer.npy', localizer_bytes.getvalue())\n        zipf.writestr('localizer/meta.json', json.dumps(self.localizer.meta.as_dict()))\n\n        # Save localizer transform\n        if self.localizer_transform is not None:\n            transform_bytes = io.BytesIO()\n            np.save(transform_bytes, self.localizer_transform.params)\n            zipf.writestr('localizer/transform_params.npy', transform_bytes.getvalue())\n\n        # Save Localizer Annotations\n        if len(self.localizer._area_maps) &gt; 0:\n            for i, p in enumerate(self.localizer._area_maps):\n                # For boolean arrays, use compressed packbits format\n                if is_boolean_array(p.data):\n                    compressed_data, compression_meta = compress_boolean_mask(p.data)\n                    zipf.writestr(f'localizer/annotations/pixel/pixel_map_{i}.bin', compressed_data)\n                    zipf.writestr(\n                        f'localizer/annotations/pixel/pixel_map_{i}_meta.json',\n                        json.dumps({\n                            'annotation_meta': p.meta,\n                            'compression_meta': compression_meta,\n                        })\n                    )\n                else:\n                    # For non-boolean arrays, save as npy\n                    pixel_bytes = io.BytesIO()\n                    np.save(pixel_bytes, p.data)\n                    zipf.writestr(f'localizer/annotations/pixel/pixel_map_{i}.npy', pixel_bytes.getvalue())\n                    zipf.writestr(\n                        f'localizer/annotations/pixel/pixel_map_{i}_meta.json',\n                        json.dumps(p.meta)\n                    )\n\n        # Save Optic Disc annotation\n        if self.localizer.optic_disc is not None:\n            polygon_bytes = io.BytesIO()\n            np.save(polygon_bytes, self.localizer.optic_disc.polygon)\n            zipf.writestr('localizer/annotations/optic_disc/polygon.npy', polygon_bytes.getvalue())\n\n            if self.localizer.optic_disc.shape is not None:\n                zipf.writestr(\n                    'localizer/annotations/optic_disc/shape.json',\n                    json.dumps(self.localizer.optic_disc.shape)\n                )\n\n        # Save Fovea annotation\n        if self.localizer.fovea is not None:\n            fovea_polygon_bytes = io.BytesIO()\n            np.save(fovea_polygon_bytes, self.localizer.fovea.polygon)\n            zipf.writestr('localizer/annotations/fovea/polygon.npy', fovea_polygon_bytes.getvalue())\n\n            if self.localizer.fovea.shape is not None:\n                zipf.writestr(\n                    'localizer/annotations/fovea/shape.json',\n                    json.dumps(self.localizer.fovea.shape)\n                )\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.set_intensity_transform","title":"<code>set_intensity_transform(func)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[str, Callable]</code> <p>Either a string specifying a transform from eyepy.core.utils.intensity_transforms or a function</p> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def set_intensity_transform(self, func: Union[str, Callable]) -&gt; None:\n    \"\"\"\n\n    Args:\n        func: Either a string specifying a transform from eyepy.core.utils.intensity_transforms or a function\n\n    Returns:\n\n    \"\"\"\n    if isinstance(func, str):\n        if func in intensity_transforms:\n            self.meta['intensity_transform'] = func\n            self.intensity_transform = intensity_transforms[func]\n            self._data = None\n        elif func == 'custom':\n            logger.warning(\n                'Custom intensity transforms can not be loaded currently')\n        else:\n            logger.warning(\n                f\"Provided intensity transform name {func} is not known. Valid names are 'vol' or 'default'. You can also pass your own function.\"\n            )\n    elif isinstance(func, Callable):\n        self.meta['intensity_transform'] = 'custom'\n        self.intensity_transform = func\n        self._data = None\n</code></pre>"},{"location":"reference/src/eyepy/core/eyevolume/#eyepy.core.eyevolume.EyeVolume.set_par_algorithm","title":"<code>set_par_algorithm(func)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>func</code> <code>Union[str, Callable]</code> <p>Either a string specifying a par algorithm from eyepy.core.utils.par_algorithms or a function</p> required <p>Returns:</p> Source code in <code>src/eyepy/core/eyevolume.py</code> <pre><code>def set_par_algorithm(self, func: Union[str, Callable]) -&gt; None:\n    \"\"\"\n\n    Args:\n        func: Either a string specifying a par algorithm from eyepy.core.utils.par_algorithms or a function\n\n    Returns:\n\n    \"\"\"\n    if isinstance(func, str):\n        if func in par_algorithms:\n            self.meta['par_algorithm'] = func\n            self.par_algorithm = par_algorithms[func]\n            self._data_par = None\n        elif func == 'custom':\n            logger.warning(\n                'Custom par algorithms can not be loaded currently')\n        else:\n            logger.warning(\n                f\"Provided par algorithm name {func} is not known. Valid names are 'default'. You can also pass your own function.\"\n            )\n    elif isinstance(func, Callable):\n        self.meta['par_algorithm'] = 'custom'\n        self.par_algorithm = func\n        self._data_par = None\n</code></pre>"},{"location":"reference/src/eyepy/core/filter/","title":"filter","text":""},{"location":"reference/src/eyepy/core/filter/#eyepy.core.filter","title":"<code>eyepy.core.filter</code>","text":""},{"location":"reference/src/eyepy/core/filter/#eyepy.core.filter.filter_by_depth","title":"<code>filter_by_depth(drusen_map, minimum_depth=2)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>drusen_map</code> <code>NDArray[bool_]</code> required <code>minimum_depth</code> <code>int</code> <code>2</code> <p>Returns:</p> Source code in <code>src/eyepy/core/filter.py</code> <pre><code>def filter_by_depth(drusen_map: npt.NDArray[np.bool_],\n                    minimum_depth: int = 2) -&gt; npt.NDArray[np.bool_]:\n    \"\"\"\n\n    Args:\n        drusen_map:\n        minimum_depth:\n\n    Returns:\n\n    \"\"\"\n    filtered_drusen = np.copy(drusen_map)\n    if minimum_depth == 0:\n        return drusen_map\n    # get array where connected components get same label\n    connected_component_array, _ = ndimage.label(drusen_map, output=None)\n    # Go through each component, sum it along axis 0 and check max depth against threshold\n    max_depths = np.zeros_like(connected_component_array)\n    for label, drusen_pos in enumerate(\n            ndimage.find_objects(connected_component_array)):\n        component_sub_vol = connected_component_array[drusen_pos]\n        component_max_depth = np.max(\n            np.sum(component_sub_vol == label + 1, axis=0))\n        component_sub_vol[component_sub_vol == label + 1] = component_max_depth\n        max_depths[drusen_pos] = component_sub_vol\n    filtered_drusen[max_depths &lt; minimum_depth] = False\n    return filtered_drusen.astype(bool)\n</code></pre>"},{"location":"reference/src/eyepy/core/filter/#eyepy.core.filter.filter_by_height_enface","title":"<code>filter_by_height_enface(drusen_map, minimum_height=2)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>drusen_map</code> <code>NDArray[bool_]</code> required <code>minimum_height</code> <code>int</code> <code>2</code> <p>Returns:</p> Source code in <code>src/eyepy/core/filter.py</code> <pre><code>def filter_by_height_enface(drusen_map: npt.NDArray[np.bool_],\n                            minimum_height: int = 2) -&gt; npt.NDArray[np.bool_]:\n    \"\"\"\n\n    Args:\n        drusen_map:\n        minimum_height:\n\n    Returns:\n\n    \"\"\"\n    if minimum_height == 0:\n        return drusen_map\n\n    projection = np.sum(drusen_map, axis=1,\n                        keepdims=True)  # Shape (n_bscans, width)\n\n    # Find connected components in the enface projection\n    connected_component_array, num_drusen = ndimage.label(projection != 0)\n    # print(connected_component_array.shape)\n    max_heights = np.zeros_like(connected_component_array)\n    for drusen_pos in ndimage.find_objects(connected_component_array):\n        # Work on subvolume for faster processing\n        component_sub_vol = connected_component_array[drusen_pos]\n        # Find current label (most frequent label in the subvolume)\n        label = np.bincount(component_sub_vol[component_sub_vol != 0]).argmax()\n        component_max_height = np.max(\n            projection[drusen_pos][component_sub_vol == label])\n        # Set drusen region to drusen max height\n        max_heights[drusen_pos][component_sub_vol ==\n                                label] = component_max_height\n\n    filtered_drusen = np.copy(drusen_map)\n    indices = np.nonzero(max_heights &lt; minimum_height)\n    filtered_drusen[indices[0], :, indices[2]] = False\n    return filtered_drusen.astype(bool)\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/","title":"grids","text":""},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids","title":"<code>eyepy.core.grids</code>","text":""},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.circle_mask","title":"<code>circle_mask(radius, mask_shape=None, smooth_edges=False)</code>","text":"<p>Create a centered circular mask with given radius.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>int</code> required <code>mask_shape</code> <code>Optional[tuple[int, int]]</code> <code>None</code> <code>smooth_edges</code> <code>bool</code> <code>False</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>def circle_mask(radius: int,\n                mask_shape: Optional[tuple[int, int]] = None,\n                smooth_edges: bool = False) -&gt; npt.NDArray[Any]:\n    \"\"\"Create a centered circular mask with given radius.\n\n    Args:\n        radius:\n        mask_shape:\n        smooth_edges:\n\n    Returns:\n    \"\"\"\n    if mask_shape is None:\n        mask_shape = (radius * 2, radius * 2)\n\n    if smooth_edges:\n        work_shape = (mask_shape[0] * 5, mask_shape[1] * 5)\n        radius *= 5\n    else:\n        work_shape = mask_shape\n\n    circle_mask = np.zeros(work_shape)\n    circle_mask[radius_filtergrid(\n        work_shape, quadrant_shift=False, normalize=False) &lt; radius] = 1\n\n    return transform.resize(circle_mask, mask_shape)\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.create_grid_regions","title":"<code>create_grid_regions(mask_shape, radii, n_sectors, offsets, clockwise, smooth_edges=False)</code>  <code>cached</code>","text":"<p>Create sectorized circular region masks.</p> <p>First circular masks with the provided radii are generated. Then ring masks are created by subtracting the first circular mask from the second and so on. If you want the complete ring, set the respective n_sectors entry to 1. You  can split the ring into n sectors by setting the respective entry to n. Setting a number in <code>offsets</code> rotates the respective ring sectors by n degree.</p> <p>Parameters:</p> Name Type Description Default <code>mask_shape</code> <code>tuple[int, int]</code> <p>Output shape of the computed masks</p> required <code>radii</code> <code>Sequence[int]</code> <p>Ascending radii of the circular regions in pixels</p> required <code>n_sectors</code> <code>Sequence[int]</code> <p>Number of sectors corresponding to the radii</p> required <code>offsets</code> <code>Sequence[int]</code> <p>Angular offset of first sector corresponding to the radii</p> required <code>clockwise</code> <code>bool</code> <p>If True sectors are added clockwise starting from the start_angles</p> required <code>smooth_edges</code> <code>bool</code> <p>If True, compute non binary masks where edges might be shared between adjacent regions</p> <code>False</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>@functools.lru_cache(8, typed=False)\ndef create_grid_regions(\n    mask_shape: tuple[int, int],\n    radii: Sequence[int],\n    n_sectors: Sequence[int],\n    offsets: Sequence[int],\n    clockwise: bool,\n    smooth_edges: bool = False,\n) -&gt; list[npt.NDArray[Any]]:\n    \"\"\"Create sectorized circular region masks.\n\n    First circular masks with the provided radii are generated. Then ring masks\n    are created by subtracting the first circular mask from the second and so\n    on.\n    If you want the complete ring, set the respective n_sectors entry to 1. You  can split\n    the ring into n sectors by setting the respective entry to n.\n    Setting a number in `offsets` rotates the respective ring sectors by n\n    degree.\n\n    Args:\n        mask_shape: Output shape of the computed masks\n        radii: Ascending radii of the circular regions in pixels\n        n_sectors: Number of sectors corresponding to the radii\n        offsets: Angular offset of first sector corresponding to the radii\n        clockwise: If True sectors are added clockwise starting from the start_angles\n        smooth_edges: If True, compute non binary masks where edges might be shared between adjacent regions\n\n    Returns:\n    \"\"\"\n    # Create circles\n    circles = []\n    for radius in radii:\n        circles.append(circle_mask(radius, mask_shape, smooth_edges))\n\n    level_sector_parts = []\n    for n_sec, start_angle in zip(n_sectors, offsets):\n        if n_sec is not None:\n            level_sector_parts.append(\n                create_sectors(\n                    mask_shape,\n                    n_sectors=n_sec,\n                    start_angle=start_angle,\n                    clockwise=clockwise,\n                    smooth_edges=smooth_edges,\n                ))\n\n    rings = [circles[0]]\n    for i, _ in enumerate(circles):\n        if i + 1 &gt;= len(circles):\n            break\n        elif not radii[i] &lt; radii[i + 1]:\n            break\n        else:\n            rings.append(-circles[i] + circles[i + 1])\n\n    pairs = zip(rings, level_sector_parts)\n\n    all_masks = []\n    for cir, sectors in pairs:\n        for sec in sectors:\n            all_masks.append(cir * sec)\n\n    return all_masks\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.create_sectors","title":"<code>create_sectors(mask_shape, n_sectors=4, start_angle=0, clockwise=False, smooth_edges=False)</code>","text":"<p>Create masks for n radial sectors.</p> <p>By default the first sector is the first quadrant, and the remaining 3 sectors are added counter clockwise.</p> <p>For a binary mask pixels can not belong to two mask without changing the sum over all masks. But for pixels at the sector edges it is not clear to which sector they belong and assigning them to two sectors partially might be desired. Hence if smooth_edges is True, we create 5 times bigger binary masks and then use the anti-aliasing from downscaling them to the desired shape to create a float mask.</p> <p>Parameters:</p> Name Type Description Default <code>mask_shape</code> <code>tuple[int, int]</code> required <code>n_sectors</code> <code>int</code> <code>4</code> <code>start_angle</code> <code>int</code> <code>0</code> <code>clockwise</code> <code>bool</code> <code>False</code> <code>smooth_edges</code> <code>bool</code> <code>False</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>def create_sectors(mask_shape: tuple[int, int],\n                   n_sectors: int = 4,\n                   start_angle: int = 0,\n                   clockwise: bool = False,\n                   smooth_edges: bool = False) -&gt; list[npt.NDArray[Any]]:\n    \"\"\"Create masks for n radial sectors.\n\n    By default the first sector is the first quadrant, and the remaining 3\n    sectors are added counter clockwise.\n\n    For a binary mask pixels can not belong to two mask without changing the\n    sum over all masks. But for pixels at the sector edges it is not clear to\n    which sector they belong and assigning them to two sectors partially might\n    be desired. Hence if smooth_edges is True, we create 5 times bigger binary\n    masks and then use the anti-aliasing from downscaling them to the desired\n    shape to create a float mask.\n\n    Args:\n        mask_shape:\n        n_sectors:\n        start_angle:\n        clockwise:\n        smooth_edges:\n\n    Returns:\n    \"\"\"\n    if smooth_edges:\n        work_shape = (mask_shape[0] * 5, mask_shape[1] * 5)\n    else:\n        work_shape = mask_shape\n\n    theta = theta_filtergrid(work_shape, quadrant_shift=False)\n    # Convert from angles in radian range [-pi, +pi] to degree range [0, 360]\n    theta = theta / np.pi * 180\n    theta[np.where(theta &lt; 0)] += 360\n\n    masks = []\n    sector_size = 360 / n_sectors\n    for i in range(n_sectors):\n        if clockwise:\n            theta = np.flip(theta, axis=1)\n            sector_start = start_angle - i * sector_size\n            sector_end = start_angle - (i + 1) * sector_size\n        else:\n            sector_start = start_angle + i * sector_size\n            sector_end = start_angle + (i + 1) * sector_size\n\n        sector_start = sector_start % 360\n        sector_end = sector_end % 360\n\n        mask = np.zeros(work_shape)\n        # Handle clockwise and counter-clockwise sector rotation\n        if clockwise:\n\n            if sector_start &gt; sector_end:\n                # If rotating clockwise the start angle is bigger than the end angle\n                selection = np.where(\n                    np.logical_and(theta &lt;= sector_start, theta &gt; sector_end))\n            else:\n                # If this is not the case, only the end angle has crossed the 0\u00b0\n                selection = np.where(\n                    np.logical_or(theta &lt;= sector_start, theta &gt; sector_end))\n        else:\n            if sector_start &lt; sector_end:\n                # If rotating counter-clockwise the start angle is smaller than the end\n                selection = np.where(\n                    np.logical_and(theta &gt;= sector_start, theta &lt; sector_end))\n            else:\n                # If this is not the case only the end angle has crossed the 360\u00b0\n                selection = np.where(\n                    np.logical_or(theta &gt;= sector_start, theta &lt; sector_end))\n\n        mask[selection] = 1\n\n        if smooth_edges:\n            mask = transform.resize(mask, mask_shape)\n\n        masks.append(mask)\n\n    return masks\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.filtergrid","title":"<code>filtergrid(size, quadrant_shift=True, normalize=True)</code>  <code>cached</code>","text":"<p>Generates grid for constructing frequency domain filters.</p> <p>Coordinate matrices for x and y value for a 2D array. The out can be quadrant shifted and / or normalized. This is basically a wrapper around np.meshgrid.</p> <p>Inspired by filtergrid.m found at https://www.peterkovesi.com/matlabfns/</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Shape</code> <p>Size of the filter</p> required <code>quadrant_shift</code> <code>bool</code> <p>Quadrant shift such that 0 values / frequencies are at the corners</p> <code>True</code> <code>normalize</code> <code>bool</code> <p>Normalize the range to [-0.5,0.5]</p> <code>True</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>@functools.lru_cache(maxsize=8)\ndef filtergrid(size: Shape,\n               quadrant_shift: bool = True,\n               normalize: bool = True) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generates grid for constructing frequency domain filters.\n\n    Coordinate matrices for x and y value for a 2D array. The out can be quadrant shifted\n    and / or normalized. This is basically a wrapper around np.meshgrid.\n\n    Inspired by filtergrid.m found at https://www.peterkovesi.com/matlabfns/\n\n    Args:\n        size: Size of the filter\n        quadrant_shift: Quadrant shift such that 0 values / frequencies are at the corners\n        normalize: Normalize the range to [-0.5,0.5]\n\n    Returns:\n    \"\"\"\n    if type(size) is int:\n        rows = cols = size\n    else:\n        rows = size[0]\n        cols = size[1]\n\n    range_1 = np.linspace(-(cols // 2), np.floor((cols - 1) / 2), cols)\n    range_2 = np.linspace(-(rows // 2), np.floor((rows - 1) / 2), rows)\n\n    if normalize:\n        range_1 = range_1 / cols\n        range_2 = range_2 / rows\n\n    x, y = np.meshgrid(range_1, range_2)\n\n    # Quadrant shift so that filters are constructed with 0 frequency at the corners\n    if quadrant_shift:\n        x = np.fft.ifftshift(x)\n        y = np.fft.ifftshift(y)\n\n    return x.T, y.T\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.grid","title":"<code>grid(mask_shape, radii, laterality, n_sectors=1, offsets=0, center=None, smooth_edges=False, radii_scale=1)</code>","text":"<p>Create a quantification grid.</p> <p>Parameters:</p> Name Type Description Default <code>mask_shape</code> <code>tuple[int, int]</code> <p>Output shape of the computed masks</p> required <code>radii</code> <code>Union[Sequence[Union[int, float]], int, float]</code> <p>Ascending radii of the circular regions in pixels</p> required <code>laterality</code> <code>str</code> <p>OD/OS depending for which eye to compute the grid</p> required <code>n_sectors</code> <code>Union[Sequence[Union[int, float]], int, float]</code> <p>Number of sectors corresponding to the radii</p> <code>1</code> <code>offsets</code> <code>Union[Sequence[Union[int, float]], int, float]</code> <p>Sector offsets from the horizonal line on the nasal side in degree</p> <code>0</code> <code>center</code> <code>Optional[tuple]</code> <p>Center location of the computed masks</p> <code>None</code> <code>smooth_edges</code> <code>bool</code> <p>If True, compute non binary masks where edges might be shared between adjacent regions</p> <code>False</code> <code>radii_scale</code> <code>Union[int, float]</code> <code>1</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>def grid(\n    mask_shape: tuple[int, int],\n    radii: Union[Sequence[Union[int, float]], int, float],\n    laterality: str,\n    n_sectors: Union[Sequence[Union[int, float]], int, float] = 1,\n    offsets: Union[Sequence[Union[int, float]], int, float] = 0,\n    center: Optional[tuple] = None,\n    smooth_edges: bool = False,\n    radii_scale: Union[int, float] = 1,\n) -&gt; dict[str, npt.NDArray[Any]]:\n    \"\"\"Create a quantification grid.\n\n    Args:\n        mask_shape: Output shape of the computed masks\n        radii: Ascending radii of the circular regions in pixels\n        laterality: OD/OS depending for which eye to compute the grid\n        n_sectors: Number of sectors corresponding to the radii\n        offsets: Sector offsets from the horizonal line on the nasal side in degree\n        center: Center location of the computed masks\n        smooth_edges: If True, compute non binary masks where edges might be shared between adjacent regions\n        radii_scale:\n\n    Returns:\n    \"\"\"\n    # Make sure radii, n_sectors and offsets are lists even if you get numbers or tuples\n    radii = [radii] if isinstance(radii, (int, float)) else list(radii)\n    if not sorted(radii) == radii:\n        raise ValueError('radii have to be given in ascending order')\n    input_radii = radii\n    radii = [r / radii_scale for r in radii]\n\n    n_sectors = [n_sectors] if isinstance(n_sectors,\n                                          (int, float)) else list(n_sectors)\n    if len(n_sectors) == 1:\n        n_sectors = n_sectors * len(radii)\n\n    offsets = [offsets] if isinstance(offsets, (int, float)) else list(offsets)\n    if len(offsets) == 1:\n        offsets = offsets * len(radii)\n\n    clockwise = False\n    masks = create_grid_regions(\n        mask_shape,\n        tuple(radii),\n        tuple(n_sectors),\n        tuple(offsets),\n        clockwise,\n        smooth_edges,\n    )\n\n    names = []\n    radii = [0.0] + radii\n    input_radii = [0] + input_radii\n    for i, r in enumerate(radii):\n        if i + 1 &gt;= len(radii):\n            break\n        for s in range(n_sectors[i]):\n            names.append(\n                f'Radius: {input_radii[i]}-{input_radii[i+1]} Sector: {s}')\n\n    masks = {name: mask for name, mask in zip(names, masks)}\n    if laterality == 'OS':\n        masks = {name: np.flip(m, axis=1) for name, m in masks.items()}\n    elif laterality == 'OD':\n        pass\n    else:\n        raise ValueError('laterality has to be one of OD/OS')\n\n    if center is not None:\n        translation = transform.AffineTransform(translation=np.array(center) -\n                                                np.array(mask_shape) / 2)\n        masks = {\n            name: transform.warp(masks[name], translation.inverse)\n            for name in masks.keys()\n        }\n\n    return masks\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.radius_filtergrid","title":"<code>radius_filtergrid(size, quadrant_shift=True, normalize=True)</code>  <code>cached</code>","text":"<p>Radius Filtergrid.</p> <p>A matrix containing the radius from the center. This radius is in range [0, 0.5] if normalized. The result can be quadrant shifted such that the 0 values are in the corners.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Shape</code> <p>Size of the filter</p> required <code>quadrant_shift</code> <code>bool</code> <p>Quadrant shift such that 0 values / frequencies are at the corners</p> <code>True</code> <code>normalize</code> <code>bool</code> <p>Normalize radius to [0 ,0.5]</p> <code>True</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>@functools.lru_cache(maxsize=8)\ndef radius_filtergrid(size: Shape,\n                      quadrant_shift: bool = True,\n                      normalize: bool = True) -&gt; np.ndarray:\n    \"\"\"Radius Filtergrid.\n\n    A matrix containing the radius from the center. This radius is in range [0, 0.5] if normalized.\n    The result can be quadrant shifted such that the 0 values are in the corners.\n\n    Args:\n        size: Size of the filter\n        quadrant_shift: Quadrant shift such that 0 values / frequencies are at the corners\n        normalize: Normalize radius to [0 ,0.5]\n\n    Returns:\n    \"\"\"\n    x, y = filtergrid(size, quadrant_shift, normalize)\n    radius = np.sqrt(x**2 + y**2)\n    return radius\n</code></pre>"},{"location":"reference/src/eyepy/core/grids/#eyepy.core.grids.theta_filtergrid","title":"<code>theta_filtergrid(size, quadrant_shift=True)</code>  <code>cached</code>","text":"<p>Theta Filtergrid.</p> <p>A matrix containing the polar angle in radian at the respective position for a circle centered in the matrix. The result can be returned quadrant shifted. The angle is 0 for all points on the positive x-axis. The angles are pi/2 (90\u00b0) and -pi/2 (-90\u00b0) on the positive and negative y-axis respectively. On the negative x-axis the angle is pi (180\u00b0). If you need the angle to be in range [0, 2pi] instead of [-pi, pi], you can simply add 2pi whenever the angle is negative.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>Shape</code> <p>Size of the filter</p> required <code>quadrant_shift</code> <code>bool</code> <p>Quadrant shift such that 0 values / frequencies are at the corners</p> <code>True</code> <p>Returns:</p> Source code in <code>src/eyepy/core/grids.py</code> <pre><code>@functools.lru_cache(maxsize=8)\ndef theta_filtergrid(size: Shape, quadrant_shift: bool = True) -&gt; np.ndarray:\n    \"\"\"Theta Filtergrid.\n\n    A matrix containing the polar angle in radian at the respective position for a circle centered in the matrix.\n    The result can be returned quadrant shifted. The angle is 0 for all points on the positive x-axis.\n    The angles are pi/2 (90\u00b0) and -pi/2 (-90\u00b0) on the positive and negative y-axis respectively. On the negative\n    x-axis the angle is pi (180\u00b0). If you need the angle to be in range [0, 2pi] instead of [-pi, pi], you can simply\n    add 2pi whenever the angle is negative.\n\n    Args:\n        size: Size of the filter\n        quadrant_shift: Quadrant shift such that 0 values / frequencies are at the corners\n\n    Returns:\n    \"\"\"\n    y, x = filtergrid(size, quadrant_shift)\n\n    # Matrix values contain polar angle.\n    # 0 angle starts on the horizontal line and runs counter clock-wise\n    theta = np.arctan2(-y, x)\n\n    return theta\n</code></pre>"},{"location":"reference/src/eyepy/core/mask_compression/","title":"mask_compression","text":""},{"location":"reference/src/eyepy/core/mask_compression/#eyepy.core.mask_compression","title":"<code>eyepy.core.mask_compression</code>","text":"<p>Utilities for compressing and decompressing boolean masks using packbits.</p> <p>This module provides functions to compress boolean masks using numpy.packbits for efficient storage and to decompress them back to their original form.</p>"},{"location":"reference/src/eyepy/core/mask_compression/#eyepy.core.mask_compression.compress_boolean_mask","title":"<code>compress_boolean_mask(mask)</code>","text":"<p>Compress a boolean mask using packbits.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>A boolean numpy array of any shape</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>A tuple of (compressed_data, metadata) where:</p> <code>dict</code> <ul> <li>compressed_data: bytes from np.packbits(mask.ravel())</li> </ul> <code>tuple[bytes, dict]</code> <ul> <li>metadata: dict containing 'shape' to reconstruct the original shape</li> </ul> Source code in <code>src/eyepy/core/mask_compression.py</code> <pre><code>def compress_boolean_mask(mask: npt.NDArray[np.bool_]) -&gt; tuple[bytes, dict]:\n    \"\"\"Compress a boolean mask using packbits.\n\n    Args:\n        mask: A boolean numpy array of any shape\n\n    Returns:\n        A tuple of (compressed_data, metadata) where:\n        - compressed_data: bytes from np.packbits(mask.ravel())\n        - metadata: dict containing 'shape' to reconstruct the original shape\n    \"\"\"\n    # Flatten the mask\n    flat_mask = mask.ravel()\n\n    # Pack bits\n    packed = np.packbits(flat_mask)\n\n    # Store metadata\n    metadata = {\n        'shape': list(mask.shape),\n        'dtype': 'bool',\n    }\n\n    return packed.tobytes(), metadata\n</code></pre>"},{"location":"reference/src/eyepy/core/mask_compression/#eyepy.core.mask_compression.decompress_boolean_mask","title":"<code>decompress_boolean_mask(compressed_data, metadata)</code>","text":"<p>Decompress a boolean mask from packbits format.</p> <p>Parameters:</p> Name Type Description Default <code>compressed_data</code> <code>bytes</code> <p>bytes from np.packbits</p> required <code>metadata</code> <code>dict</code> <p>dict containing 'shape' from compress_boolean_mask</p> required <p>Returns:</p> Type Description <code>NDArray[bool_]</code> <p>The decompressed boolean mask with original shape</p> Source code in <code>src/eyepy/core/mask_compression.py</code> <pre><code>def decompress_boolean_mask(\n    compressed_data: bytes,\n    metadata: dict,\n) -&gt; npt.NDArray[np.bool_]:\n    \"\"\"Decompress a boolean mask from packbits format.\n\n    Args:\n        compressed_data: bytes from np.packbits\n        metadata: dict containing 'shape' from compress_boolean_mask\n\n    Returns:\n        The decompressed boolean mask with original shape\n    \"\"\"\n    # Convert bytes back to packed array\n    packed = np.frombuffer(compressed_data, dtype=np.uint8)\n\n    # Unpack bits\n    shape = metadata['shape']\n    total_elements = np.prod(shape)\n    unpacked = np.unpackbits(packed)[:total_elements]\n\n    # Reshape to original shape\n    mask = unpacked.astype(bool).reshape(shape)\n\n    return mask\n</code></pre>"},{"location":"reference/src/eyepy/core/mask_compression/#eyepy.core.mask_compression.is_boolean_array","title":"<code>is_boolean_array(arr)</code>","text":"<p>Check if an array is of boolean dtype.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>NDArray</code> <p>numpy array to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if array dtype is bool, False otherwise</p> Source code in <code>src/eyepy/core/mask_compression.py</code> <pre><code>def is_boolean_array(arr: npt.NDArray) -&gt; bool:\n    \"\"\"Check if an array is of boolean dtype.\n\n    Args:\n        arr: numpy array to check\n\n    Returns:\n        True if array dtype is bool, False otherwise\n    \"\"\"\n    return arr.dtype == np.bool_\n</code></pre>"},{"location":"reference/src/eyepy/core/plotting/","title":"plotting","text":""},{"location":"reference/src/eyepy/core/plotting/#eyepy.core.plotting","title":"<code>eyepy.core.plotting</code>","text":""},{"location":"reference/src/eyepy/core/plotting/#eyepy.core.plotting.plot_scalebar","title":"<code>plot_scalebar(scale, scale_unit, scale_length=None, pos=(100, 100), flip_x=False, flip_y=False, color='white', linewidth=1.5, ax=None, **kwargs)</code>","text":"<p>Plot a scalebar for an image.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>tuple[float, float]</code> <p>tuple of floats (x, y) with the scale in units per pixel. If the <code>scale_unit</code> is \"px\" the scale is ignored.</p> required <code>scale_unit</code> <code>str</code> <p>unit of the scalebar (\"px\" or \"\u00b5m\", or \"mm\")</p> required <code>scale_length</code> <code>Optional[Union[int, float]]</code> <p>length of the scalebar in units</p> <code>None</code> <code>pos</code> <code>tuple[int, int]</code> <p>position of the scalebar in pixels</p> <code>(100, 100)</code> <code>flip_x</code> <code>bool</code> <p>flip the scalebar in x direction</p> <code>False</code> <code>flip_y</code> <code>bool</code> <p>flip the scalebar in y direction</p> <code>False</code> <code>color</code> <code>str</code> <p>color of the scalebar</p> <code>'white'</code> <code>linewidth</code> <code>float</code> <p>linewidth of the scalebar</p> <code>1.5</code> <code>ax</code> <code>Optional[Axes]</code> <p>matplotlib axis to plot on</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>additional keyword arguments passed to ax.plot</p> <code>{}</code> <p>Returns:     None</p> Source code in <code>src/eyepy/core/plotting.py</code> <pre><code>def plot_scalebar(scale: tuple[float, float],\n                  scale_unit: str,\n                  scale_length: Optional[Union[int, float]] = None,\n                  pos: tuple[int, int] = (100, 100),\n                  flip_x: bool = False,\n                  flip_y: bool = False,\n                  color: str = 'white',\n                  linewidth: float = 1.5,\n                  ax: Optional[plt.Axes] = None,\n                  **kwargs: dict) -&gt; None:\n    \"\"\"Plot a scalebar for an image.\n\n    Args:\n        scale: tuple of floats (x, y) with the scale in units per pixel. If the `scale_unit` is \"px\" the scale is ignored.\n        scale_unit: unit of the scalebar (\"px\" or \"\u00b5m\", or \"mm\")\n        scale_length: length of the scalebar in units\n        pos: position of the scalebar in pixels\n        flip_x: flip the scalebar in x direction\n        flip_y: flip the scalebar in y direction\n        color: color of the scalebar\n        linewidth: linewidth of the scalebar\n        ax: matplotlib axis to plot on\n        **kwargs: additional keyword arguments passed to ax.plot\n    Returns:\n        None\n    \"\"\"\n    ax = plt.gca() if ax is None else ax\n\n    x, y = pos\n\n    if scale_unit == 'px':\n        scale = (1.0, 1.0)\n\n    if scale_length is None:\n        if scale_unit == 'px':\n            scale_length = 100\n        elif scale_unit == '\u00b5m':\n            scale_length = 500\n        elif scale_unit == 'mm':\n            scale_length = 0.5\n        else:\n            logger.info(\n                f'Unknown scale unit: {scale_unit}. Scalebar not plotted.')\n            return\n\n    x_start = x\n    x_end = x + (scale_length / scale[0])\n\n    y_start = y\n    y_end = y - (scale_length / scale[1])\n\n    text_x = x + 8\n    text_y = y - 8\n\n    if flip_x:\n        x_start = x - (scale_length / scale[0])\n        x_end = x\n        text_x = x - 50\n\n    if flip_y:\n        y_start = y + (scale_length / scale[1])\n        y_end = y\n        text_y = y + 17\n\n    # Plot horizontal line\n    ax.plot([x_start, x_end], [y, y],\n            color=color,\n            linewidth=linewidth,\n            **kwargs)\n    # Plot vertical line\n    ax.plot([x, x], [y_start, y_end],\n            color=color,\n            linewidth=linewidth,\n            **kwargs)\n\n    ax.text(text_x,\n            text_y,\n            f'{scale_length}{scale_unit}',\n            fontsize=7,\n            weight='bold',\n            color=color)\n</code></pre>"},{"location":"reference/src/eyepy/core/plotting/#eyepy.core.plotting.plot_watermark","title":"<code>plot_watermark(ax)</code>","text":"<p>Add a watermark in the lower right corner of a matplotlib axes object.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Axes object</p> required <p>Returns:     None</p> Source code in <code>src/eyepy/core/plotting.py</code> <pre><code>def plot_watermark(ax: plt.Axes) -&gt; None:\n    \"\"\"Add a watermark in the lower right corner of a matplotlib axes object.\n\n    Args:\n        ax: Axes object\n    Returns:\n        None\n    \"\"\"\n    ax.text(0.98,\n            0.02,\n            'Visualized with eyepy',\n            fontsize=6,\n            color='white',\n            ha='right',\n            va='bottom',\n            alpha=0.4,\n            transform=ax.transAxes,\n            bbox=dict(boxstyle='Round',\n                      facecolor='gray',\n                      alpha=0.2,\n                      linewidth=0))\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/","title":"utils","text":""},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils","title":"<code>eyepy.core.utils</code>","text":""},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.DynamicDefaultDict","title":"<code>DynamicDefaultDict(factory)</code>","text":"<p>               Bases: <code>dict</code></p> <p>A defaultdict for which the factory function has access to the missing key.</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def __init__(self, factory):\n    self.factory = factory\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.angio_intensity_transform","title":"<code>angio_intensity_transform(data)</code>","text":"<p>Wrapper around from_angio_intensity.</p> <p>Transform intensities from Heyex ANGIO exports to achieve a constrast similar to the one used in Heyex.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayFloat</code> <p>Input data</p> required <p>Returns:</p> Type Description <code>NDArrayInt</code> <p>Transformed data</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def angio_intensity_transform(data: NDArrayFloat) -&gt; NDArrayInt:\n    \"\"\"Wrapper around from_angio_intensity.\n\n    Transform intensities from Heyex ANGIO exports to achieve a constrast similar to the one used in Heyex.\n\n    Args:\n        data: Input data\n\n    Returns:\n        Transformed data\n    \"\"\"\n    return from_angio_intensity(data)\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.default_intensity_transform","title":"<code>default_intensity_transform(data)</code>","text":"<p>Default intensity transform.</p> <p>By default intensities are not changed.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Input data unchanged</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def default_intensity_transform(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Default intensity transform.\n\n    By default intensities are not changed.\n\n    Args:\n        data: Input data\n\n    Returns:\n        Input data unchanged\n    \"\"\"\n    return data\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.default_par_algorithm","title":"<code>default_par_algorithm(data)</code>","text":"<p>Default Projection Artifact Removal (PAR) algorithm.</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def default_par_algorithm(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Default Projection Artifact Removal (PAR) algorithm.\"\"\"\n    return data\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.drusen","title":"<code>drusen(rpe_height, bm_height, volume_shape, minimum_height=2)</code>","text":"<p>Compute drusen from the RPE and BM layer segmentation.</p> <p>First estimate the ideal RPE based on a histogram of the RPE heights relativ to the BM. Then compute drusen as the area between the RPE and the normal RPE</p> <p>Parameters:</p> Name Type Description Default <code>rpe_height</code> <code>NDArrayFloat</code> <p>The RPE height as offset from the lower border of the B-Scan</p> required <code>bm_height</code> <code>NDArrayFloat</code> <p>The BM height as offset from the lower border of the B-Scan</p> required <code>volume_shape</code> <code>tuple[int, int, int]</code> <p>Shape of the OCT volume (number of B-Scans, height, width)</p> required <code>minimum_height</code> <code>int</code> <p>Minimum height of a drusen in pixels</p> <code>2</code> <p>Returns:</p> Type Description <code>NDArrayBool</code> <p>A boolean array with the same shape as the OCT volume. True indicates a</p> <code>NDArrayBool</code> <p>voxel beeing part of a drusen.</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def drusen(rpe_height: NDArrayFloat,\n           bm_height: NDArrayFloat,\n           volume_shape: tuple[int, int, int],\n           minimum_height: int = 2) -&gt; NDArrayBool:\n    \"\"\"Compute drusen from the RPE and BM layer segmentation.\n\n    First estimate the ideal RPE based on a histogram of the RPE heights relativ\n    to the BM. Then compute drusen as the area between the RPE and the normal RPE\n\n    Args:\n        rpe_height: The RPE height as offset from the lower border of the B-Scan\n        bm_height: The BM height as offset from the lower border of the B-Scan\n        volume_shape: Shape of the OCT volume (number of B-Scans, height, width)\n        minimum_height: Minimum height of a drusen in pixels\n\n    Returns:\n        A boolean array with the same shape as the OCT volume. True indicates a\n        voxel beeing part of a drusen.\n    \"\"\"\n    # Estimate ideal RPE\n    if isinstance(rpe_height, EyeVolumeLayerAnnotation):\n        rpe_height = np.copy(rpe_height.data)\n    if isinstance(bm_height, EyeVolumeLayerAnnotation):\n        bm_height = np.copy(bm_height.data)\n\n    irpe = ideal_rpe(rpe_height, bm_height, volume_shape)\n    # Create drusen map, exclude layer boundaries from the mask (rpe_height+1).\n    drusen_map = mask_from_boundaries_loop(\n        upper=rpe_height+1, lower=irpe, height=volume_shape[1]\n    )\n    drusen_map = filter_by_height_enface(drusen_map, minimum_height)\n\n    return drusen_map\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.ideal_rpe","title":"<code>ideal_rpe(rpe_height, bm_height, volume_shape)</code>","text":"<p>Compute the ideal RPE from an RPE with Drusen.</p> <p>Parameters:</p> Name Type Description Default <code>rpe_height</code> <code>NDArrayFloat</code> <p>The RPE height as offset from the lower border of the B-Scan</p> required <code>bm_height</code> <code>NDArrayFloat</code> <p>The BM height as offset from the lower border of the B-Scan</p> required <code>volume_shape</code> <code>tuple[int, int, int]</code> <p>Shape of the OCT volume (number of B-Scans, height, width)</p> required <p>Returns:</p> Type Description <code>NDArrayFloat</code> <p>The ideal RPE height as offset from the lower border of the B-Scan</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def ideal_rpe(rpe_height: NDArrayFloat, bm_height: NDArrayFloat,\n              volume_shape: tuple[int, int, int]) -&gt; NDArrayFloat:\n    \"\"\"Compute the ideal RPE from an RPE with Drusen.\n\n    Args:\n        rpe_height: The RPE height as offset from the lower border of the B-Scan\n        bm_height: The BM height as offset from the lower border of the B-Scan\n        volume_shape: Shape of the OCT volume (number of B-Scans, height, width)\n\n    Returns:\n        The ideal RPE height as offset from the lower border of the B-Scan\n    \"\"\"\n    d, h, w = volume_shape\n\n    # compute shift needed to align the BM to the horizontal center line\n    shift = np.empty((d, w), dtype='int')\n    shift.fill(h - (h / 2))\n    shift = shift - bm_height\n\n    # now shift the RPE location array as well\n    shifted_rpe_height = rpe_height + shift\n\n    # Remove all NANs from the shifted RPE data\n    clean_shifted = shifted_rpe_height[~np.isnan(shifted_rpe_height)]\n\n    # Compute a histogram with a bin for every pixel height in a B-Scan\n    hist, edges = np.histogram(clean_shifted.flatten(),\n                               bins=np.arange(volume_shape[1]))\n\n    # Compute the ideal RPE as the mean of the biggest bin and its neighbours\n    lower_edge = edges[np.argmax(hist) - 1]\n    upper_edge = edges[np.argmax(hist) + 2]\n    irpe_height = np.mean(clean_shifted[np.logical_and(\n        clean_shifted &lt;= upper_edge, clean_shifted &gt;= lower_edge)])\n    ideal_rpe = np.full_like(shifted_rpe_height, irpe_height)\n\n    # Shift back into original image space\n    ideal_rpe = np.reshape(ideal_rpe, (d, w)) - shift\n\n    return ideal_rpe\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.mask_from_boundaries","title":"<code>mask_from_boundaries(upper, lower, height)</code>","text":"<p>Compute a boolean mask from upper and lower boundaries for each column using numpy broadcasting.</p> <p>The mask includes the upper boundary and excludes the lower boundary. To exclude the upper layer, add 1 to it before calling this function. To include the lower layer, add 1 to it before calling this function.</p> <p>This method is generally faster and more efficient for typical use cases. Use this when the proportion of NaN values in the boundaries is below 20%. For large volumes with mostly valid data, broadcasting is recommended.</p> <p>Parameters:</p> Name Type Description Default <code>upper</code> <code>ndarray</code> <p>2D array (slices, columns) of upper boundary indices.</p> required <code>lower</code> <code>ndarray</code> <p>2D array (slices, columns) of lower boundary indices.</p> required <code>height</code> <code>int</code> <p>int, the number of rows (y-dimension) in the mask.</p> required <p>Returns:</p> Name Type Description <code>mask</code> <code>ndarray</code> <p>3D boolean array (slices, height, columns)</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def mask_from_boundaries(upper: np.ndarray, lower: np.ndarray, height: int) -&gt; np.ndarray:\n    \"\"\"Compute a boolean mask from upper and lower boundaries for each column\n    using numpy broadcasting.\n\n    The mask includes the upper boundary and excludes the lower boundary.\n    To exclude the upper layer, add 1 to it before calling this function.\n    To include the lower layer, add 1 to it before calling this function.\n\n    This method is generally faster and more efficient for typical use cases.\n    Use this when the proportion of NaN values in the boundaries is below 20%.\n    For large volumes with mostly valid data, broadcasting is recommended.\n\n    Args:\n        upper: 2D array (slices, columns) of upper boundary indices.\n        lower: 2D array (slices, columns) of lower boundary indices.\n        height: int, the number of rows (y-dimension) in the mask.\n\n    Returns:\n        mask: 3D boolean array (slices, height, columns)\n    \"\"\"\n    upper = np.asarray(upper, dtype=float)\n    lower = np.asarray(lower, dtype=float)\n    nans = np.isnan(upper) | np.isnan(lower)\n    # Avoid casting issues with NaNs\n    upper = np.where(nans, -1, upper)\n    lower = np.where(nans, -1, lower)\n    # Round to nearest integer and clip to valid range\n    upper_idx = np.rint(upper).astype(int)\n    lower_idx = np.rint(lower).astype(int)\n    upper_idx = np.clip(upper_idx, 0, height)\n    lower_idx = np.clip(lower_idx, 0, height)\n\n    valid = ~nans &amp; (upper_idx &lt; lower_idx)\n    y_coords = np.arange(height)\n    mask = (\n        (y_coords[None, :, None] &gt;= upper_idx[:, None, :]) &amp;\n        (y_coords[None, :, None] &lt; lower_idx[:, None, :]) &amp;\n        (valid[:, None, :])\n    )\n    return mask\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.mask_from_boundaries_loop","title":"<code>mask_from_boundaries_loop(upper, lower, height)</code>","text":"<p>Looping variant of mask_from_boundaries, iterating only over valid columns.</p> <p>The mask includes the upper boundary and excludes the lower boundary. To exclude the upper layer, add 1 to it before calling this function. To include the lower layer, add 1 to it before calling this function.</p> <p>This method can be more efficient than broadcasting when the NaN or invalid column proportion (where upper &gt; lower) is above 20%. For highly masked data, the looping approach avoids extra work.</p> <p>Parameters:</p> Name Type Description Default <code>upper</code> <code>ndarray</code> <p>2D array (slices, columns) of upper boundary indices.</p> required <code>lower</code> <code>ndarray</code> <p>2D array (slices, columns) of lower boundary indices.</p> required <code>height</code> <code>int</code> <p>int, the number of rows (y-dimension) in the mask.</p> required <p>Returns:</p> Name Type Description <code>mask</code> <code>ndarray</code> <p>3D boolean array (slices, height, columns)</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def mask_from_boundaries_loop(\n    upper: np.ndarray, lower: np.ndarray, height: int\n) -&gt; np.ndarray:\n    \"\"\"Looping variant of mask_from_boundaries, iterating only over valid columns.\n\n    The mask includes the upper boundary and excludes the lower boundary.\n    To exclude the upper layer, add 1 to it before calling this function.\n    To include the lower layer, add 1 to it before calling this function.\n\n    This method can be more efficient than broadcasting when the NaN or invalid\n    column proportion (where upper &gt; lower) is above 20%.\n    For highly masked data, the looping approach avoids extra work.\n\n    Args:\n        upper: 2D array (slices, columns) of upper boundary indices.\n        lower: 2D array (slices, columns) of lower boundary indices.\n        height: int, the number of rows (y-dimension) in the mask.\n\n    Returns:\n        mask: 3D boolean array (slices, height, columns)\n    \"\"\"\n    upper = np.asarray(upper, dtype=float)\n    lower = np.asarray(lower, dtype=float)\n    nans = np.isnan(upper) | np.isnan(lower)\n    # Avoid casting issues with NaNs\n    upper = np.where(nans, -1, upper)\n    lower = np.where(nans, -1, lower)\n    # Round to nearest integer and clip to valid range\n    upper_idx = np.rint(upper).astype(int)\n    lower_idx = np.rint(lower).astype(int)\n    upper_idx = np.clip(upper_idx, 0, height)\n    lower_idx = np.clip(lower_idx, 0, height)\n\n    valid = ~nans &amp; (upper_idx &lt; lower_idx)\n    mask = np.zeros((upper.shape[0], height, upper.shape[1]), dtype=bool)\n    for sli, col in zip(*np.where(valid)):\n        mask[sli, upper_idx[sli, col]:lower_idx[sli, col], col] = True\n    return mask\n</code></pre>"},{"location":"reference/src/eyepy/core/utils/#eyepy.core.utils.vol_intensity_transform","title":"<code>vol_intensity_transform(data)</code>","text":"<p>Wrapper around from_vol_intensity.</p> <p>Transform intensities from Heyex VOL exports to achieve a constrast similar to the one used in Heyex.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>NDArrayFloat</code> <p>Input data</p> required <p>Returns:</p> Type Description <code>NDArrayUByte</code> <p>Transformed data</p> Source code in <code>src/eyepy/core/utils.py</code> <pre><code>def vol_intensity_transform(data: NDArrayFloat) -&gt; NDArrayUByte:\n    \"\"\"Wrapper around from_vol_intensity.\n\n    Transform intensities from Heyex VOL exports to achieve a constrast similar to the one used in Heyex.\n\n    Args:\n        data: Input data\n\n    Returns:\n        Transformed data\n    \"\"\"\n    return from_vol_intensity(data)\n</code></pre>"},{"location":"reference/src/eyepy/data/","title":"data","text":""},{"location":"reference/src/eyepy/data/#eyepy.data","title":"<code>eyepy.data</code>","text":""},{"location":"reference/src/eyepy/data/#eyepy.data.load","title":"<code>load(name)</code>","text":"<p>Load sample data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the sample data to load. Available options are: - 'drusen_patient': Sample data with many drusen. - 'healthy_OS': Healthy left eye volume. - 'healthy_OD': Healthy right eye volume. - 'healthy_OS_Angio': Healthy left eye OCT Angiography. - 'healthy_OD_Angio': Healthy right eye OCT Angiography.</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>ep.EyeVolume: The loaded eye volume data.</p> Source code in <code>src/eyepy/data/__init__.py</code> <pre><code>def load(name: str) -&gt; ep.EyeVolume:\n    \"\"\"Load sample data.\n\n    Args:\n        name: Name of the sample data to load.\n            Available options are:\n            - 'drusen_patient': Sample data with many drusen.\n            - 'healthy_OS': Healthy left eye volume.\n            - 'healthy_OD': Healthy right eye volume.\n            - 'healthy_OS_Angio': Healthy left eye OCT Angiography.\n            - 'healthy_OD_Angio': Healthy right eye OCT Angiography.\n\n    Returns:\n        ep.EyeVolume: The loaded eye volume data.\n    \"\"\"\n    url, import_func = SAMPLE_DATA[name]\n    file_ext = Path(url).suffix\n    data_path = EYEPY_DATA_DIR / name\n\n    if file_ext == '.zip':\n        # ZIP file: extract if not already extracted\n        if not data_path.is_dir():\n            download_path = EYEPY_DATA_DIR / (name + '.zip')\n            urllib.request.urlretrieve(url, download_path)\n            with zipfile.ZipFile(download_path, 'r') as zip_ref:\n                zip_ref.extractall(EYEPY_DATA_DIR)\n            download_path.unlink()\n        # Assume XML inside extracted folder for zip samples\n        return import_func(data_path / 'metaclean.xml')\n    else:\n        # Direct file (e.g., .vol): download if not present\n        if not data_path.exists():\n            urllib.request.urlretrieve(url, data_path)\n        return import_func(data_path)\n</code></pre>"},{"location":"reference/src/eyepy/io/","title":"io","text":""},{"location":"reference/src/eyepy/io/#eyepy.io","title":"<code>eyepy.io</code>","text":""},{"location":"reference/src/eyepy/io/#eyepy.io.HeVolWriter","title":"<code>HeVolWriter(volume)</code>","text":"Source code in <code>src/eyepy/io/he/vol_reader.py</code> <pre><code>def __init__(self, volume: EyeVolume):\n    self.volume = volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/","title":"import_functions","text":""},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions","title":"<code>eyepy.io.import_functions</code>","text":""},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_bscan_folder","title":"<code>import_bscan_folder(path)</code>","text":"<p>Read B-Scans from a folder.</p> <p>This function can be used to read B-scans from a folder in case that there is no additional metadata available.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the folder containing the B-Scans</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_bscan_folder(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read B-Scans from a folder.\n\n    This function can be used to read B-scans from a folder in case that\n    there is no additional metadata available.\n\n    Args:\n        path: Path to the folder containing the B-Scans\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    path = Path(path)\n    img_paths = sorted(list(path.iterdir()))\n    img_paths = [\n        p for p in img_paths if p.is_file()\n        and p.suffix.lower() in ['.jpg', '.jpeg', '.tiff', '.tif', '.png']\n    ]\n\n    images = []\n    for p in img_paths:\n        image = imageio.imread(p)\n        if len(image.shape) == 3:\n            image = image[..., 0]\n        images.append(image)\n\n    volume = np.stack(images, axis=0)\n    bscan_meta = [\n        EyeBscanMeta(start_pos=(0, i),\n                     end_pos=(volume.shape[2] - 1, i),\n                     pos_unit='pixel')\n        for i in range(volume.shape[0] - 1, -1, -1)\n    ]\n    meta = EyeVolumeMeta(scale_x=1,\n                         scale_y=1,\n                         scale_z=1,\n                         scale_unit='pixel',\n                         bscan_meta=bscan_meta)\n\n    return EyeVolume(data=volume, meta=meta)\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_duke_mat","title":"<code>import_duke_mat(path)</code>","text":"<p>Import an OCT volume from the Duke dataset.</p> <p>The dataset is available at https://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm OCT volumes are stored as .mat files which are parsed by this function and returned as EyeVolume object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the .mat file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_duke_mat(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Import an OCT volume from the Duke dataset.\n\n    The dataset is available at https://people.duke.edu/~sf59/RPEDC_Ophth_2013_dataset.htm\n    OCT volumes are stored as .mat files which are parsed by this function and returned as\n    EyeVolume object.\n\n    Args:\n        path: Path to the .mat file\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    import scipy.io as sio\n\n    loaded = sio.loadmat(path)\n    volume = np.moveaxis(loaded['images'], -1, 0)\n    layer_maps = np.moveaxis(loaded['layerMaps'], -1, 0)\n\n    bscan_meta = [\n        EyeBscanMeta(\n            start_pos=(0, 0.067 * i),\n            end_pos=(0.0067 * (volume.shape[2] - 1), 0.067 * i),\n            pos_unit='mm',\n        ) for i in range(volume.shape[0] - 1, -1, -1)\n    ]\n    meta = EyeVolumeMeta(\n        scale_x=0.0067,\n        scale_y=0.0045,  # https://retinatoday.com/articles/2008-may/0508_10-php\n        scale_z=0.067,\n        scale_unit='mm',\n        bscan_meta=bscan_meta,\n        age=int(loaded['Age'][0][0]),\n    )\n\n    volume = EyeVolume(data=volume, meta=meta)\n    names = {0: 'ILM', 1: 'IBRPE', 2: 'BM'}\n    for i, height_map in enumerate(layer_maps):\n        volume.add_layer_annotation(\n            height_map,\n            name=names[i],\n        )\n\n    return volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_dukechiu2_mat","title":"<code>import_dukechiu2_mat(path)</code>","text":"<p>Import an OCT volume from the Duke dataset (Chiu_BOE_2014).</p> <p>The dataset is available at https://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm OCT volumes are stored as .mat files which are parsed by this function and returned as EyeVolume object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the .mat file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_dukechiu2_mat(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Import an OCT volume from the Duke dataset (Chiu_BOE_2014).\n\n    The dataset is available at https://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm\n    OCT volumes are stored as .mat files which are parsed by this function and returned as\n    EyeVolume object.\n\n    Args:\n        path: Path to the .mat file\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    import scipy.io as sio\n\n    loaded = sio.loadmat(path)\n    volume = np.moveaxis(loaded['images'], -1, 0)\n\n    layer_versions = [\n        'manualLayers1', 'manualLayers2', 'automaticLayersDME',\n        'automaticLayersNormal'\n    ]\n    fluid_versions = ['manualFluid1', 'manualFluid2', 'automaticFluidDME']\n    all_layer_maps = {\n        x: np.moveaxis(loaded[x], -1, 1).astype(np.float32)\n        for x in layer_versions\n    }\n    # Manual annotations are instances of fluid regions, we convert to binary here\n    all_pixel_maps = {\n        x: (np.moveaxis(loaded[x], -1, 0) &gt; 0).astype(bool)\n        for x in fluid_versions\n    }\n\n    bscan_meta = [\n        EyeBscanMeta(\n            start_pos=(0, 0.123 * i),\n            end_pos=(0.01133 * (volume.shape[2] - 1), 0.123 * i),\n            pos_unit='mm',\n        ) for i in range(volume.shape[0] - 1, -1, -1)\n    ]\n    meta = EyeVolumeMeta(\n        scale_x=\n        0.01133,  # This value is the average of min and max values given in the paper.\n        scale_y=0.00387,\n        scale_z=\n        0.123,  # This value is the average of min and max values given in the paper.\n        scale_unit='mm',\n        bscan_meta=bscan_meta,\n    )\n\n    volume = EyeVolume(data=volume, meta=meta)\n    names = {\n        7: 'BM',\n        6: 'OS/RPE',\n        5: 'ISM/ISE',\n        4: 'OPL/ONL',\n        3: 'INL/OPL',\n        2: 'IPL/INL',\n        1: 'NFL/GCL',\n        0: 'ILM'\n    }\n\n    for layer_version in layer_versions:\n        layer_maps = all_layer_maps[layer_version]\n        for i, height_map in enumerate(layer_maps):\n            volume.add_layer_annotation(\n                height_map,\n                name=f'{layer_version}_{names[i]}',\n            )\n\n    for fluid_version in fluid_versions:\n        pixel_map = all_pixel_maps[fluid_version]\n        for i, height_map in enumerate(pixel_map):\n            volume.add_pixel_annotation(\n                pixel_map,\n                name=fluid_version,\n            )\n\n    return volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_heyex_angio_vol","title":"<code>import_heyex_angio_vol(path)</code>","text":"<p>Read a Heyex Angio VOL file.</p> <p>This function is a thin wrapper around the HeVolReader class which you can use directly if you need more control.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the Angio VOL file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_heyex_angio_vol(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read a Heyex Angio VOL file.\n\n    This function is a thin wrapper around the HeVolReader class\n    which you can use directly if you need more control.\n\n    Args:\n        path: Path to the Angio VOL file\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    from .he import HeVolReader\n    return HeVolReader(path, type='octa').volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_heyex_e2e","title":"<code>import_heyex_e2e(path)</code>","text":"<p>Read a Heyex E2E file.</p> <p>This function is a thin wrapper around the HeE2eReader class and returns the first of potentially multiple OCT volumes. If you want to read all volumes, or need more control, you can use the HeE2eReader class directly.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the E2E file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If E2E extras are not installed (construct-typing)</p>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_heyex_e2e--notes","title":"Notes","text":"<p>This function requires additional dependencies. Install with: <code>pip install eyepy[e2e]</code></p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_heyex_e2e(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read a Heyex E2E file.\n\n    This function is a thin wrapper around the HeE2eReader class and\n    returns the first of potentially multiple OCT volumes. If you want to\n    read all volumes, or need more control, you can use the\n    [HeE2eReader][eyepy.io.he.e2e_reader.HeE2eReader] class directly.\n\n    Args:\n        path: Path to the E2E file\n\n    Returns:\n        Parsed data as EyeVolume object\n\n    Raises:\n        ImportError: If E2E extras are not installed (construct-typing)\n\n    Notes\n    -----\n    This function requires additional dependencies.\n    Install with: `pip install eyepy[e2e]`\n    \"\"\"\n    try:\n        from .he import HeE2eReader\n    except ImportError as exc:\n        raise ImportError(\n            'Reading E2E files requires additional dependencies.'\n            'Install with pip install eyepy[e2e]'\n        ) from exc\n\n    reader = HeE2eReader(path)\n    if len(reader.series) &lt; 1:\n        logger.info(\n            f'There are {len(reader.series)} Series stored in the E2E file. If you want to read all of them, use the HeE2eReader class directly.'\n        )\n    with reader as open_reader:\n        ev = open_reader.volume\n    return ev\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_heyex_vol","title":"<code>import_heyex_vol(path)</code>","text":"<p>Read a Heyex VOL file.</p> <p>This function is a thin wrapper around the HeVolReader class which you can use directly if you need more control.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the VOL file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_heyex_vol(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read a Heyex VOL file.\n\n    This function is a thin wrapper around the HeVolReader class\n    which you can use directly if you need more control.\n\n    Args:\n        path: Path to the VOL file\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    from .he import HeVolReader\n    return HeVolReader(path).volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_heyex_xml","title":"<code>import_heyex_xml(path)</code>","text":"<p>Read a Heyex XML file.</p> <p>This function is a thin wrapper around the HeXmlReader class which you can use directly if you need more control.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the XML file or the folder containing the XML file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_heyex_xml(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read a Heyex XML file.\n\n    This function is a thin wrapper around the HeXmlReader class\n    which you can use directly if you need more control.\n\n    Args:\n        path: Path to the XML file or the folder containing the XML file\n\n    Returns:\n        Parsed data as EyeVolume object\n    \"\"\"\n    from .he import HeXmlReader\n    return HeXmlReader(path).volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_retouch","title":"<code>import_retouch(path)</code>","text":"<p>Import an OCT volume from the Retouch dataset.</p> <p>The dataset is available upon request at https://retouch.grand-challenge.org/</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the folder containing the OCT volume</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If ITK is not installed</p>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_retouch--notes","title":"Notes","text":"<p>This function requires the optional <code>itk</code> dependency. Install it with: <code>pip install eyepy[itk]</code></p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_retouch(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Import an OCT volume from the Retouch dataset.\n\n    The dataset is available upon request at https://retouch.grand-challenge.org/\n\n    Args:\n        path: Path to the folder containing the OCT volume\n\n    Returns:\n        Parsed data as EyeVolume object\n\n    Raises:\n        ImportError: If ITK is not installed\n\n    Notes\n    -----\n    This function requires the optional `itk` dependency.\n    Install it with: `pip install eyepy[itk]`\n    \"\"\"\n    try:\n        import itk\n    except ImportError as exc:\n        raise ImportError(\n            'itk is required to read Retouch data. '\n            'Install it with: pip install eyepy[itk]'\n        ) from exc\n\n    path = Path(path)\n    data = itk.imread(str(path / 'oct.mhd'))\n\n    bscan_meta = [\n        EyeBscanMeta(\n            start_pos=(0, data['spacing'][0] * i),\n            end_pos=(data['spacing'][2] * (data.shape[2] - 1),\n                     data['spacing'][0] * i),\n            pos_unit='mm',\n        ) for i in range(data.shape[0] - 1, -1, -1)\n    ]\n\n    meta = EyeVolumeMeta(\n        scale_x=data['spacing'][2],\n        scale_y=data['spacing'][1],\n        scale_z=data['spacing'][0],\n        scale_unit='mm',\n        bscan_meta=bscan_meta,\n    )\n    # Todo: Add intensity transform instead. Topcon and Cirrus are stored as UCHAR while heidelberg is stored as USHORT\n    data = (data[...].astype(float) / np.iinfo(data[...].dtype).max *\n            255).astype(np.uint8)\n    eye_volume = EyeVolume(data=data[...], meta=meta)\n\n    if (path / 'reference.mhd').is_file():\n        annotation = itk.imread(str(path / 'reference.mhd'))\n        eye_volume.add_pixel_annotation(np.equal(annotation, 1),\n                                        name='IRF',\n                                        current_color='FF0000')\n        eye_volume.add_pixel_annotation(np.equal(annotation, 2),\n                                        name='SRF',\n                                        current_color='0000FF')\n        eye_volume.add_pixel_annotation(np.equal(annotation, 3),\n                                        name='PED',\n                                        current_color='FFFF00')\n\n    return eye_volume\n</code></pre>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_topcon_fda","title":"<code>import_topcon_fda(path)</code>","text":"<p>Read a Topcon fda file.</p> <p>This function is a wrapper around the FDA reader in OCT-Converter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the fda file</p> required <p>Returns:</p> Type Description <code>EyeVolume</code> <p>Parsed data as EyeVolume object</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If oct-converter is not installed</p>"},{"location":"reference/src/eyepy/io/import_functions/#eyepy.io.import_functions.import_topcon_fda--notes","title":"Notes","text":"<p>B-scan position and scaling data is computed assuming that B-scans were acquired in a horizontal raster pattern.</p> <p>This function requires the optional <code>oct-converter</code> dependency. Install it with: <code>pip install eyepy[fda]</code></p> Source code in <code>src/eyepy/io/import_functions.py</code> <pre><code>def import_topcon_fda(path: Union[str, Path]) -&gt; EyeVolume:\n    \"\"\"Read a Topcon fda file.\n\n    This function is a wrapper around the FDA reader in OCT-Converter.\n\n    Args:\n        path: Path to the fda file\n\n    Returns:\n        Parsed data as EyeVolume object\n\n    Raises:\n        ImportError: If oct-converter is not installed\n\n    Notes\n    -----\n    B-scan position and scaling data is computed assuming that B-scans\n    were acquired in a horizontal raster pattern.\n\n    This function requires the optional `oct-converter` dependency.\n    Install it with: `pip install eyepy[fda]`\n    \"\"\"\n    try:\n        from oct_converter.readers import FDA\n    except ImportError as exc:\n        raise ImportError(\n            'oct-converter is required to read FDA files. '\n            'Install it with: pip install eyepy[fda]'\n        ) from exc\n    reader = FDA(path, printing=False)\n\n    try:\n        oct_volume = reader.read_oct_volume()\n        segmentation = oct_volume.contours\n        metadata = oct_volume.metadata\n    except:\n        logger.warn('Regular B-scan read failed. Using alternative.')\n        oct_volume = reader.read_oct_volume_2()\n        segmentation = reader.read_segmentation()\n        metadata = reader.read_all_metadata()\n\n    localizer_image = reader.read_fundus_image().image\n    bscan = oct_volume.volume\n\n    # retrieve image dimensions and scaling\n    n_bscan = len(bscan)\n    n_axial = bscan[0].shape[0]\n    n_ascan = bscan[0].shape[1]\n\n    size_x = metadata['param_scan_04']['x_dimension_mm']\n    size_z = metadata['param_scan_04']['y_dimension_mm']\n\n    scale_x = size_x / (n_ascan - 1)\n    scale_y = metadata['param_scan_04']['z_resolution_um'] / 1000\n    scale_z = size_z / (n_bscan - 1)\n\n    # compute B-scan mm coordinates from fundus top-left corner\n    box = metadata['regist_info']['bounding_box_in_fundus_pixels']\n\n    scale_x_fun = size_x / (box[2] - box[0] - 1)\n    scale_z_fun = size_z / (box[3] - box[1] - 1)\n\n    x_0 = box[0] * scale_x_fun  # top-left x\n    z_0 = box[1] * scale_z_fun  # top-left y\n    x_1 = box[2] * scale_x_fun  # top-right x\n\n    # build metadata objects\n    bscan_meta = []\n    for i in range(n_bscan):\n        z = z_0 + i * scale_z\n        bscan_meta.append(\n            EyeBscanMeta(start_pos=(x_0, z), end_pos=(x_1, z), pos_unit='mm'))\n\n    volume_meta = EyeVolumeMeta(scale_x=scale_x,\n                                scale_y=scale_y,\n                                scale_z=scale_z,\n                                scale_unit='mm',\n                                bscan_meta=bscan_meta)\n\n    localizer_meta = EyeEnfaceMeta(scale_x=scale_x_fun,\n                                   scale_y=scale_z_fun,\n                                   scale_unit='mm',\n                                   modality='CFP',\n                                   laterality='unknown')\n\n    # build image ojects\n    localizer = EyeEnface(localizer_image, localizer_meta)\n    dims = (n_bscan, n_axial, n_ascan)\n    transformation = _compute_localizer_oct_transform(volume_meta,\n                                                      localizer.meta, dims)\n\n    ev = EyeVolume(data=np.stack(bscan),\n                   meta=volume_meta,\n                   localizer=localizer,\n                   transformation=transformation)\n\n    if segmentation:\n        for name, i in segmentation.items():\n            ev.add_layer_annotation(segmentation[name], name=name)\n\n    return ev\n</code></pre>"},{"location":"reference/src/eyepy/io/utils/","title":"utils","text":""},{"location":"reference/src/eyepy/io/utils/#eyepy.io.utils","title":"<code>eyepy.io.utils</code>","text":""},{"location":"reference/src/eyepy/io/utils/#eyepy.io.utils.find_float","title":"<code>find_float(bytestring, value, endian=None, bits=None, rtol=1e-05, atol=1e-08)</code>","text":"<p>Find all occurrences of a float in a byte string.</p> <p>Parameters:</p> Name Type Description Default <code>bytestring</code> <code>bytes</code> <p>The byte string to search.</p> required <code>value</code> <code>float</code> <p>The float to search for.</p> required <code>endian</code> <code>Optional[str]</code> <p>\"l\" for little and \"b\" for big, the endianness of the float. If not specified, the endianness is assumed to be the same as the endianness of the system.</p> <code>None</code> <code>bits</code> <code>Optional[Union[int, list[int], str, list[str]]]</code> <p>The number of bits in the float. If not specified, 16, 32 and 64 bit floats are searched for.</p> <code>None</code> <code>rtol</code> <code>float</code> <p>The relative tolerance parameter for matching a value (see numpy.isclose).</p> <code>1e-05</code> <code>atol</code> <code>float</code> <p>The absolute tolerance parameter for matching a value (see numpy.isclose).</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>A dictionary where the key is the type and the value, a list of offsets for which the searched value was found</p> Source code in <code>src/eyepy/io/utils.py</code> <pre><code>def find_float(bytestring: bytes,\n               value: float,\n               endian: Optional[str] = None,\n               bits: Optional[Union[int, list[int], str, list[str]]] = None,\n               rtol: float = 1e-05,\n               atol: float = 1e-08) -&gt; dict[str, list[int]]:\n    \"\"\"Find all occurrences of a float in a byte string.\n\n    Args:\n        bytestring: The byte string to search.\n        value: The float to search for.\n        endian: \"l\" for little and \"b\" for big, the endianness of the float.\n            If not specified, the endianness is assumed to be the same as the endianness of the system.\n        bits: The number of bits in the float. If not specified, 16, 32 and 64\n            bit floats are searched for.\n        rtol: The relative tolerance parameter for matching a value (see numpy.isclose).\n        atol: The absolute tolerance parameter for matching a value (see numpy.isclose).\n\n    Returns:\n        A dictionary where the key is the type and the value, a list of offsets for which the searched value was found\n    \"\"\"\n\n    # construct format strings\n    if endian is None:\n        endian = sys.byteorder[0]  # first letter of endianness\n    if bits is None:\n        bits = ['16', '32', '64']\n    elif isinstance(bits, int):\n        bits = [str(bits)]\n    elif isinstance(bits, str):\n        bits = [bits]\n    elif isinstance(bits, list):\n        bits = [str(b) for b in bits]\n\n    # Build a list of all format strings\n    formats = [(int(b), f'Float{b}{endian}') for b in bits]\n\n    # find all occurrences\n    results = defaultdict(list)\n    for bts, fmt_string in formats:\n        format = getattr(cs, fmt_string)\n\n        # Parse the bytestring with multiple byte offsets depending on the format\n        for offset in range(bts // 8):\n            # Calculate the number of items that can be parsed\n            count = (len(bytestring) - offset) // (bts // 8)\n            if count &lt;= 0:\n                continue\n            data = np.array(cs.Array(count, format).parse(bytestring[offset:]))\n\n            # Find all occurrences for this format\n            hits = np.nonzero(np.isclose(data, value, rtol, atol))\n            res = [(pos * (bts // 8)) + offset + 1 for pos in hits[0]]\n            if res:\n                results[fmt_string] += res\n\n    results = {**results}\n    return results\n</code></pre>"},{"location":"reference/src/eyepy/io/utils/#eyepy.io.utils.find_int","title":"<code>find_int(bytestring, value, signed=None, endian=None, bits=None, rtol=1e-05, atol=1e-08)</code>","text":"<p>Find all occurrences of an integer in a byte string.</p> <p>Parameters:</p> Name Type Description Default <code>bytestring</code> <code>bytes</code> <p>The byte string to search.</p> required <code>value</code> <code>int</code> <p>The integer to search for.</p> required <code>signed</code> <code>Optional[Union[bool, str, list[str]]]</code> <p>Whether the integer is signed or not. If not specified, the integer is assumed to be signed if it is negative, otherwise signed and unsigned are searched for.</p> <code>None</code> <code>endian</code> <code>Optional[str]</code> <p>\"l\" for little and \"b\" for big, the endianness of the integer. If not specified, the endianness is assumed to be the same as the endianness of the system.</p> <code>None</code> <code>bits</code> <code>Optional[Union[int, list[int], str, list[str]]]</code> <p>The number of bits in the integer. If not specified, 8, 16, 24, 32, and 64 bit integers are searched for.</p> <code>None</code> <code>rtol</code> <code>float</code> <p>The relative tolerance parameter for matching a value (see numpy.isclose).</p> <code>1e-05</code> <code>atol</code> <code>float</code> <p>The absolute tolerance parameter for matching a value (see numpy.isclose).</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>A dictionary where the key is the type and the value, a list of offsets for which the searched value was found</p> Source code in <code>src/eyepy/io/utils.py</code> <pre><code>def find_int(bytestring: bytes,\n             value: int,\n             signed: Optional[Union[bool, str, list[str]]] = None,\n             endian: Optional[str] = None,\n             bits: Optional[Union[int, list[int], str, list[str]]] = None,\n             rtol: float = 1e-05,\n             atol: float = 1e-08) -&gt; dict[str, list[int]]:\n    \"\"\"Find all occurrences of an integer in a byte string.\n\n    Args:\n        bytestring: The byte string to search.\n        value: The integer to search for.\n        signed: Whether the integer is signed or not. If not specified, the\n            integer is assumed to be signed if it is negative, otherwise signed and unsigned are searched for.\n        endian: \"l\" for little and \"b\" for big, the endianness of the integer.\n            If not specified, the endianness is assumed to be the same as the endianness of the system.\n        bits: The number of bits in the integer. If not specified, 8, 16, 24, 32, and 64\n            bit integers are searched for.\n        rtol: The relative tolerance parameter for matching a value (see numpy.isclose).\n        atol: The absolute tolerance parameter for matching a value (see numpy.isclose).\n\n    Returns:\n        A dictionary where the key is the type and the value, a list of offsets for which the searched value was found\n    \"\"\"\n\n    # construct format strings\n    if signed is None:\n        signed = ['s'] if value &lt; 0 else ['s', 'u']\n    elif isinstance(signed, bool):\n        signed = ['s'] if signed else ['u']\n    elif isinstance(signed, str):\n        signed = [signed]\n    if endian is None:\n        endian = sys.byteorder[0]  # first letter of endianness\n    if bits is None:\n        bits = ['8', '16', '24', '32', '64']\n    elif isinstance(bits, int):\n        bits = [str(bits)]\n    elif isinstance(bits, str):\n        bits = [bits]\n    elif isinstance(bits, list):\n        bits = [str(b) for b in bits]\n\n    # Build a list of all format strings\n    formats = [(int(b), f'Int{b}{s}{endian}') for b in bits for s in signed]\n\n    # find all occurrences\n    results = defaultdict(list)\n    for bts, fmt_string in formats:\n        format = getattr(cs, fmt_string)\n\n        # Parse the bytestring with multiple byte offsets depending on the format\n        for offset in range(bts // 8):\n\n            # Calculate the number of items that can be parsed\n            count = (len(bytestring) - offset) // (bts // 8)\n            if count &lt;= 0:\n                continue\n            data = np.array(cs.Array(count, format).parse(bytestring[offset:]))\n\n            # Find all occurrences\n            hits = np.nonzero(np.isclose(data, value, rtol=rtol, atol=atol))\n            res = [(pos * (bts // 8)) + offset + 1 for pos in hits[0]]\n            if res:\n                results[fmt_string] += res\n\n    results = {**results}\n    return results\n</code></pre>"},{"location":"reference/src/eyepy/io/he/","title":"he","text":""},{"location":"reference/src/eyepy/io/he/#eyepy.io.he","title":"<code>eyepy.io.he</code>","text":""},{"location":"reference/src/eyepy/io/he/#eyepy.io.he.HeVolWriter","title":"<code>HeVolWriter(volume)</code>","text":"Source code in <code>src/eyepy/io/he/vol_reader.py</code> <pre><code>def __init__(self, volume: EyeVolume):\n    self.volume = volume\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_format/","title":"e2e_format","text":""},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format","title":"<code>eyepy.io.he.e2e_format</code>","text":""},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.BscanAdapter","title":"<code>BscanAdapter(*args, **kwargs)</code>","text":"<p>               Bases: <code>Adapter</code></p> Source code in <code>src/eyepy/io/he/e2e_format.py</code> <pre><code>def __init__(self, *args: t.Any, **kwargs: t.Any):\n    super().__init__(*args, **kwargs)\n    self.LUT = self._make_LUT()\n    self.inv_LUT = self._make_inv_LUT()\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Chunk","title":"<code>Chunk(chunk_header=csfield(header_format, doc='Each chunk refers to the start position of the previous chunk (`prev` field)'), folders=csfield(cs.Array(cs.this.chunk_header.num_entries, folderheader_format), doc='In the data we have seen each chunk has 512 folders with headers of size 44'), jump=csfield(cs.Seek(cs.this.folders[-1].start + cs.this.folders[-1].size + datacontainer_format.header.sizeof())))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Data chunk.</p> <p>Size: variable</p> <p>Notes: Every chunk has a header similar to the file header. A chunk then holds the headers of all contained folders sequentially, followed by data containers, that are referenced by the folder headers. A chunk can contain folders with data of different patients, studies, series, slices and types. Each folder contains data for a single (patient, study, series, slice, type) combination which is given in the folder header as well as the data container header. For the last chunk to have 512 folders, empty folders of type=0 are appended.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.ContainerHeader","title":"<code>ContainerHeader(magic3=csfield(cs.PaddedString(12, 'ascii')), unknown0=csfield(cs.Int32ul), header_pos=csfield(cs.Int32ul, doc='Position of the header'), pos=csfield(cs.Int32ul, doc='Position of the data'), size=csfield(cs.Int32ul, doc='Size of the container'), unknown1=csfield(cs.Int32ul, doc=\"Always 0 (b'\\\\x00\\\\x00\\\\x00\\\\x00')? At least in our data\"), patient_id=csfield(cs.Int32sl, doc='Patient ID'), study_id=csfield(cs.Int32sl, doc='Study ID'), series_id=csfield(cs.Int32sl, doc='Series ID'), slice_id=csfield(cs.Int32sl, doc='Slice ID, has to be divided by 2 to get the correct slice number'), ind=csfield(cs.Int16ul, doc=\"Takes only values 65333, 0 and 1 (b'\u00ff\u00ff', b'\\x00\\x00', b'\\x01\\x00') at least in our data - 0 for enface and 1 for bscan for image containers\"), unknown2=csfield(cs.Int16ul, doc=\"Always 0 (b'\\x00\\x00')? At least in our data\"), type=csfield(TEnum(cs.Int32ul, TypesEnum), doc='Type ID of the contained data'), unknown3=csfield(cs.Int32ul, doc='Large integer that increases in steps of folder header size (=44) Maybe the folder header position in HEYEX database not in this file? - Possibly related to the folder header unknown4 value'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Container header data.</p> <p>Size: 60 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.DataContainer","title":"<code>DataContainer(header=csfield(containerheader_format), item=csfield(item_switch, doc='There are many kinds of DataItems indicated by different type IDs in the folder/container header'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Data container.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.E2EFormat","title":"<code>E2EFormat(version=csfield(version_format), header=csfield(header_format, doc='The `prev` field in the main header refers to the start position of the last chunk'), chunks=csfield(cs.GreedyRange(chunk_format), doc='The number and size of the chunks depends on the data'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>E2E file format.</p> <p>Size: variable</p> <p>Notes: An E2E file starts with a version structure, followed by a header structure. After that the data comes in chunks of 512 folders.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.FolderHeader","title":"<code>FolderHeader(pos=csfield(cs.Int32ul, doc='Position of the folder (In a chunk all 512 folder headers are stored sequentially, refering to the data that follows after this header block)'), start=csfield(cs.Int32ul, doc='Start of the data container, after the header block in the chunk'), size=csfield(cs.Int32ul, doc='Size of the data container'), unknown0=csfield(cs.Int32ul, doc=\"Always 0 (b'\\x00\\x00')? At leat in our data\"), patient_id=csfield(cs.Int32sl, doc='Patient ID'), study_id=csfield(cs.Int32sl, doc='Study ID'), series_id=csfield(cs.Int32sl, doc='Series ID'), slice_id=csfield(cs.Int32sl, doc='Slice ID, has to be divided by 2 to get the correct slice number'), ind=csfield(cs.Int16ul, doc='0 for enface and 1 for bscan for image containers'), unknown1=csfield(cs.Int16ul), type=csfield(TEnum(cs.Int32ul, TypesEnum), doc='Type ID of the contained data'), unknown3=csfield(cs.Int32ul, doc='Large integer possibly related to data_container.unknown5. Maybe the position in HEYEX DB?'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Folder header.</p> <p>Size: 44 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Header","title":"<code>Header(magic2=csfield(cs.PaddedString(12, 'ascii')), version=csfield(cs.Int32ul), unknown0=csfield(cs.Array(10, cs.Int16ul)), num_entries=csfield(cs.Int32ul, doc='Number of entries in the chunk'), current=csfield(cs.Int32ul, doc='Position of the current chunk'), prev=csfield(cs.Int32ul, doc='Position of the previous chunk'), unknown1=csfield(cs.Int32ul))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Chunk header.</p> <p>Size: 52 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.LateralityEnum","title":"<code>LateralityEnum</code>","text":"<p>               Bases: <code>EnumBase</code></p> <p>Enum for laterality of eye.</p> <p>The laterality is stored as single character in ASCII code.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10004","title":"<code>Type10004(unknown0=csfield(cs.Int32ul), size_y=csfield(cs.Int32ul, doc='Bscan height'), size_x=csfield(cs.Int32ul, doc='Bscan width'), start_x=csfield(cs.Float32l, doc='Start X coordinate of Bscan'), start_y=csfield(cs.Float32l, doc='Start Y coordinate of Bscan'), end_x=csfield(cs.Float32l, doc='End X coordinate of Bscan'), end_y=csfield(cs.Float32l, doc='End Y coordinate of Bscan'), zero1=csfield(cs.Int32ul), unknown1=csfield(cs.Float32l), scale_y=csfield(cs.Float32l, doc='Scale of Bscan y-axis (height)'), unknown2=csfield(cs.Float32l), zero2=csfield(cs.Int32ul), unknown3=csfield(cs.Array(2, cs.Float32l)), zero3=csfield(cs.Int32ul), imgSizeWidth=csfield(cs.Int32ul, doc='Might differ from size_x, and is probably the number of filled A-scans in the Bscan. Bscans sometimes have empty A-scans at the ends.'), n_bscans=csfield(cs.Int32ul, doc='Number of Bscans in the respective volume'), aktImage=csfield(cs.Int32ul, doc='Index of the current Bscan in the volume'), scan_pattern=csfield(cs.Int32ul, doc='Scan pattern of the volume. &lt;br&gt;**Does this corresponds to the scan pattterns in VOL and XML export?**'), center_x=csfield(cs.Float32l, doc='Exactly the average of start_x and end_x.'), center_y=csfield(cs.Float32l, doc='Exactly the average of start_y and end_y.'), unknown4=csfield(cs.Int32ul, doc='Maybe the UTC bias?'), acquisitionTime=csfield(DateTime, doc='Acquisition time of Bscan'), numAve=csfield(cs.Int32ul, doc='Number of averages according to LibE2E&lt;br&gt;**Not coherent with XML export**'), quality=csfield(cs.Float32l, doc='Quality according to LibE2E&lt;br&gt;**Does not match the quality value in the XML export which is an integer compared to a float here with value 0.84 for a complete volume. Maybe this is the focus length, at least it is similar to the value given in the XML (0.87)**'), unknown5=csfield(cs.Float32l))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>B-scan Metadata Metadata for a single B-scan.</p> <p>Size: 428 bytes</p> <p>Notes: The current Bscan-Meta structure builds on the implementation found in LibE2E.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10010","title":"<code>Type10010(unknown=csfield(cs.Bytes(12)), n_bscans=csfield(cs.Int32ul))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 10010.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10012","title":"<code>Type10012(unknown0=csfield(cs.Bytes(28)), value_1=csfield(cs.Float32l), unknown1=csfield(cs.Bytes(1)), value_2=csfield(cs.Float32l))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 10012.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10013","title":"<code>Type10013(unknown=csfield(cs.Bytes(12)), n_bscans=csfield(cs.Int32ul))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 10013.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10019","title":"<code>Type10019(unknown0=csfield(cs.Int32ul), id=csfield(cs.Int32ul, doc='ID of the layer'), unknown1=csfield(cs.Int32ul), width=csfield(cs.Int32ul, doc='Width of the layer'), data=csfield(Segmentation, doc='Layer annotation data'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Layer Annotation Stores one layer for one Bscan.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type10025","title":"<code>Type10025(unknown=csfield(cs.Bytes(24)), windate=csfield(DateTime), transform=csfield(cs.Array(6, cs.Float32l), doc='Parameters of affine transformation'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Localizer Metadata.</p> <p>Size: 100 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type1073741824","title":"<code>Type1073741824(size=csfield(cs.Int32ul, doc='Size of the data'), type=csfield(cs.Int32ul, doc='Type of the data'), n_values=csfield(cs.Int32ul, doc='Number of values in the data'), height=csfield(cs.Int32ul, doc='Height of the image'), width=csfield(cs.Int32ul, doc='Width of the image'), data=csfield(cs.Switch(cs.this.type, {33620481: LocalizerNIR, 35652097: Bscan}, default=(cs.Bytes(cs.this.size))), doc='Image data'))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Image data Stores various kinds of images.</p> <p>Size: variable</p> <p>Notes: Different kinds of images are stored in this structure. Currently we know the following types:</p> <ul> <li>33620481: LocalizerNIR (<code>int8u</code>)</li> <li>35652097: Bscan (<code>float16u</code>)</li> </ul> <p>The custom <code>float16u</code> used to store the Bscan data, has no sign, a 6-bit exponent und 10-bit mantissa.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type11","title":"<code>Type11(unknown=csfield(cs.Bytes(14)), laterality=csfield(TEnum(cs.Int8ul, LateralityEnum)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 11.</p> <p>Size: 27 bytes</p> <p>Notes: We don't know what this data is used for, only that the 15th byte indicates the laterality of the eye.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type17","title":"<code>Type17(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Diagnose data.</p> <p>Size: variable</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type3","title":"<code>Type3(unknown=csfield(cs.Bytes(4)), laterality=csfield(TEnum(cs.Int8ul, LateralityEnum)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 3.</p> <p>Size: 96 bytes</p> <p>Notes: We don't know what this data is used for, only that the 5th byte indicates the laterality of the eye.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type5","title":"<code>Type5(unknown=csfield(cs.Bytes(2)), laterality=csfield(TEnum(cs.Int8ul, LateralityEnum)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 5.</p> <p>Size: 59 bytes</p> <p>Notes: We don't know what this data is used for, only that the 3rd byte indicates the laterality of the eye.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type59","title":"<code>Type59(unknown=csfield(cs.Bytes(14)), laterality=csfield(TEnum(cs.Int8ul, LateralityEnum)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Type 59.</p> <p>Size: 27 bytes</p> <p>Notes: We don't know what this data is used for, only that the 14th byte indicates the laterality of the eye.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type7","title":"<code>Type7(eye_side=csfield(TEnum(cs.Int8ul, LateralityEnum)), c_curve_mm=csfield(cs.Float64l), refraction_dpt=csfield(cs.Float64l), cylinder_dpt=csfield(cs.Float64l), axis_deg=csfield(cs.Float64l), pupil_size_mm=csfield(cs.Float64l), iop_mmHg=csfield(cs.Float64l), vfield_mean=csfield(cs.Float64l), vfield_var=csfield(cs.Float64l), corrective_lens=csfield(cs.Int16ul), rest=csfield(cs.Bytes(1)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Measurements Global measurements of the eye.</p> <p>Size: 68 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9","title":"<code>Type9(firstname=csfield(cs.PaddedString(31, 'ascii')), surname=csfield(cs.PaddedString(66, 'ascii')), birthdate=csfield(cs.Int32ul), sex=csfield(cs.PaddedString(1, 'ascii')), patient_id=csfield(cs.PaddedString(25, 'ascii')))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Patient data Personal data of the patient.</p> <p>Size: 131 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9000","title":"<code>Type9000(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Studyname Name of the study/visit.</p> <p>Size: 264 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9001","title":"<code>Type9001(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Device Name of the used device.</p> <p>Size: 776 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9005","title":"<code>Type9005(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Examined structure Name of the examined structure.</p> <p>Size: 264 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9006","title":"<code>Type9006(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Scan pattern Bscan pattern used for the aquisition.</p> <p>Size: 520 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9007","title":"<code>Type9007(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>Enface Modality Modality of the enface (eg IR)</p> <p>Size: 520 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Type9008","title":"<code>Type9008(n_strings=csfield(cs.Int32ul), string_size=csfield(cs.Int32ul), text=csfield(cs.Array(cs.this.n_strings, cs.PaddedString(cs.this.string_size, 'utf16'))))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code>, <code>TypeMixin</code></p> <p>OCT Modality Modality of the OCT (eg OCT)</p> <p>Size: 520 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.TypesEnum","title":"<code>TypesEnum</code>","text":"<p>               Bases: <code>EnumBase</code></p> <p>Enum for types of data stored in .e2e files.</p>"},{"location":"reference/src/eyepy/io/he/e2e_format/#eyepy.io.he.e2e_format.Version","title":"<code>Version(name=csfield(cs.PaddedString(12, 'ascii'), doc='Name of the version'), version=csfield(cs.Int32ul, doc='Verion of the file'), unknown0=csfield(cs.Array(10, cs.Int16ul)))</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DataclassMixin</code></p> <p>Version header.</p> <p>Size: 36 bytes</p> <p>Notes:</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/","title":"e2e_reader","text":""},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader","title":"<code>eyepy.io.he.e2e_reader</code>","text":""},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFileStructure","title":"<code>E2EFileStructure()</code>","text":"<p>               Bases: <code>E2EStructureMixin</code></p> <p>E2E File Structure.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self):\n    self.substructure: dict[int, E2EPatientStructure] = {}\n    self.folders: dict[Union[int, str], list[E2EFolder]] = {}\n\n    self._section_description_parts = []\n    self._section_title = ''\n    self._section_description = ''\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFileStructure.add_folder","title":"<code>add_folder(folder)</code>","text":"<p>Add a folder to the File Structure.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>E2EFolder</code> <p>The folder to add.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def add_folder(self, folder: E2EFolder):\n    \"\"\"Add a folder to the File Structure.\n\n    Args:\n        folder: The folder to add.\n    \"\"\"\n    try:\n        self.all_folders.append(folder)\n    except AttributeError:\n        self.all_folders = [folder]\n\n    if folder.patient_id == -1:\n        try:\n            self.folders[folder.type].append(folder)\n        except KeyError:\n            self.folders[folder.type] = [folder]\n    else:\n        if folder.patient_id not in self.patients:\n            self.patients[folder.patient_id] = E2EPatientStructure(\n                folder.patient_id)\n        self.patients[folder.patient_id].add_folder(folder)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder","title":"<code>E2EFolder(patient_id, study_id, series_id, slice_id, pos, start, type, size, ind, reader)</code>  <code>dataclass</code>","text":"<p>Folder data class.</p> <p>Note</p> <p>Folders are created during initialization of the HeE2eReader. For accessing the data the respective HeE2eReader has to be used as a Context Manager. This opens the E2E file and allows the E2EFolder to access the data.</p> <pre><code>with HeE2eReader(\"path/to/e2e\") as reader:\n    folder_dict = reader.file_hierarchy.folders\n    folder = folder_dict[TypesEnum.YOURTYPE][0]\n    data = folder.data\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder.data","title":"<code>data</code>  <code>property</code>","text":"<p>Return the data.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder.file_object","title":"<code>file_object</code>  <code>property</code>","text":"<p>Return the file object.</p> <p>This refers to the the HeE2eReader file object.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder.header","title":"<code>header</code>  <code>property</code>","text":"<p>Return the data header.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder.get_bytes","title":"<code>get_bytes()</code>","text":"<p>Return the bytes of the data.</p> <p>This only works if the HeE2eReader is used as a Context Manager or during initialization of the HeE2eReader. Otherwise the E2E file is not open.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_bytes(self) -&gt; bytes:\n    \"\"\"Return the bytes of the data.\n\n    This only works if the HeE2eReader is used as a Context Manager\n    or during initialization of the HeE2eReader. Otherwise the E2E\n    file is not open.\n    \"\"\"\n    self.file_object.seek(self.start + containerheader_format.sizeof())\n    return self.file_object.read(self.size)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EFolder.parse_spec","title":"<code>parse_spec(data_construct, offset=0)</code>","text":"<p>Parse a data specification.</p> <p>This only works if the HeE2eReader is used as a Context Manager or during initialization of the HeE2eReader. Otherwise the E2E file is not open.</p> <p>Parameters:</p> Name Type Description Default <code>data_construct</code> <code>Construct</code> <p>The construct to parse the data with. You can Constructs defined in the construct library or those defined in the e2e_format module.</p> required <code>offset</code> <code>int</code> <p>The offset in bytes, 0 by default.</p> <code>0</code> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def parse_spec(self, data_construct: cs.Construct, offset: int = 0) -&gt; Any:\n    \"\"\"Parse a data specification.\n\n    This only works if the HeE2eReader is used as a Context Manager or during initialization of the HeE2eReader.\n    Otherwise the E2E file is not open.\n\n\n\n    Args:\n        data_construct: The construct to parse the data with. You can Constructs defined in the construct library or those defined in the [e2e_format][eyepy.io.he.e2e_format] module.\n        offset: The offset in bytes, 0 by default.\n    \"\"\"\n    b = self.get_bytes()\n    return data_construct.parse(b[offset:])\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EPatientStructure","title":"<code>E2EPatientStructure(id)</code>","text":"<p>               Bases: <code>E2EStructureMixin</code></p> <p>E2E Patient Structure.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self, id) -&gt; None:\n    self.id = id\n    self.substructure: dict[int, E2EStudyStructure] = {}\n    self.folders: dict[Union[int, str], list[E2EFolder]] = {}\n\n    self._section_description_parts = []\n    self._section_title = ''\n    self._section_description = ''\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EPatientStructure.add_folder","title":"<code>add_folder(folder)</code>","text":"<p>Add a folder to the Patient Structure.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>E2EFolder</code> <p>The folder to add.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def add_folder(self, folder: E2EFolder) -&gt; None:\n    \"\"\"Add a folder to the Patient Structure.\n\n    Args:\n        folder: The folder to add.\n    \"\"\"\n    if folder.study_id == -1:\n        try:\n            self.folders[folder.type].append(folder)\n        except KeyError:\n            self.folders[folder.type] = [folder]\n    else:\n        if folder.study_id not in self.studies:\n            self.studies[folder.study_id] = E2EStudyStructure(\n                folder.study_id)\n        self.studies[folder.study_id].add_folder(folder)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure","title":"<code>E2ESeriesStructure(id)</code>","text":"<p>               Bases: <code>E2EStructureMixin</code></p> <p>E2E Series Structure.</p> <p>This structure contains folders with data for a single Series/OCT- Volume and provides convenience functions for accessing the data.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self, id: int) -&gt; None:\n    self.id = id\n    self.substructure: dict[int, E2ESliceStructure] = {}\n    self.folders: dict[Union[int, str], list[E2EFolder]] = {}\n\n    self._meta = None\n    self._bscan_meta = None\n    self._localizer_meta = None\n    self._section_title = ''\n    self._section_description = ''\n\n    # Description used in inspect()\n    # Parts are (name, folder_id, index in list of strings)\n    self._section_description_parts = [\n        ('Structure:', 9005, 0),\n        ('Scanpattern:', 9006, 0),\n        ('Oct Modality:', 9008, 1),\n        ('Enface Modality:', 9007, 1),\n    ]\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.n_bscans","title":"<code>n_bscans</code>  <code>property</code>","text":"<p>Return the number of B-scans in the series.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.slices","title":"<code>slices</code>  <code>property</code>","text":"<p>Alias for substructure.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.add_folder","title":"<code>add_folder(folder)</code>","text":"<p>Add a folder to the Series.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>E2EFolder</code> <p>The folder to add.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def add_folder(self, folder: E2EFolder) -&gt; None:\n    \"\"\"Add a folder to the Series.\n\n    Args:\n        folder: The folder to add.\n    \"\"\"\n    if folder.slice_id == -1:\n        try:\n            self.folders[folder.type].append(folder)\n        except KeyError:\n            self.folders[folder.type] = [folder]\n    else:\n        if folder.slice_id not in self.slices:\n            self.slices[folder.slice_id] = E2ESliceStructure(\n                folder.slice_id)\n        self.slices[folder.slice_id].add_folder(folder)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.get_bscan_meta","title":"<code>get_bscan_meta()</code>","text":"<p>Return EyeBscanMeta objects for all B-scans in the series.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_bscan_meta(self) -&gt; list[EyeBscanMeta]:\n    \"\"\"Return EyeBscanMeta objects for all B-scans in the series.\"\"\"\n    if self._bscan_meta is None:\n        self._bscan_meta = sorted(\n            [sl.get_meta() for sl in self.slices.values()],\n            key=lambda x: x['aktImage'])\n    return self._bscan_meta\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.get_layers","title":"<code>get_layers()</code>","text":"<p>Return layer height maps for the series as dict of numpy arrays where the key is the layer id.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_layers(self) -&gt; dict[int, np.ndarray]:\n    \"\"\"Return layer height maps for the series as dict of numpy arrays where\n    the key is the layer id.\"\"\"\n    slice_layers = {}\n    layer_ids = set()\n\n    for ind, sl in self.slices.items():\n        layers = sl.get_layers()\n        [layer_ids.add(k) for k in layers.keys()]\n        slice_layers[ind // 2] = layers\n\n    layers = {}\n    size_x = self.get_bscan_meta()[0]['size_x']\n    for i in layer_ids:\n        layer = np.full((self.n_bscans, size_x), np.nan)\n        if self.n_bscans == 1:\n            layer[0, :] = slice_layers[1][i]\n            layers[i] = layer\n\n        else:\n            for sl in range(self.n_bscans):\n                try:\n                    layer[sl, :] = slice_layers[sl][i]\n                except KeyError:\n                    pass\n\n        layer[layer &gt;= 3.0e+38] = np.nan\n        layers[i] = layer\n\n    return layers\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.get_localizer","title":"<code>get_localizer()</code>","text":"<p>Return EyeEnface object for the localizer image.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_localizer(self) -&gt; EyeEnface:\n    \"\"\"Return EyeEnface object for the localizer image.\"\"\"\n    try:\n        folders = self.folders[TypesEnum.image]\n        if len(folders) &gt; 1:\n            logger.warning(\n                'There is more than one enface localizer image stored. This is not expected.'\n            )\n\n        # Slodata is not always present in E2E files.\n        # Todo: Give transform to EyeEnface object where it is applied to the image. EyeEnface then by default has an identity transform.\n        #transform = np.array(list(self.slo_data().transform) +\n        #                     [0, 0, 1]).reshape((3, 3))\n        # transfrom localizer with transform from E2E file\n        #transformed_localizer = warp(folders[0].data.data,\n        #                             AffineTransform(transform),\n        #                             order=1,\n        #                             preserve_range=True)\n        return EyeEnface(folders[0].data.data,\n                         self.localizer_meta(height=folders[0].data.height,\n                                             width=folders[0].data.width))\n    except KeyError:\n        if self.n_bscans == 1:\n            slice_struct = self.slices[2]\n            return EyeEnface(slice_struct.get_localizer(),\n                             self.localizer_meta())\n        else:\n            raise ValueError(\n                'There is no localizer/fundus image in the E2E file.')\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.get_meta","title":"<code>get_meta()</code>","text":"<p>Return EyeVolumeMeta object for the series.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_meta(self) -&gt; EyeVolumeMeta:\n    \"\"\"Return EyeVolumeMeta object for the series.\"\"\"\n    if self._meta is None:\n        bscan_meta = self.get_bscan_meta()\n        self._meta = EyeVolumeMeta(\n            scale_x=1,  #0.0114,  # Todo: Where is this in E2E?\n            scale_y=1,  #bscan_meta[0][\"scale_y\"],\n            scale_z=1,  #get_bscan_spacing(bscan_meta) if\n            #(bscan_meta[0][\"scan_pattern\"] not in [1, 2]) else 0.03,\n            scale_unit='px',\n            laterality=self.laterality(),\n            visit_date=None,\n            exam_time=None,\n            bscan_meta=bscan_meta,\n            intensity_transform='e2e',\n        )\n    return self._meta\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.get_volume","title":"<code>get_volume()</code>","text":"<p>Return EyeVolume object for the series.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_volume(self) -&gt; EyeVolume:\n    \"\"\"Return EyeVolume object for the series.\"\"\"\n    ## Check if scan is a volume scan\n    volume_meta = self.get_meta()\n\n    scan_pattern = volume_meta['bscan_meta'][0]['scan_pattern']\n\n    ## Check if scan pattern is supported by EyeVolume\n    if scan_pattern == 2:\n        msg = f'The EyeVolume object does not support scan pattern 2 (one Circular B-scan).'\n        raise ValueError(msg)\n    elif scan_pattern == 5:\n        msg = f'The EyeVolume object does not support scan pattern 5 (Radial scan - star pattern).'\n        raise ValueError(msg)\n\n    data = self.get_bscans()\n\n    volume_meta = self.get_meta()\n    localizer = self.get_localizer()\n    volume = EyeVolume(\n        data=data,\n        meta=volume_meta,\n        localizer=localizer,\n        transformation=_compute_localizer_oct_transform(\n            volume_meta, localizer.meta, data.shape),\n    )\n\n    layer_height_maps = self.get_layers()\n    for name, i in SEG_MAPPING.items():\n        if i in layer_height_maps:\n            volume.add_layer_annotation(layer_height_maps[i], name=name)\n\n    return volume\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.inspect","title":"<code>inspect(recursive=False, ind_prefix='', tables=False)</code>","text":"<p>Inspect the series.</p> <p>Custom <code>inspect</code> method to print a summary table for the slices belonging to the series.</p> <p>Parameters:</p> Name Type Description Default <code>recursive</code> <code>bool</code> <p>If True inspect lower level structures recursively.</p> <code>False</code> <code>ind_prefix</code> <code>str</code> <p>Indentation for showing information from lower level structures.</p> <code>''</code> <code>tables</code> <code>bool</code> <p>If True add markdown table overview of the contained folder types.</p> <code>False</code> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def inspect(self,\n            recursive: bool = False,\n            ind_prefix: str = '',\n            tables: bool = False) -&gt; str:\n    \"\"\"Inspect the series.\n\n    Custom `inspect` method to print a summary table for the slices belonging to the series.\n\n    Args:\n        recursive: If True inspect lower level structures recursively.\n        ind_prefix: Indentation for showing information from lower level structures.\n        tables: If True add markdown table overview of the contained folder types.\n    \"\"\"\n    laterality = self.folders[TypesEnum.laterality][\n        0].data.laterality.name if TypesEnum.laterality in self.folders else 'Unknown'\n    text = self._get_section_title(\n    ) + f' - Laterality: {laterality} - B-scans: {self.n_bscans}\\n'\n    text += self._get_section_description() + '\\n'\n    if tables:\n        text += self._get_folder_summary() + '\\n'\n\n    if not recursive:\n        return text\n\n    # Describe all slices in one table\n    s_data = defaultdict(list)\n    for sl in self.slices.values():\n        for f_list in sl.folders.values():\n            for f in f_list:\n                s_data[f.type].append(f.size)\n\n    if len(s_data) == 0 or tables == False:\n        text += ''\n    else:\n        text += '\\nE2ESlice Summary:\\n'\n        text += indent(self._get_table(s_data, 'E2ESliceStructure'),\n                       ind_prefix)\n        text += '\\n'\n    return text\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESeriesStructure.localizer_meta","title":"<code>localizer_meta(height, width)</code>","text":"<p>Return EyeEnfaceMeta object for the localizer image.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def localizer_meta(self, height, width) -&gt; EyeEnfaceMeta:\n    \"\"\"Return EyeEnfaceMeta object for the localizer image.\"\"\"\n    if self._localizer_meta is None:\n        self._localizer_meta = EyeEnfaceMeta(\n            scale_x=30 / width,  # Give scale in degrees per pixel\n            scale_y=30 / height,\n            scale_unit='\u00b0',\n            modality=self.enface_modality(),\n            laterality=self.laterality(),\n            field_size=None,\n            scan_focus=None,\n            visit_date=None,\n            exam_time=None,\n        )\n    logger.info(\n        'The localizer scale is currently hardcoded and not read from the E2E file. If you know how or where to find the scale information let us know by opening an issue.'\n    )\n    return self._localizer_meta\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure","title":"<code>E2ESliceStructure(id)</code>","text":"<p>               Bases: <code>E2EStructureMixin</code></p> <p>E2E Slice Structure.</p> <p>This structure contains folders with data for a single Slice/B-csan and provide convenience functions for accessing the data.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self, id: int) -&gt; None:\n    self.id = id\n    self.folders: dict[Union[int, str], list[E2EFolder]] = {}\n\n    # Empty so inspect() does not fail\n    self.substructure = {}\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure.add_folder","title":"<code>add_folder(folder)</code>","text":"<p>Add a folder to the slice.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>E2EFolder</code> <p>The folder to add.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def add_folder(self, folder: E2EFolder) -&gt; None:\n    \"\"\"Add a folder to the slice.\n\n    Args:\n        folder: The folder to add.\n    \"\"\"\n    try:\n        self.folders[folder.type].append(folder)\n    except KeyError:\n        self.folders[folder.type] = [folder]\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure.get_bscan","title":"<code>get_bscan()</code>","text":"<p>Return the slice image (B-scan)</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_bscan(self) -&gt; np.ndarray:\n    \"\"\"Return the slice image (B-scan)\"\"\"\n    bscan_folders = [\n        f for f in self.folders[TypesEnum.image] if f.data.type == 35652097\n    ]\n    if len(bscan_folders) &gt; 1:\n        logger.warning(\n            'There is more than one B-scan per slice. This is not expected.'\n        )\n    return bscan_folders[0].data.data\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure.get_layers","title":"<code>get_layers()</code>","text":"<p>Return the layers as a dictionary of layer id and layer data.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_layers(self) -&gt; dict[int, np.ndarray]:\n    \"\"\"Return the layers as a dictionary of layer id and layer data.\"\"\"\n    layers = {}\n    for layer_folder in self.folders[TypesEnum.layer_annotation]:\n        layers[layer_folder.data.id] = layer_folder.data.data\n    return layers\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure.get_localizer","title":"<code>get_localizer()</code>","text":"<p>Return the slice image (Localizer/Fundus) For the scanpattern \"OCT Bscan\" a localizer might be stored in the E2ESliceStructure and not the E2ESeriesStructure.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_localizer(self) -&gt; np.ndarray:\n    \"\"\"Return the slice image (Localizer/Fundus) For the scanpattern \"OCT\n    Bscan\" a localizer might be stored in the E2ESliceStructure and not the\n    E2ESeriesStructure.\"\"\"\n    localizer_folders = [\n        f for f in self.folders[TypesEnum.image] if f.data.type == 33620481\n    ]\n    if len(localizer_folders) &gt; 1:\n        logger.warning(\n            'There is more than one localizer per slice. This is not expected.'\n        )\n    return localizer_folders[0].data.data\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2ESliceStructure.get_meta","title":"<code>get_meta()</code>","text":"<p>Return the slice meta data.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_meta(self) -&gt; EyeBscanMeta:\n    \"\"\"Return the slice meta data.\"\"\"\n    if len(self.folders[TypesEnum.bscanmeta]) &gt; 1:\n        logger.warning(\n            'There is more than one bscanmeta object. This is not expected.'\n        )\n\n\n    meta = self.folders[TypesEnum.bscanmeta][0].data\n\n    return EyeBscanMeta(  #quality=meta.quality,\n        start_pos=((meta['start_x']),\n                   (meta['start_y'])),\n        end_pos=((meta['end_x']),\n                 (meta['end_y'])),\n        pos_unit='\u00b0',\n        **dataclasses.asdict(meta))\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EStructureMixin","title":"<code>E2EStructureMixin</code>","text":"<p>A Mixin for shared functionality between structures in the E2E hierarchy.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EStructureMixin.get_folder_data","title":"<code>get_folder_data(folder_type, offset=0, data_construct=None)</code>","text":"<p>Return the data of a folder type.</p> <p>Parameters:</p> Name Type Description Default <code>folder_type</code> <code>Union[TypesEnum, int]</code> <p>Either one of TypesEnum or the type id (int).</p> required <code>offset</code> <code>int</code> <p>Offset to the data in bytes.</p> <code>0</code> <code>data_construct</code> <code>Optional[Union[Construct, str]]</code> <p>A construct to parse the data with (Python construct package) or a string describing one of the basic constructs from the construct package like \"Int8ul\", or \"Float32l\"</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Parsed data or None if no folder of the given type was found.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def get_folder_data(\n    self,\n    folder_type: Union[TypesEnum, int],\n    offset: int = 0,\n    data_construct: Optional[Union[cs.Construct, str]] = None,\n) -&gt; Any:\n    \"\"\"Return the data of a folder type.\n\n    Args:\n        folder_type: Either one of [TypesEnum][eyepy.io.he.e2e_format.TypesEnum] or the type id (int).\n        offset: Offset to the data in bytes.\n        data_construct: A construct to parse the data with (Python construct package) or a string describing one of the basic constructs from the construct package like \"Int8ul\", or \"Float32l\"\n\n    Returns:\n        Parsed data or None if no folder of the given type was found.\n    \"\"\"\n\n    folders: list[E2EFolder] = self.folders[folder_type]\n\n    if len(folders) == 0:\n        return None\n\n    if data_construct is None:\n        return [f.data for f in folders]\n    elif type(data_construct) == str:\n        data_construct = getattr(cs, data_construct)\n\n    return [f.parse_spec(data_construct, offset) for f in folders]\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EStructureMixin.inspect","title":"<code>inspect(recursive=False, ind_prefix='', tables=False)</code>","text":"<p>Inspect the E2E structure.</p> <p>Parameters:</p> Name Type Description Default <code>recursive</code> <code>bool</code> <p>If True inspect lower level structures recursively.</p> <code>False</code> <code>ind_prefix</code> <code>str</code> <p>Indentation for showing information from lower level structures.</p> <code>''</code> <code>tables</code> <code>bool</code> <p>If True add markdown table overview of the contained folder types.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Information about the E2E structure.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def inspect(self,\n            recursive: bool = False,\n            ind_prefix: str = '',\n            tables: bool = False) -&gt; str:\n    \"\"\"Inspect the E2E structure.\n\n    Args:\n        recursive: If True inspect lower level structures recursively.\n        ind_prefix: Indentation for showing information from lower level structures.\n        tables: If True add markdown table overview of the contained folder types.\n\n    Returns:\n        Information about the E2E structure.\n    \"\"\"\n    text = self._get_section_title() + '\\n'\n    text += self._get_section_description() + '\\n'\n    if tables:\n        text += self._get_folder_summary() + '\\n'\n\n    if not recursive:\n        return text\n\n    for s in self.substructure.values():\n        text += '\\n'\n        text += indent(s.inspect(recursive, ind_prefix, tables),\n                       ind_prefix)\n    return text\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EStudyStructure","title":"<code>E2EStudyStructure(id)</code>","text":"<p>               Bases: <code>E2EStructureMixin</code></p> <p>E2E Study Structure.</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self, id) -&gt; None:\n    self.id = id\n    self.substructure: dict[int, E2ESeriesStructure] = {}\n    self.folders: dict[Union[int, str], list[E2EFolder]] = {}\n\n    self._section_description_parts = [('Device:', 9001, 0),\n                                       ('Studyname:', 9000, 0)]\n    self._section_title = ''\n    self._section_description = ''\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.E2EStudyStructure.add_folder","title":"<code>add_folder(folder)</code>","text":"<p>Add a folder to the Study.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>E2EFolder</code> <p>The folder to add.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def add_folder(self, folder: E2EFolder) -&gt; None:\n    \"\"\"Add a folder to the Study.\n\n    Args:\n        folder: The folder to add.\n    \"\"\"\n    if folder.series_id == -1:\n        try:\n            self.folders[folder.type].append(folder)\n        except KeyError:\n            self.folders[folder.type] = [folder]\n    else:\n        if folder.series_id not in self.series:\n            self.series[folder.series_id] = E2ESeriesStructure(\n                folder.series_id)\n        self.series[folder.series_id].add_folder(folder)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader","title":"<code>HeE2eReader(path)</code>","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>Index an E2E file.</p> <p>Initialization of the HeE2eReader class indexes the specified E2E file. This allows for printing the reader object for a quick overview of the files contents. If you want to access the data, the reader has to be used as a Context Manager.</p> <pre><code>with HeE2eReader(\"path/to/file.e2e\") as reader:\n    data = reader.volumes\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the e2e file.</p> required Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def __init__(self, path: Union[str, Path]):\n    \"\"\"Index an E2E file.\n\n    Initialization of the HeE2eReader class indexes the specified E2E file. This allows for printing the reader object\n    for a quick overview of the files contents. If you want to access the data, the reader has to be used as a Context Manager.\n\n    ```python\n    with HeE2eReader(\"path/to/file.e2e\") as reader:\n        data = reader.volumes\n    ```\n\n    Args:\n        path: Path to the e2e file.\n    \"\"\"\n    self.path = Path(path)\n    self.file_object: BufferedReader\n\n    # Index file to create hierarchy\n    self.file_hierarchy = E2EFileStructure()\n    self._index_file()\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.patients","title":"<code>patients</code>  <code>property</code>","text":"<p>List of all patients in the file as E2EPatient objects.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.series","title":"<code>series</code>  <code>property</code>","text":"<p>List of all series in the file as E2ESeries objects.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.studies","title":"<code>studies</code>  <code>property</code>","text":"<p>List of all studies in the file as E2EStudy objects.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.volume","title":"<code>volume</code>  <code>property</code>","text":"<p>First EyeVolume object in the E2E file.</p> <p>Returns:</p> Type Description <code>EyeVolume</code> <p>EyeVolume object for the first Series in the e2e file.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.volumes","title":"<code>volumes</code>  <code>property</code>","text":"<p>All EyeVolume objects in the E2E file.</p> <p>Returns:</p> Type Description <code>list[EyeVolume]</code> <p>List with EyeVolume objects for every Series in the e2e file.</p>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.find_float","title":"<code>find_float(value, excluded_folders=['images', 'layers'], slice_id=None, **kwargs)</code>","text":"<p>Find a float value in the e2e file.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>The value to find.</p> required <code>excluded_folders</code> <code>list[Union[int, str]]</code> <p>A list of folders to exclude from the search. None: Exclude no folders. \"images\": Exclude image data from search. \"layers\": Exclude layer data from search.</p> <code>['images', 'layers']</code> <code>slice_id</code> <code>Optional[int]</code> <p>The slice to search in. Specify 0 if you do not want to search through all slices but one slice per volume is enough.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments passed to <code>find_float</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[int, dict[int, dict[str, list[int]]]]</code> <p>A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def find_float(self,\n               value: float,\n               excluded_folders: list[Union[int,\n                                            str]] = ['images', 'layers'],\n               slice_id: Optional[int] = None,\n               **kwargs: Any) -&gt; dict[int, dict[int, dict[str, list[int]]]]:\n    \"\"\"Find a float value in the e2e file.\n\n    Args:\n        value: The value to find.\n        excluded_folders: A list of folders to exclude from the search.\n            None: Exclude no folders.\n            \"images\": Exclude image data from search.\n            \"layers\": Exclude layer data from search.\n        slice_id: The slice to search in. Specify 0 if you do not want to search through all slices but one slice per volume is enough.\n        **kwargs: Keyword arguments passed to [`find_float`][eyepy.io.utils.find_float].\n\n    Returns:\n        A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}\n    \"\"\"\n    if 'images' in excluded_folders:\n        excluded_folders[excluded_folders.index('images')] = 1073741824\n    if 'layers' in excluded_folders:\n        excluded_folders[excluded_folders.index('layers')] = 10019\n\n    results = defaultdict(dict)\n    for folder in self.file_hierarchy.all_folders:\n        if not int(folder.type) in excluded_folders and (\n                True if slice_id is None else folder.slice_id == slice_id):\n            res = find_float(folder.get_bytes(), value, **kwargs)\n            if res:\n                results[folder.series_id][folder.type] = res\n    results = {**results}\n    return results\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.find_int","title":"<code>find_int(value, excluded_folders=['images', 'layers'], slice_id=None, **kwargs)</code>","text":"<p>Find an integer value in the e2e file.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value to find.</p> required <code>excluded_folders</code> <code>list[Union[int, str]]</code> <p>A list of folders to exclude from the search. None: Exclude no folders. \"images\": Exclude image data from search. \"layers\": Exclude layer data from search.</p> <code>['images', 'layers']</code> <code>slice_id</code> <code>Optional[int]</code> <p>The slice id to search in.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments passed to <code>find_int</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[int, dict[int, dict[str, list[int]]]]</code> <p>A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def find_int(self,\n             value: int,\n             excluded_folders: list[Union[int,\n                                          str]] = ['images', 'layers'],\n             slice_id: Optional[int] = None,\n             **kwargs: Any) -&gt; dict[int, dict[int, dict[str, list[int]]]]:\n    \"\"\"Find an integer value in the e2e file.\n\n    Args:\n        value: The value to find.\n        excluded_folders: A list of folders to exclude from the search.\n            None: Exclude no folders.\n            \"images\": Exclude image data from search.\n            \"layers\": Exclude layer data from search.\n        slice_id: The slice id to search in.\n        **kwargs: Keyword arguments passed to [`find_int`][eyepy.io.utils.find_int].\n\n    Returns:\n        A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}\n    \"\"\"\n    if 'images' in excluded_folders:\n        excluded_folders[excluded_folders.index('images')] = 1073741824\n    if 'layers' in excluded_folders:\n        excluded_folders[excluded_folders.index('layers')] = 10019\n\n    results = defaultdict(dict)\n    for folder in self.file_hierarchy.all_folders:\n        if not int(folder.type) in excluded_folders and (\n                True if slice_id is None else folder.slice_id == slice_id):\n            res = find_int(folder.get_bytes(), value, **kwargs)\n            if res:\n                results[folder.series_id][folder.type] = res\n    results = {**results}\n    return results\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.find_number","title":"<code>find_number(value, excluded_folders=['images', 'layers'], slice_id=None, **kwargs)</code>","text":"<p>Find a number value in the e2e file.</p> <p>Use this function if you don't know if the value is an integer or a float. This is just a shortcut for calling <code>find_int</code> and <code>find_float</code> individually.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Union[int, float]</code> <p>The value to find.</p> required <code>excluded_folders</code> <code>list[Union[int, str]]</code> <p>A list of folders to exclude from the search. None: Exclude no folders. \"images\": Exclude image data from search. \"layers\": Exclude layer data from search.</p> <code>['images', 'layers']</code> <code>slice_id</code> <code>Optional[int]</code> <p>The slice to search in. Specify 0 if you do not want to search through all slices but one slice per volume is enough.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments passed to <code>find_int</code> and <code>find_float</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[int, dict[int, dict[str, list[int]]]]</code> <p>A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}</p> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def find_number(self,\n                value: Union[int, float],\n                excluded_folders: list[Union[int,\n                                             str]] = ['images', 'layers'],\n                slice_id: Optional[int] = None,\n                **kwargs: Any) -&gt; dict[int, dict[int, dict[str, list[int]]]]:\n    \"\"\"Find a number value in the e2e file.\n\n    Use this function if you don't know if the value is an integer or a float.\n    This is just a shortcut for calling [`find_int`][eyepy.io.he.e2e_reader.HeE2eReader.find_int]\n    and [`find_float`][eyepy.io.he.e2e_reader.HeE2eReader.find_float] individually.\n\n    Args:\n        value: The value to find.\n        excluded_folders: A list of folders to exclude from the search.\n            None: Exclude no folders.\n            \"images\": Exclude image data from search.\n            \"layers\": Exclude layer data from search.\n        slice_id: The slice to search in. Specify 0 if you do not want to search through all slices but one slice per volume is enough.\n        **kwargs: Keyword arguments passed to [`find_int`][eyepy.io.utils.find_int] and [`find_float`][eyepy.io.utils.find_float].\n\n    Returns:\n        A dictionary of the form {series_id(int): {folder_type(int): {fmt_string(str): [positions(int)]}}}\n    \"\"\"\n    results = {\n        **self.find_float(value, excluded_folders, slice_id, **kwargs),\n        **self.find_int(round(value), excluded_folders, slice_id, **kwargs)\n    }\n    return results\n</code></pre>"},{"location":"reference/src/eyepy/io/he/e2e_reader/#eyepy.io.he.e2e_reader.HeE2eReader.inspect","title":"<code>inspect(recursive=False, ind_prefix='', tables=True)</code>","text":"<p>Inspect the file hierarchy (contents) of the file.</p> <p>Parameters:</p> Name Type Description Default <code>recursive</code> <code>bool</code> <p>If True inspect lower level structures recursively.</p> <code>False</code> <code>ind_prefix</code> <code>str</code> <p>Indentation for showing information from lower level structures.</p> <code>''</code> <code>tables</code> <code>bool</code> <p>If True add markdown table overview of the contained folder types.</p> <code>True</code> Source code in <code>src/eyepy/io/he/e2e_reader.py</code> <pre><code>def inspect(self,\n            recursive: bool = False,\n            ind_prefix: str = '',\n            tables: bool = True) -&gt; str:\n    \"\"\"Inspect the file hierarchy (contents) of the file.\n\n    Args:\n        recursive: If True inspect lower level structures recursively.\n        ind_prefix: Indentation for showing information from lower level structures.\n        tables: If True add markdown table overview of the contained folder types.\n    \"\"\"\n    return self.file_hierarchy.inspect(recursive, ind_prefix, tables)\n</code></pre>"},{"location":"reference/src/eyepy/io/he/vol_reader/","title":"vol_reader","text":""},{"location":"reference/src/eyepy/io/he/vol_reader/#eyepy.io.he.vol_reader","title":"<code>eyepy.io.he.vol_reader</code>","text":"<p>Inspired by:</p> <p>https://github.com/ayl/heyexReader/blob/master/heyexReader/volReader.py https://github.com/FabianRathke/octSegmentation/blob/master/collector/HDEVolImporter.m</p>"},{"location":"reference/src/eyepy/io/he/vol_reader/#eyepy.io.he.vol_reader.HeVolWriter","title":"<code>HeVolWriter(volume)</code>","text":"Source code in <code>src/eyepy/io/he/vol_reader.py</code> <pre><code>def __init__(self, volume: EyeVolume):\n    self.volume = volume\n</code></pre>"},{"location":"reference/src/eyepy/io/he/xml_reader/","title":"xml_reader","text":""},{"location":"reference/src/eyepy/io/he/xml_reader/#eyepy.io.he.xml_reader","title":"<code>eyepy.io.he.xml_reader</code>","text":""},{"location":"reference/src/eyepy/quant/","title":"quant","text":""},{"location":"reference/src/eyepy/quant/#eyepy.quant","title":"<code>eyepy.quant</code>","text":"<p>Quantification module for ophthalmic image analysis.</p> <p>This module provides tools for quantifying features in ophthalmic images, including area measurements and spatial extent calculations relative to anatomical landmarks.</p>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin","title":"<code>AnatomicalOrigin(y, x, laterality, mode)</code>  <code>dataclass</code>","text":"<p>Reference origin based on anatomical landmarks.</p> <p>Defines a coordinate system origin that can be based on the optic disc, fovea, a hybrid approach, or a custom position.</p> <p>Coordinate System Convention: This class uses (row, col) image coordinates for input and output: - row: vertical axis, increases downward (corresponds to y) - col: horizontal axis, increases rightward (corresponds to x)</p> <p>The internal storage uses (y, x) where y=row and x=col. All methods that accept or return coordinates use (row, col) format unless explicitly documented otherwise.</p> <p>Attributes:</p> Name Type Description <code>y</code> <code>float</code> <p>Vertical (y) coordinate of the origin</p> <code>x</code> <code>float</code> <p>Horizontal (x) coordinate of the origin</p> <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> <code>mode</code> <code>OriginMode</code> <p>Origin mode used to determine the position</p>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.from_custom","title":"<code>from_custom(origin, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at custom position.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of custom origin</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at custom position</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_custom(\n    cls,\n    origin: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at custom position.\n\n    Args:\n        origin: (y, x) coordinates of custom origin\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at custom position\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=origin[0],\n        x=origin[1],\n        laterality=laterality,\n        mode=OriginMode.CUSTOM,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.from_fovea","title":"<code>from_fovea(fovea_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at fovea center.</p> <p>Parameters:</p> Name Type Description Default <code>fovea_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of fovea center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at fovea center</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_fovea(\n    cls,\n    fovea_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at fovea center.\n\n    Args:\n        fovea_center: (y, x) coordinates of fovea center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at fovea center\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=fovea_center[0],\n        x=fovea_center[1],\n        laterality=laterality,\n        mode=OriginMode.FOVEA,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.from_hybrid","title":"<code>from_hybrid(optic_disc_center, fovea_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create hybrid origin from optic disc and fovea positions.</p> <p>Uses the horizontal (x) position from the optic disc center and the vertical (y) position from the fovea center.</p> <p>Parameters:</p> Name Type Description Default <code>optic_disc_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of optic disc center</p> required <code>fovea_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of fovea center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin with y from fovea, x from optic disc</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_hybrid(\n    cls,\n    optic_disc_center: tuple[float, float],\n    fovea_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create hybrid origin from optic disc and fovea positions.\n\n    Uses the horizontal (x) position from the optic disc center and\n    the vertical (y) position from the fovea center.\n\n    Args:\n        optic_disc_center: (y, x) coordinates of optic disc center\n        fovea_center: (y, x) coordinates of fovea center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin with y from fovea, x from optic disc\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    # Origin: horizontal position from OD, vertical position from fovea\n    origin_y = fovea_center[0]\n    origin_x = optic_disc_center[1]\n\n    return cls(\n        y=origin_y,\n        x=origin_x,\n        laterality=laterality,\n        mode=OriginMode.HYBRID,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.from_optic_disc","title":"<code>from_optic_disc(optic_disc_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at optic disc center.</p> <p>Parameters:</p> Name Type Description Default <code>optic_disc_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of optic disc center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at optic disc center</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_optic_disc(\n    cls,\n    optic_disc_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at optic disc center.\n\n    Args:\n        optic_disc_center: (y, x) coordinates of optic disc center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at optic disc center\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=optic_disc_center[0],\n        x=optic_disc_center[1],\n        laterality=laterality,\n        mode=OriginMode.OPTIC_DISC,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.to_cartesian","title":"<code>to_cartesian(y, x)</code>","text":"<p>Convert image coordinates (row, col) to Cartesian coordinates relative to origin.</p> <p>Image coordinates use (row, col) convention where: - row increases downward - col increases to the right</p> <p>Cartesian output coordinates are anatomically oriented: - x: horizontal (positive = temporal, negative = nasal) - y: vertical (positive = inferior, negative = superior)</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>float</code> <p>Image row coordinate (increases downward)</p> required <code>x</code> <code>float</code> <p>Image column coordinate (increases to the right)</p> required <p>Returns:</p> Type Description <code>float</code> <p>(x_cart, y_cart) Cartesian coordinates relative to origin where:</p> <code>float</code> <ul> <li>x_cart: horizontal distance (positive = temporal, negative = nasal)</li> </ul> <code>tuple[float, float]</code> <ul> <li>y_cart: vertical distance (positive = inferior/downward, negative = superior/upward)</li> </ul> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_cartesian(self, y: float, x: float) -&gt; tuple[float, float]:\n    \"\"\"Convert image coordinates (row, col) to Cartesian coordinates relative\n    to origin.\n\n    Image coordinates use (row, col) convention where:\n    - row increases downward\n    - col increases to the right\n\n    Cartesian output coordinates are anatomically oriented:\n    - x: horizontal (positive = temporal, negative = nasal)\n    - y: vertical (positive = inferior, negative = superior)\n\n    Args:\n        y: Image row coordinate (increases downward)\n        x: Image column coordinate (increases to the right)\n\n    Returns:\n        (x_cart, y_cart) Cartesian coordinates relative to origin where:\n        - x_cart: horizontal distance (positive = temporal, negative = nasal)\n        - y_cart: vertical distance (positive = inferior/downward, negative = superior/upward)\n    \"\"\"\n    # Compute displacement in image coordinates\n    dx_image = x - self.x  # Column displacement\n    dy_image = y - self.y  # Row displacement (positive = downward)\n\n    # In Cartesian coordinates:\n    # - y_cart = dy_image (positive downward = inferior, negative upward = superior)\n    # - x_cart needs laterality adjustment for temporal/nasal\n\n    y_cart = dy_image  # Positive = inferior/downward, negative = superior/upward\n\n    # Adjust for laterality: temporal direction\n    # OD (right eye): nasal is to the right (positive dx), temporal is to the left (negative dx)\n    #                 So temporal (positive x_cart) = negative dx_image\n    # OS (left eye): nasal is to the left (negative dx), temporal is to the right (positive dx)\n    #                So temporal (positive x_cart) = positive dx_image\n    if self.laterality == 'OD':\n        x_cart = -dx_image\n    else:  # OS\n        x_cart = dx_image\n\n    return (x_cart, y_cart)\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.AnatomicalOrigin.to_polar","title":"<code>to_polar(y, x)</code>","text":"<p>Convert image coordinates (row, col) to polar coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>float</code> <p>Image row coordinate (increases downward)</p> required <code>x</code> <code>float</code> <p>Image column coordinate (increases to the right)</p> required <p>Returns:</p> Type Description <code>float</code> <p>(distance, angle) where:</p> <code>float</code> <ul> <li>distance: Euclidean distance from origin</li> </ul> <code>tuple[float, float]</code> <ul> <li>angle: Angle in radians (0 = temporal, \u03c0/2 = inferior,      \u03c0 = nasal, 3\u03c0/2 = superior)</li> </ul> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_polar(self, y: float, x: float) -&gt; tuple[float, float]:\n    \"\"\"Convert image coordinates (row, col) to polar coordinates.\n\n    Args:\n        y: Image row coordinate (increases downward)\n        x: Image column coordinate (increases to the right)\n\n    Returns:\n        (distance, angle) where:\n        - distance: Euclidean distance from origin\n        - angle: Angle in radians (0 = temporal, \u03c0/2 = inferior,\n                 \u03c0 = nasal, 3\u03c0/2 = superior)\n    \"\"\"\n    x_cart, y_cart = self.to_cartesian(y, x)\n    distance = np.sqrt(x_cart**2 + y_cart**2)\n    angle = np.arctan2(y_cart, x_cart)  # Range: [-\u03c0, \u03c0]\n\n    # Convert to [0, 2\u03c0] with 0 = temporal\n    if angle &lt; 0:\n        angle += 2 * np.pi\n\n    return (distance, angle)\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.DirectionalExtent","title":"<code>DirectionalExtent(temporal, nasal, superior, inferior, superior_temporal, inferior_temporal, superior_nasal, inferior_nasal)</code>  <code>dataclass</code>","text":"<p>Extent of a region in specific directions from origin.</p> <p>Contains ExtentMetrics for each of the 8 anatomical directions (4 cardinal + 4 ordinal) from an anatomical origin. Each direction includes mean, max, median, and standard deviation of boundary distances, along with a flag indicating if that specific direction touches the image border.</p> <p>Attributes:</p> Name Type Description <code>temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in temporal direction</p> <code>nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in nasal direction</p> <code>superior</code> <code>ExtentMetrics</code> <p>Extent metrics in superior direction</p> <code>inferior</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior direction</p> <code>superior_temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in superior-temporal direction</p> <code>inferior_temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior-temporal direction</p> <code>superior_nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in superior-nasal direction</p> <code>inferior_nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior-nasal direction</p>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.DirectionalExtent.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with nested structure: direction -&gt; metric -&gt; value</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary.\n\n    Returns:\n        Dictionary with nested structure: direction -&gt; metric -&gt; value\n    \"\"\"\n    return {\n        'temporal': self.temporal.to_dict(),\n        'nasal': self.nasal.to_dict(),\n        'superior': self.superior.to_dict(),\n        'inferior': self.inferior.to_dict(),\n        'superior_temporal': self.superior_temporal.to_dict(),\n        'inferior_temporal': self.inferior_temporal.to_dict(),\n        'superior_nasal': self.superior_nasal.to_dict(),\n        'inferior_nasal': self.inferior_nasal.to_dict(),\n    }\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.ExtentMetrics","title":"<code>ExtentMetrics(midpoint, mean, max, median, std, touches_border=False)</code>  <code>dataclass</code>","text":"<p>Metrics for extent in a single direction.</p> <p>Contains statistical measures of distances from the origin to boundary points within a single angular sector.</p> <p>Attributes:</p> Name Type Description <code>midpoint</code> <code>float</code> <p>Distance to boundary at exact midpoint angle of this direction</p> <code>mean</code> <code>float</code> <p>Mean distance to boundary points in this direction</p> <code>max</code> <code>float</code> <p>Maximum distance to boundary in this direction</p> <code>median</code> <code>float</code> <p>Median distance to boundary points in this direction</p> <code>std</code> <code>float</code> <p>Standard deviation of distances in this direction</p> <code>touches_border</code> <code>bool</code> <p>Whether the region extends to the image border in this            specific direction, indicating measurements may be truncated</p>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.ExtentMetrics.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping metric names to values</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary.\n\n    Returns:\n        Dictionary mapping metric names to values\n    \"\"\"\n    return {\n        'midpoint': self.midpoint,\n        'mean': self.mean,\n        'max': self.max,\n        'median': self.median,\n        'std': self.std,\n        'touches_border': self.touches_border,\n    }\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.OriginMode","title":"<code>OriginMode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Mode for determining the anatomical origin.</p> <p>OPTIC_DISC: Use optic disc center as origin FOVEA: Use fovea center as origin HYBRID: Use optic disc x-coordinate and fovea y-coordinate CUSTOM: Use a custom user-specified origin point</p>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.PolarReference","title":"<code>PolarReference(origin)</code>","text":"<p>Polar coordinate reference system for spatial analysis.</p> <p>Divides the image into 8 angular sectors (4 cardinal + 4 ordinal directions) relative to an anatomical origin for computing directional statistics.</p> <p>Attributes:</p> Name Type Description <code>origin</code> <p>Anatomical origin point</p> <p>Initialize polar reference system.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <code>AnatomicalOrigin</code> <p>Anatomical origin defining the coordinate system</p> required Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def __init__(\n    self,\n    origin: AnatomicalOrigin,\n):\n    \"\"\"Initialize polar reference system.\n\n    Args:\n        origin: Anatomical origin defining the coordinate system\n    \"\"\"\n    self.origin = origin\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.PolarReference.compute_directional_extent","title":"<code>compute_directional_extent(mask, scale_x=1.0, scale_y=1.0)</code>","text":"<p>Compute extent in all 8 directions with complete metrics.</p> <p>For each of the 8 anatomical directions (4 cardinal + 4 ordinal), computes: - Midpoint distance: distance to boundary at exact direction angle - Mean, max, median, std: statistics of all boundary points in that sector - Border flag: whether that specific direction touches the image border</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask of the region</p> required <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction</p> <code>1.0</code> <p>Returns:</p> Type Description <code>DirectionalExtent</code> <p>DirectionalExtent with ExtentMetrics for all 8 directions</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def compute_directional_extent(\n    self,\n    mask: npt.NDArray[np.bool_],\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n) -&gt; DirectionalExtent:\n    \"\"\"Compute extent in all 8 directions with complete metrics.\n\n    For each of the 8 anatomical directions (4 cardinal + 4 ordinal),\n    computes:\n    - Midpoint distance: distance to boundary at exact direction angle\n    - Mean, max, median, std: statistics of all boundary points in that sector\n    - Border flag: whether that specific direction touches the image border\n\n    Args:\n        mask: Binary mask of the region\n        scale_x: Micrometers per pixel in x-direction\n        scale_y: Micrometers per pixel in y-direction\n\n    Returns:\n        DirectionalExtent with ExtentMetrics for all 8 directions\n    \"\"\"\n    # Define the 8 directions with their midpoint angles and sector ranges\n    # Each sector spans \u03c0/4 radians (45 degrees) centered on its midpoint\n    directions_config = {\n        'temporal': {\n            'midpoint_angle': 0.0,\n            'sector_range': (-np.pi / 8, np.pi / 8),\n        },\n        'inferior_temporal': {\n            'midpoint_angle': np.pi / 4,\n            'sector_range': (np.pi / 8, 3 * np.pi / 8),\n        },\n        'inferior': {\n            'midpoint_angle': np.pi / 2,\n            'sector_range': (3 * np.pi / 8, 5 * np.pi / 8),\n        },\n        'inferior_nasal': {\n            'midpoint_angle': 3 * np.pi / 4,\n            'sector_range': (5 * np.pi / 8, 7 * np.pi / 8),\n        },\n        'nasal': {\n            'midpoint_angle': np.pi,\n            'sector_range': ((7 * np.pi / 8, np.pi), (-np.pi, -7 * np.pi / 8)),\n        },\n        'superior_nasal': {\n            'midpoint_angle': -3 * np.pi / 4,\n            'sector_range': (-7 * np.pi / 8, -5 * np.pi / 8),\n        },\n        'superior': {\n            'midpoint_angle': -np.pi / 2,\n            'sector_range': (-5 * np.pi / 8, -3 * np.pi / 8),\n        },\n        'superior_temporal': {\n            'midpoint_angle': -np.pi / 4,\n            'sector_range': (-3 * np.pi / 8, -np.pi / 8),\n        },\n    }\n\n    if not np.any(mask):\n        # Empty mask - return zeros for all directions\n        zero_metrics = ExtentMetrics(\n            midpoint=0.0, mean=0.0, max=0.0, median=0.0, std=0.0, touches_border=False\n        )\n        return DirectionalExtent(\n            temporal=zero_metrics,\n            nasal=zero_metrics,\n            superior=zero_metrics,\n            inferior=zero_metrics,\n            superior_temporal=zero_metrics,\n            inferior_temporal=zero_metrics,\n            superior_nasal=zero_metrics,\n            inferior_nasal=zero_metrics,\n        )\n\n    # Extract boundary pixels, properly handling border cases\n    y_coords, x_coords, _ = _extract_boundary_with_border(mask)\n\n    if len(y_coords) == 0:\n        # Single pixel mask - use the pixel itself\n        y_coords, x_coords = np.where(mask)\n\n    # Compute metrics for all 8 directions\n    mask_shape = (mask.shape[0], mask.shape[1])\n    metrics = {}\n    for direction_name, config in directions_config.items():\n        metrics[direction_name] = self._compute_single_direction_metrics(\n            y_coords=y_coords,\n            x_coords=x_coords,\n            scale_x=scale_x,\n            scale_y=scale_y,\n            midpoint_angle=config['midpoint_angle'],\n            sector_range=config['sector_range'],\n            mask_shape=mask_shape,\n        )\n\n    return DirectionalExtent(\n        temporal=metrics['temporal'],\n        nasal=metrics['nasal'],\n        superior=metrics['superior'],\n        inferior=metrics['inferior'],\n        superior_temporal=metrics['superior_temporal'],\n        inferior_temporal=metrics['inferior_temporal'],\n        superior_nasal=metrics['superior_nasal'],\n        inferior_nasal=metrics['inferior_nasal'],\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/#eyepy.quant.compute_area","title":"<code>compute_area(mask, scale_x=1.0, scale_y=1.0)</code>","text":"<p>Compute area of a binary mask in physical units.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask (True = region of interest)</p> required <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction (default: 1.0)</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Area in square micrometers (or square pixels if scales are 1.0)</p> Source code in <code>src/eyepy/quant/metrics.py</code> <pre><code>def compute_area(\n    mask: npt.NDArray[np.bool_],\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n) -&gt; float:\n    \"\"\"Compute area of a binary mask in physical units.\n\n    Args:\n        mask: Binary mask (True = region of interest)\n        scale_x: Micrometers per pixel in x-direction (default: 1.0)\n        scale_y: Micrometers per pixel in y-direction (default: 1.0)\n\n    Returns:\n        Area in square micrometers (or square pixels if scales are 1.0)\n    \"\"\"\n    pixel_area = scale_x * scale_y\n    n_pixels = np.sum(mask)\n    return float(n_pixels * pixel_area)\n</code></pre>"},{"location":"reference/src/eyepy/quant/metrics/","title":"metrics","text":""},{"location":"reference/src/eyepy/quant/metrics/#eyepy.quant.metrics","title":"<code>eyepy.quant.metrics</code>","text":"<p>Core metric calculations for quantification.</p> <p>This module provides fundamental metric calculations for area, distance, and other quantitative measures in ophthalmic images.</p>"},{"location":"reference/src/eyepy/quant/metrics/#eyepy.quant.metrics.compute_area","title":"<code>compute_area(mask, scale_x=1.0, scale_y=1.0)</code>","text":"<p>Compute area of a binary mask in physical units.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask (True = region of interest)</p> required <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction (default: 1.0)</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Area in square micrometers (or square pixels if scales are 1.0)</p> Source code in <code>src/eyepy/quant/metrics.py</code> <pre><code>def compute_area(\n    mask: npt.NDArray[np.bool_],\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n) -&gt; float:\n    \"\"\"Compute area of a binary mask in physical units.\n\n    Args:\n        mask: Binary mask (True = region of interest)\n        scale_x: Micrometers per pixel in x-direction (default: 1.0)\n        scale_y: Micrometers per pixel in y-direction (default: 1.0)\n\n    Returns:\n        Area in square micrometers (or square pixels if scales are 1.0)\n    \"\"\"\n    pixel_area = scale_x * scale_y\n    n_pixels = np.sum(mask)\n    return float(n_pixels * pixel_area)\n</code></pre>"},{"location":"reference/src/eyepy/quant/regions/","title":"regions","text":""},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions","title":"<code>eyepy.quant.regions</code>","text":""},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification","title":"<code>RegionQuantification(area, extent, origin=None, scale_x=1.0, scale_y=1.0, unit='px')</code>  <code>dataclass</code>","text":"<p>Base class for region quantification results.</p> <p>Attributes:</p> Name Type Description <code>area</code> <code>float</code> <p>Area of the region in square micrometers</p> <code>extent</code> <code>DirectionalExtent</code> <p>Directional extent from anatomical origin</p> <code>origin</code> <code>Optional[AnatomicalOrigin]</code> <p>Anatomical origin used for directional measurements (optional, for plotting)</p> <code>mask</code> <code>Optional[AnatomicalOrigin]</code> <p>Binary mask of the region (optional, for plotting)</p> <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction (optional, for plotting)</p> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction (optional, for plotting)</p> <code>unit</code> <code>str</code> <p>Unit for displaying distances, has to match the provided scale (Default: 'px')</p>"},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification.from_EyeEnface","title":"<code>from_EyeEnface(enface, area_map_name, origin_mode=OriginMode.HYBRID, custom_origin=None)</code>  <code>classmethod</code>","text":"<p>Create RegionQuantification from an EyeEnface object.</p> <p>A RegionQuantification quantifies an annotation mask of one connected component. Extents from a specified origin are computed in 8 directions.</p> <p>Parameters:</p> Name Type Description Default <code>enface</code> <code>EyeEnface</code> <p>EyeEnface object containing the image and annotations</p> required <code>area_map_name</code> <code>str</code> <p>Name of the area map containing the region to quantify</p> required <code>origin_mode</code> <code>OriginModeType</code> <p>Mode determining the reference origin.         Can be 'optic_disc', 'fovea', 'hybrid' or 'custom'         (default: 'hybrid')</p> <code>HYBRID</code> <code>custom_origin</code> <code>Optional[AnatomicalOrigin]</code> <p>AnatomicalOrigin to use when origin_mode is 'custom'           (default: None)</p> <code>None</code> <p>Returns:</p> Type Description <p>RegionQuantification subclass instance with computed metrics</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required annotations or area map are missing</p> Source code in <code>src/eyepy/quant/regions.py</code> <pre><code>@classmethod\ndef from_EyeEnface(\n    cls,\n    enface: 'EyeEnface',\n    area_map_name: str,\n    origin_mode: OriginModeType = OriginMode.HYBRID,\n    custom_origin: Optional[AnatomicalOrigin] = None,\n):\n    \"\"\"Create RegionQuantification from an EyeEnface object.\n\n    A RegionQuantification quantifies an annotation mask of one connected component.\n    Extents from a specified origin are computed in 8 directions.\n\n    Args:\n        enface: EyeEnface object containing the image and annotations\n        area_map_name: Name of the area map containing the region to quantify\n        origin_mode: Mode determining the reference origin.\n                    Can be 'optic_disc', 'fovea', 'hybrid' or 'custom'\n                    (default: 'hybrid')\n        custom_origin: AnatomicalOrigin to use when origin_mode is 'custom'\n                      (default: None)\n\n    Returns:\n        RegionQuantification subclass instance with computed metrics\n\n    Raises:\n        ValueError: If required annotations or area map are missing\n    \"\"\"\n    # Normalize origin_mode to ENUM\n    origin_mode = _normalize_origin_mode(origin_mode)\n\n    # Validate based on origin_mode\n    if origin_mode == OriginMode.CUSTOM:\n        if custom_origin is None:\n            raise ValueError(\n                'custom_origin must be provided when origin_mode is CUSTOM.'\n            )\n    elif origin_mode == OriginMode.OPTIC_DISC:\n        if enface.optic_disc is None:\n            raise ValueError(\n                'EyeEnface must have optic_disc annotation when origin_mode is OPTIC_DISC. '\n                'Set enface.optic_disc before calling from_EyeEnface().'\n            )\n    elif origin_mode == OriginMode.FOVEA:\n        if enface.fovea is None:\n            raise ValueError(\n                'EyeEnface must have fovea annotation when origin_mode is FOVEA. '\n                'Set enface.fovea before calling from_EyeEnface().'\n            )\n    elif origin_mode == OriginMode.HYBRID:\n        if enface.optic_disc is None:\n            raise ValueError(\n                'EyeEnface must have optic_disc annotation when origin_mode is HYBRID. '\n                'Set enface.optic_disc before calling from_EyeEnface().'\n            )\n        if enface.fovea is None:\n            raise ValueError(\n                'EyeEnface must have fovea annotation when origin_mode is HYBRID. '\n                'Set enface.fovea before calling from_EyeEnface().'\n            )\n\n    # Get the area map\n    if area_map_name not in enface.area_maps:\n        raise ValueError(\n            f'Area map \"{area_map_name}\" not found in EyeEnface. '\n            f'Available area maps: {list(enface.area_maps.keys())}.'\n        )\n\n    area_annotation = enface.area_maps[area_map_name]\n    mask = area_annotation.data\n\n    # Get scales\n    scale_x = enface.scale_x\n    scale_y = enface.scale_y\n\n    # Get unit from metadata if available, otherwise default to 'px'\n    unit = enface.meta.get('scale_unit', 'px')\n\n    # Handle different origin modes\n    if origin_mode == OriginMode.CUSTOM:\n        # custom_origin is guaranteed to be not None due to validation above\n        assert custom_origin is not None\n        return cls.from_mask_with_origin(\n            mask=mask,\n            origin=custom_origin,\n            scale_x=scale_x,\n            scale_y=scale_y,\n            unit=unit,\n        )\n    else:\n        # Check for laterality (needed for non-CUSTOM modes)\n        laterality = enface.meta.get('laterality', None)\n        if laterality is None:\n            raise ValueError(\n                'EyeEnface must have laterality information in metadata '\n                f'when origin_mode is {origin_mode.value}. '\n                'Set enface.meta[\"laterality\"] to \"OD\" or \"OS\".'\n            )\n\n        # Get anatomical landmarks (guaranteed to be not None due to validation above)\n        optic_disc_center = enface.optic_disc.center if enface.optic_disc else (0.0, 0.0)\n        fovea_center = enface.fovea.center if enface.fovea else (0.0, 0.0)\n\n        # Create quantification using existing from_mask method\n        return cls.from_mask(\n            mask=mask,\n            optic_disc_center=optic_disc_center,\n            fovea_center=fovea_center,\n            laterality=laterality,\n            scale_x=scale_x,\n            scale_y=scale_y,\n            origin_mode=origin_mode,\n            unit=unit,\n        )\n</code></pre>"},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification.from_mask","title":"<code>from_mask(mask, optic_disc_center=None, fovea_center=None, laterality=None, scale_x=1.0, scale_y=1.0, origin_mode=OriginMode.HYBRID, unit='px')</code>  <code>classmethod</code>","text":"<p>Quantify region from a binary mask.</p> <p>Computes directional extent (midpoint) and arc statistics in all 8 directions (temporal, nasal, superior, inferior, superior_temporal, inferior_temporal, superior_nasal, inferior_nasal) using both midpoint and statistics methods.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask of the region</p> required <code>optic_disc_center</code> <code>Optional[tuple[float, float]]</code> <p>(y, x) coordinates of optic disc center</p> <code>None</code> <code>fovea_center</code> <code>Optional[tuple[float, float]]</code> <p>(y, x) coordinates of fovea center</p> <code>None</code> <code>laterality</code> <code>Optional[str]</code> <p>Eye laterality ('OD' or 'OS')</p> <code>None</code> <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction</p> <code>1.0</code> <code>origin_mode</code> <code>OriginModeType</code> <p>Mode determining the reference origin.         Can be 'optic_disc', 'fovea', 'hybrid' or 'custom'         (default: 'hybrid')</p> <code>HYBRID</code> <code>unit</code> <code>str</code> <p>Unit for displaying distances (default: 'px')</p> <code>'px'</code> <p>Returns:</p> Type Description <p>RegionQuantification subclass instance with computed metrics</p> Source code in <code>src/eyepy/quant/regions.py</code> <pre><code>@classmethod\ndef from_mask(\n    cls,\n    mask: npt.NDArray[np.bool_],\n    optic_disc_center: Optional[tuple[float, float]] = None,\n    fovea_center: Optional[tuple[float, float]] = None,\n    laterality: Optional[str] = None,\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n    origin_mode: OriginModeType = OriginMode.HYBRID,\n    unit: str = 'px',\n):\n    \"\"\"Quantify region from a binary mask.\n\n    Computes directional extent (midpoint) and arc statistics in all 8 directions (temporal, nasal,\n    superior, inferior, superior_temporal, inferior_temporal, superior_nasal,\n    inferior_nasal) using both midpoint and statistics methods.\n\n    Args:\n        mask: Binary mask of the region\n        optic_disc_center: (y, x) coordinates of optic disc center\n        fovea_center: (y, x) coordinates of fovea center\n        laterality: Eye laterality ('OD' or 'OS')\n        scale_x: Micrometers per pixel in x-direction\n        scale_y: Micrometers per pixel in y-direction\n        origin_mode: Mode determining the reference origin.\n                    Can be 'optic_disc', 'fovea', 'hybrid' or 'custom'\n                    (default: 'hybrid')\n        unit: Unit for displaying distances (default: 'px')\n\n    Returns:\n        RegionQuantification subclass instance with computed metrics\n    \"\"\"\n    # Normalize origin_mode to ENUM\n    origin_mode = _normalize_origin_mode(origin_mode)\n\n    # Create anatomical origin based on mode\n    if origin_mode == OriginMode.OPTIC_DISC:\n        if optic_disc_center is None:\n            raise ValueError(\n                'optic_disc_center must be provided when origin_mode is OPTIC_DISC.'\n            )\n        if laterality is None:\n            raise ValueError(\n                'laterality must be provided when origin_mode is OPTIC_DISC.'\n            )\n        origin = AnatomicalOrigin.from_optic_disc(\n            optic_disc_center=optic_disc_center,\n            laterality=laterality,\n        )\n    elif origin_mode == OriginMode.FOVEA:\n        if fovea_center is None:\n            raise ValueError(\n                'fovea_center must be provided when origin_mode is FOVEA.'\n            )\n        if laterality is None:\n            raise ValueError(\n                'laterality must be provided when origin_mode is FOVEA.'\n            )\n        origin = AnatomicalOrigin.from_fovea(\n            fovea_center=fovea_center,\n            laterality=laterality,\n        )\n    elif origin_mode == OriginMode.HYBRID:\n        if optic_disc_center is None:\n            raise ValueError(\n                'optic_disc_center must be provided when origin_mode is HYBRID.'\n            )\n        if fovea_center is None:\n            raise ValueError(\n                'fovea_center must be provided when origin_mode is HYBRID.'\n            )\n        if laterality is None:\n            raise ValueError(\n                'laterality must be provided when origin_mode is HYBRID.'\n            )\n\n        origin = AnatomicalOrigin.from_hybrid(\n            optic_disc_center=optic_disc_center,\n            fovea_center=fovea_center,\n            laterality=laterality,\n        )\n    elif origin_mode == OriginMode.CUSTOM:\n        raise ValueError(\n            f'Use from_mask_with_origin() for OriginMode.CUSTOM'\n        )\n\n    return cls.from_mask_with_origin(\n        mask=mask,\n        origin=origin,\n        scale_x=scale_x,\n        scale_y=scale_y,\n        unit=unit,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification.from_mask_with_origin","title":"<code>from_mask_with_origin(mask, origin, scale_x=1.0, scale_y=1.0, unit='px')</code>  <code>classmethod</code>","text":"<p>Quantify region from a binary mask with custom origin.</p> <p>Computes directional extent (midpoint) and arc statistics in all 8 directions (temporal, nasal, superior, inferior, superior_temporal, inferior_temporal, superior_nasal, inferior_nasal).</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask of the region</p> required <code>origin</code> <code>AnatomicalOrigin</code> <p>AnatomicalOrigin defining the reference point</p> required <code>scale_x</code> <code>float</code> <p>Size of a pixel in x-direction (default: 1.0)</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Size of a pixel in y-direction (default: 1.0)</p> <code>1.0</code> <code>unit</code> <code>str</code> <p>Unit for displaying distances (default: 'px')</p> <code>'px'</code> <p>Returns:</p> Type Description <p>RegionQuantification subclass instance with computed metrics</p> Source code in <code>src/eyepy/quant/regions.py</code> <pre><code>@classmethod\ndef from_mask_with_origin(\n    cls,\n    mask: npt.NDArray[np.bool_],\n    origin: AnatomicalOrigin,\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n    unit: str = 'px',\n):\n    \"\"\"Quantify region from a binary mask with custom origin.\n\n    Computes directional extent (midpoint) and arc statistics in all 8 directions (temporal, nasal,\n    superior, inferior, superior_temporal, inferior_temporal, superior_nasal,\n    inferior_nasal).\n\n    Args:\n        mask: Binary mask of the region\n        origin: AnatomicalOrigin defining the reference point\n        scale_x: Size of a pixel in x-direction (default: 1.0)\n        scale_y: Size of a pixel in y-direction (default: 1.0)\n        unit: Unit for displaying distances (default: 'px')\n\n    Returns:\n        RegionQuantification subclass instance with computed metrics\n    \"\"\"\n    # Compute area\n    area = compute_area(mask, scale_x, scale_y)\n\n    # Compute directional extent\n    polar_ref = PolarReference(origin)\n    extent = polar_ref.compute_directional_extent(\n        mask,\n        scale_x=scale_x,\n        scale_y=scale_y,\n    )\n\n    return cls(\n        area=area,\n        extent=extent,\n        origin=origin,\n        scale_x=scale_x,\n        scale_y=scale_y,\n        unit=unit,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification.plot","title":"<code>plot(ax=None, show_origin=True, show_extent_lines=True, directions=None, origin_color='blue', origin_marker='x', origin_size=100, line_color='yellow', line_width=2, font_size=10)</code>","text":"<p>Plot the region with directional extent measurements.</p> <p>Visualizes the quantification by showing: - The anatomical origin point - Directional extent lines with distance annotations</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes to plot on (creates new if None)</p> <code>None</code> <code>show_origin</code> <code>bool</code> <p>Whether to mark the origin point</p> <code>True</code> <code>show_extent_lines</code> <code>bool</code> <p>Whether to show directional extent lines</p> <code>True</code> <code>directions</code> <code>Optional[list[str]]</code> <p>List of directions to plot. If None, plots all 8 directions.        Valid values: 'temporal', 'nasal', 'superior', 'inferior',        'superior_temporal', 'inferior_temporal', 'superior_nasal',        'inferior_nasal'</p> <code>None</code> <code>origin_color</code> <code>str</code> <p>Color for the origin marker</p> <code>'blue'</code> <code>origin_marker</code> <code>str</code> <p>Marker style for origin point</p> <code>'x'</code> <code>origin_size</code> <code>float</code> <p>Size of origin marker</p> <code>100</code> <code>line_color</code> <code>str</code> <p>Color for extent lines</p> <code>'yellow'</code> <code>line_width</code> <code>float</code> <p>Width of extent lines</p> <code>2</code> <code>font_size</code> <code>int</code> <p>Font size for distance annotations</p> <code>10</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Matplotlib axes with the plot</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If origin is not available when needed</p> Source code in <code>src/eyepy/quant/regions.py</code> <pre><code>def plot(\n    self,\n    ax: Optional['Axes'] = None,\n    show_origin: bool = True,\n    show_extent_lines: bool = True,\n    directions: Optional[list[str]] = None,\n    origin_color: str = 'blue',\n    origin_marker: str = 'x',\n    origin_size: float = 100,\n    line_color: str = 'yellow',\n    line_width: float = 2,\n    font_size: int = 10,\n) -&gt; 'Axes':\n    \"\"\"Plot the region with directional extent measurements.\n\n    Visualizes the quantification by showing:\n    - The anatomical origin point\n    - Directional extent lines with distance annotations\n\n    Args:\n        ax: Matplotlib axes to plot on (creates new if None)\n        show_origin: Whether to mark the origin point\n        show_extent_lines: Whether to show directional extent lines\n        directions: List of directions to plot. If None, plots all 8 directions.\n                   Valid values: 'temporal', 'nasal', 'superior', 'inferior',\n                   'superior_temporal', 'inferior_temporal', 'superior_nasal',\n                   'inferior_nasal'\n        origin_color: Color for the origin marker\n        origin_marker: Marker style for origin point\n        origin_size: Size of origin marker\n        line_color: Color for extent lines\n        line_width: Width of extent lines\n        font_size: Font size for distance annotations\n\n    Returns:\n        Matplotlib axes with the plot\n\n    Raises:\n        ValueError: If origin is not available when needed\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10))\n    ax.set_aspect('equal')\n\n    # Check if origin is available for remaining visualizations\n    if (show_origin or show_extent_lines) and self.origin is None:\n        raise ValueError(\n            'Origin must be provided to plot origin point or extent lines. '\n            'Use from_mask() or from_mask_with_origin() to create quantification '\n            'with origin information.'\n        )\n\n    # Show origin point\n    if show_origin and self.origin is not None:\n        ax.scatter(\n            self.origin.x,\n            self.origin.y,\n            c=origin_color,\n            marker=origin_marker,\n            s=origin_size,\n            zorder=10,\n            label='Origin',\n        )\n\n    # Show directional extent lines\n    if show_extent_lines and self.origin is not None:\n        # Define all available directions and their angles\n        all_directions = {\n            'temporal': (0, 'T'),\n            'nasal': (np.pi, 'N'),\n            'superior': (-np.pi / 2, 'S'),\n            'inferior': (np.pi / 2, 'I'),\n            'superior_temporal': (-np.pi / 4, 'ST'),\n            'inferior_temporal': (np.pi / 4, 'IT'),\n            'superior_nasal': (-3 * np.pi / 4, 'SN'),\n            'inferior_nasal': (3 * np.pi / 4, 'IN'),\n        }\n\n        # Filter to requested directions (or all if None)\n        if directions is None:\n            directions_to_plot = all_directions\n        else:\n            # Validate requested directions\n            invalid = set(directions) - set(all_directions.keys())\n            if invalid:\n                raise ValueError(\n                    f'Invalid direction(s): {invalid}. '\n                    f'Valid directions are: {list(all_directions.keys())}'\n                )\n            directions_to_plot = {k: v for k, v in all_directions.items() if k in directions}\n\n        for direction, (angle, label) in directions_to_plot.items():\n            extent_metrics = getattr(self.extent, direction, None)\n            if extent_metrics is None:\n                continue\n\n            # Extract midpoint distance from ExtentMetrics\n            distance = extent_metrics.midpoint\n            if distance == 0:\n                continue\n\n            # Convert angle and distance to Cartesian endpoint\n            # Note: in image coordinates, y increases downward\n            # angle=0 is temporal (positive x_cart)\n            # We need to convert from anatomical coordinates back to image coordinates\n            x_cart = distance * np.cos(angle)\n            y_cart = distance * np.sin(angle)\n\n            # Convert back to image coordinates from anatomical coordinates\n            # For OD: x_cart positive = temporal = left = negative dx_image\n            # For OS: x_cart positive = temporal = right = positive dx_image\n            if self.origin.laterality == 'OD':\n                dx_image = -x_cart / self.scale_x\n            else:\n                dx_image = x_cart / self.scale_x\n\n            dy_image = y_cart / self.scale_y\n\n            end_x = self.origin.x + dx_image\n            end_y = self.origin.y + dy_image\n\n            # Draw line from origin to endpoint\n            ax.plot(\n                [self.origin.x, end_x],\n                [self.origin.y, end_y],\n                color=line_color,\n                linewidth=line_width,\n                zorder=5,\n            )\n\n            # Add text annotation at midpoint\n            mid_x = (self.origin.x + end_x) / 2\n            mid_y = (self.origin.y + end_y) / 2\n\n            # Format distance based on unit\n            dist_text = self._format_distance(distance)\n\n            ax.text(\n                mid_x,\n                mid_y,\n                f'{label}: {dist_text}',\n                color='white',\n                fontsize=font_size,\n                ha='center',\n                va='center',\n                bbox=dict(\n                    boxstyle='round,pad=0.3',\n                    facecolor='black',\n                    alpha=0.7,\n                    edgecolor='none',\n                ),\n                zorder=15,\n            )\n\n    return ax\n</code></pre>"},{"location":"reference/src/eyepy/quant/regions/#eyepy.quant.regions.RegionQuantification.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary for easy export.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with all quantification metrics</p> Source code in <code>src/eyepy/quant/regions.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary for easy export.\n\n    Returns:\n        Dictionary with all quantification metrics\n    \"\"\"\n    result = {\n        'area': self.area,\n    }\n    result.update(self.extent.to_dict())\n    return result\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/","title":"spatial","text":""},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial","title":"<code>eyepy.quant.spatial</code>","text":"<p>Spatial reference systems for anatomical quantification.</p> <p>This module provides classes for defining spatial reference frames based on anatomical landmarks (optic disc, fovea) and computing distances and directions relative to these references.</p>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin","title":"<code>AnatomicalOrigin(y, x, laterality, mode)</code>  <code>dataclass</code>","text":"<p>Reference origin based on anatomical landmarks.</p> <p>Defines a coordinate system origin that can be based on the optic disc, fovea, a hybrid approach, or a custom position.</p> <p>Coordinate System Convention: This class uses (row, col) image coordinates for input and output: - row: vertical axis, increases downward (corresponds to y) - col: horizontal axis, increases rightward (corresponds to x)</p> <p>The internal storage uses (y, x) where y=row and x=col. All methods that accept or return coordinates use (row, col) format unless explicitly documented otherwise.</p> <p>Attributes:</p> Name Type Description <code>y</code> <code>float</code> <p>Vertical (y) coordinate of the origin</p> <code>x</code> <code>float</code> <p>Horizontal (x) coordinate of the origin</p> <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> <code>mode</code> <code>OriginMode</code> <p>Origin mode used to determine the position</p>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.from_custom","title":"<code>from_custom(origin, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at custom position.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of custom origin</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at custom position</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_custom(\n    cls,\n    origin: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at custom position.\n\n    Args:\n        origin: (y, x) coordinates of custom origin\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at custom position\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=origin[0],\n        x=origin[1],\n        laterality=laterality,\n        mode=OriginMode.CUSTOM,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.from_fovea","title":"<code>from_fovea(fovea_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at fovea center.</p> <p>Parameters:</p> Name Type Description Default <code>fovea_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of fovea center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at fovea center</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_fovea(\n    cls,\n    fovea_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at fovea center.\n\n    Args:\n        fovea_center: (y, x) coordinates of fovea center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at fovea center\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=fovea_center[0],\n        x=fovea_center[1],\n        laterality=laterality,\n        mode=OriginMode.FOVEA,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.from_hybrid","title":"<code>from_hybrid(optic_disc_center, fovea_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create hybrid origin from optic disc and fovea positions.</p> <p>Uses the horizontal (x) position from the optic disc center and the vertical (y) position from the fovea center.</p> <p>Parameters:</p> Name Type Description Default <code>optic_disc_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of optic disc center</p> required <code>fovea_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of fovea center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin with y from fovea, x from optic disc</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_hybrid(\n    cls,\n    optic_disc_center: tuple[float, float],\n    fovea_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create hybrid origin from optic disc and fovea positions.\n\n    Uses the horizontal (x) position from the optic disc center and\n    the vertical (y) position from the fovea center.\n\n    Args:\n        optic_disc_center: (y, x) coordinates of optic disc center\n        fovea_center: (y, x) coordinates of fovea center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin with y from fovea, x from optic disc\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    # Origin: horizontal position from OD, vertical position from fovea\n    origin_y = fovea_center[0]\n    origin_x = optic_disc_center[1]\n\n    return cls(\n        y=origin_y,\n        x=origin_x,\n        laterality=laterality,\n        mode=OriginMode.HYBRID,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.from_optic_disc","title":"<code>from_optic_disc(optic_disc_center, laterality)</code>  <code>classmethod</code>","text":"<p>Create origin at optic disc center.</p> <p>Parameters:</p> Name Type Description Default <code>optic_disc_center</code> <code>tuple[float, float]</code> <p>(y, x) coordinates of optic disc center</p> required <code>laterality</code> <code>str</code> <p>Eye laterality ('OD' or 'OS')</p> required <p>Returns:</p> Type Description <code>AnatomicalOrigin</code> <p>AnatomicalOrigin at optic disc center</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>@classmethod\ndef from_optic_disc(\n    cls,\n    optic_disc_center: tuple[float, float],\n    laterality: str,\n) -&gt; 'AnatomicalOrigin':\n    \"\"\"Create origin at optic disc center.\n\n    Args:\n        optic_disc_center: (y, x) coordinates of optic disc center\n        laterality: Eye laterality ('OD' or 'OS')\n\n    Returns:\n        AnatomicalOrigin at optic disc center\n    \"\"\"\n    if laterality not in ['OD', 'OS']:\n        raise ValueError(f'Laterality must be OD or OS, got {laterality}')\n\n    return cls(\n        y=optic_disc_center[0],\n        x=optic_disc_center[1],\n        laterality=laterality,\n        mode=OriginMode.OPTIC_DISC,\n    )\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.to_cartesian","title":"<code>to_cartesian(y, x)</code>","text":"<p>Convert image coordinates (row, col) to Cartesian coordinates relative to origin.</p> <p>Image coordinates use (row, col) convention where: - row increases downward - col increases to the right</p> <p>Cartesian output coordinates are anatomically oriented: - x: horizontal (positive = temporal, negative = nasal) - y: vertical (positive = inferior, negative = superior)</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>float</code> <p>Image row coordinate (increases downward)</p> required <code>x</code> <code>float</code> <p>Image column coordinate (increases to the right)</p> required <p>Returns:</p> Type Description <code>float</code> <p>(x_cart, y_cart) Cartesian coordinates relative to origin where:</p> <code>float</code> <ul> <li>x_cart: horizontal distance (positive = temporal, negative = nasal)</li> </ul> <code>tuple[float, float]</code> <ul> <li>y_cart: vertical distance (positive = inferior/downward, negative = superior/upward)</li> </ul> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_cartesian(self, y: float, x: float) -&gt; tuple[float, float]:\n    \"\"\"Convert image coordinates (row, col) to Cartesian coordinates relative\n    to origin.\n\n    Image coordinates use (row, col) convention where:\n    - row increases downward\n    - col increases to the right\n\n    Cartesian output coordinates are anatomically oriented:\n    - x: horizontal (positive = temporal, negative = nasal)\n    - y: vertical (positive = inferior, negative = superior)\n\n    Args:\n        y: Image row coordinate (increases downward)\n        x: Image column coordinate (increases to the right)\n\n    Returns:\n        (x_cart, y_cart) Cartesian coordinates relative to origin where:\n        - x_cart: horizontal distance (positive = temporal, negative = nasal)\n        - y_cart: vertical distance (positive = inferior/downward, negative = superior/upward)\n    \"\"\"\n    # Compute displacement in image coordinates\n    dx_image = x - self.x  # Column displacement\n    dy_image = y - self.y  # Row displacement (positive = downward)\n\n    # In Cartesian coordinates:\n    # - y_cart = dy_image (positive downward = inferior, negative upward = superior)\n    # - x_cart needs laterality adjustment for temporal/nasal\n\n    y_cart = dy_image  # Positive = inferior/downward, negative = superior/upward\n\n    # Adjust for laterality: temporal direction\n    # OD (right eye): nasal is to the right (positive dx), temporal is to the left (negative dx)\n    #                 So temporal (positive x_cart) = negative dx_image\n    # OS (left eye): nasal is to the left (negative dx), temporal is to the right (positive dx)\n    #                So temporal (positive x_cart) = positive dx_image\n    if self.laterality == 'OD':\n        x_cart = -dx_image\n    else:  # OS\n        x_cart = dx_image\n\n    return (x_cart, y_cart)\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.AnatomicalOrigin.to_polar","title":"<code>to_polar(y, x)</code>","text":"<p>Convert image coordinates (row, col) to polar coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>float</code> <p>Image row coordinate (increases downward)</p> required <code>x</code> <code>float</code> <p>Image column coordinate (increases to the right)</p> required <p>Returns:</p> Type Description <code>float</code> <p>(distance, angle) where:</p> <code>float</code> <ul> <li>distance: Euclidean distance from origin</li> </ul> <code>tuple[float, float]</code> <ul> <li>angle: Angle in radians (0 = temporal, \u03c0/2 = inferior,      \u03c0 = nasal, 3\u03c0/2 = superior)</li> </ul> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_polar(self, y: float, x: float) -&gt; tuple[float, float]:\n    \"\"\"Convert image coordinates (row, col) to polar coordinates.\n\n    Args:\n        y: Image row coordinate (increases downward)\n        x: Image column coordinate (increases to the right)\n\n    Returns:\n        (distance, angle) where:\n        - distance: Euclidean distance from origin\n        - angle: Angle in radians (0 = temporal, \u03c0/2 = inferior,\n                 \u03c0 = nasal, 3\u03c0/2 = superior)\n    \"\"\"\n    x_cart, y_cart = self.to_cartesian(y, x)\n    distance = np.sqrt(x_cart**2 + y_cart**2)\n    angle = np.arctan2(y_cart, x_cart)  # Range: [-\u03c0, \u03c0]\n\n    # Convert to [0, 2\u03c0] with 0 = temporal\n    if angle &lt; 0:\n        angle += 2 * np.pi\n\n    return (distance, angle)\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.DirectionalExtent","title":"<code>DirectionalExtent(temporal, nasal, superior, inferior, superior_temporal, inferior_temporal, superior_nasal, inferior_nasal)</code>  <code>dataclass</code>","text":"<p>Extent of a region in specific directions from origin.</p> <p>Contains ExtentMetrics for each of the 8 anatomical directions (4 cardinal + 4 ordinal) from an anatomical origin. Each direction includes mean, max, median, and standard deviation of boundary distances, along with a flag indicating if that specific direction touches the image border.</p> <p>Attributes:</p> Name Type Description <code>temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in temporal direction</p> <code>nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in nasal direction</p> <code>superior</code> <code>ExtentMetrics</code> <p>Extent metrics in superior direction</p> <code>inferior</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior direction</p> <code>superior_temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in superior-temporal direction</p> <code>inferior_temporal</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior-temporal direction</p> <code>superior_nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in superior-nasal direction</p> <code>inferior_nasal</code> <code>ExtentMetrics</code> <p>Extent metrics in inferior-nasal direction</p>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.DirectionalExtent.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with nested structure: direction -&gt; metric -&gt; value</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary.\n\n    Returns:\n        Dictionary with nested structure: direction -&gt; metric -&gt; value\n    \"\"\"\n    return {\n        'temporal': self.temporal.to_dict(),\n        'nasal': self.nasal.to_dict(),\n        'superior': self.superior.to_dict(),\n        'inferior': self.inferior.to_dict(),\n        'superior_temporal': self.superior_temporal.to_dict(),\n        'inferior_temporal': self.inferior_temporal.to_dict(),\n        'superior_nasal': self.superior_nasal.to_dict(),\n        'inferior_nasal': self.inferior_nasal.to_dict(),\n    }\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.ExtentMetrics","title":"<code>ExtentMetrics(midpoint, mean, max, median, std, touches_border=False)</code>  <code>dataclass</code>","text":"<p>Metrics for extent in a single direction.</p> <p>Contains statistical measures of distances from the origin to boundary points within a single angular sector.</p> <p>Attributes:</p> Name Type Description <code>midpoint</code> <code>float</code> <p>Distance to boundary at exact midpoint angle of this direction</p> <code>mean</code> <code>float</code> <p>Mean distance to boundary points in this direction</p> <code>max</code> <code>float</code> <p>Maximum distance to boundary in this direction</p> <code>median</code> <code>float</code> <p>Median distance to boundary points in this direction</p> <code>std</code> <code>float</code> <p>Standard deviation of distances in this direction</p> <code>touches_border</code> <code>bool</code> <p>Whether the region extends to the image border in this            specific direction, indicating measurements may be truncated</p>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.ExtentMetrics.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping metric names to values</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert to dictionary.\n\n    Returns:\n        Dictionary mapping metric names to values\n    \"\"\"\n    return {\n        'midpoint': self.midpoint,\n        'mean': self.mean,\n        'max': self.max,\n        'median': self.median,\n        'std': self.std,\n        'touches_border': self.touches_border,\n    }\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.OriginMode","title":"<code>OriginMode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Mode for determining the anatomical origin.</p> <p>OPTIC_DISC: Use optic disc center as origin FOVEA: Use fovea center as origin HYBRID: Use optic disc x-coordinate and fovea y-coordinate CUSTOM: Use a custom user-specified origin point</p>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.PolarReference","title":"<code>PolarReference(origin)</code>","text":"<p>Polar coordinate reference system for spatial analysis.</p> <p>Divides the image into 8 angular sectors (4 cardinal + 4 ordinal directions) relative to an anatomical origin for computing directional statistics.</p> <p>Attributes:</p> Name Type Description <code>origin</code> <p>Anatomical origin point</p> <p>Initialize polar reference system.</p> <p>Parameters:</p> Name Type Description Default <code>origin</code> <code>AnatomicalOrigin</code> <p>Anatomical origin defining the coordinate system</p> required Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def __init__(\n    self,\n    origin: AnatomicalOrigin,\n):\n    \"\"\"Initialize polar reference system.\n\n    Args:\n        origin: Anatomical origin defining the coordinate system\n    \"\"\"\n    self.origin = origin\n</code></pre>"},{"location":"reference/src/eyepy/quant/spatial/#eyepy.quant.spatial.PolarReference.compute_directional_extent","title":"<code>compute_directional_extent(mask, scale_x=1.0, scale_y=1.0)</code>","text":"<p>Compute extent in all 8 directions with complete metrics.</p> <p>For each of the 8 anatomical directions (4 cardinal + 4 ordinal), computes: - Midpoint distance: distance to boundary at exact direction angle - Mean, max, median, std: statistics of all boundary points in that sector - Border flag: whether that specific direction touches the image border</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>NDArray[bool_]</code> <p>Binary mask of the region</p> required <code>scale_x</code> <code>float</code> <p>Micrometers per pixel in x-direction</p> <code>1.0</code> <code>scale_y</code> <code>float</code> <p>Micrometers per pixel in y-direction</p> <code>1.0</code> <p>Returns:</p> Type Description <code>DirectionalExtent</code> <p>DirectionalExtent with ExtentMetrics for all 8 directions</p> Source code in <code>src/eyepy/quant/spatial.py</code> <pre><code>def compute_directional_extent(\n    self,\n    mask: npt.NDArray[np.bool_],\n    scale_x: float = 1.0,\n    scale_y: float = 1.0,\n) -&gt; DirectionalExtent:\n    \"\"\"Compute extent in all 8 directions with complete metrics.\n\n    For each of the 8 anatomical directions (4 cardinal + 4 ordinal),\n    computes:\n    - Midpoint distance: distance to boundary at exact direction angle\n    - Mean, max, median, std: statistics of all boundary points in that sector\n    - Border flag: whether that specific direction touches the image border\n\n    Args:\n        mask: Binary mask of the region\n        scale_x: Micrometers per pixel in x-direction\n        scale_y: Micrometers per pixel in y-direction\n\n    Returns:\n        DirectionalExtent with ExtentMetrics for all 8 directions\n    \"\"\"\n    # Define the 8 directions with their midpoint angles and sector ranges\n    # Each sector spans \u03c0/4 radians (45 degrees) centered on its midpoint\n    directions_config = {\n        'temporal': {\n            'midpoint_angle': 0.0,\n            'sector_range': (-np.pi / 8, np.pi / 8),\n        },\n        'inferior_temporal': {\n            'midpoint_angle': np.pi / 4,\n            'sector_range': (np.pi / 8, 3 * np.pi / 8),\n        },\n        'inferior': {\n            'midpoint_angle': np.pi / 2,\n            'sector_range': (3 * np.pi / 8, 5 * np.pi / 8),\n        },\n        'inferior_nasal': {\n            'midpoint_angle': 3 * np.pi / 4,\n            'sector_range': (5 * np.pi / 8, 7 * np.pi / 8),\n        },\n        'nasal': {\n            'midpoint_angle': np.pi,\n            'sector_range': ((7 * np.pi / 8, np.pi), (-np.pi, -7 * np.pi / 8)),\n        },\n        'superior_nasal': {\n            'midpoint_angle': -3 * np.pi / 4,\n            'sector_range': (-7 * np.pi / 8, -5 * np.pi / 8),\n        },\n        'superior': {\n            'midpoint_angle': -np.pi / 2,\n            'sector_range': (-5 * np.pi / 8, -3 * np.pi / 8),\n        },\n        'superior_temporal': {\n            'midpoint_angle': -np.pi / 4,\n            'sector_range': (-3 * np.pi / 8, -np.pi / 8),\n        },\n    }\n\n    if not np.any(mask):\n        # Empty mask - return zeros for all directions\n        zero_metrics = ExtentMetrics(\n            midpoint=0.0, mean=0.0, max=0.0, median=0.0, std=0.0, touches_border=False\n        )\n        return DirectionalExtent(\n            temporal=zero_metrics,\n            nasal=zero_metrics,\n            superior=zero_metrics,\n            inferior=zero_metrics,\n            superior_temporal=zero_metrics,\n            inferior_temporal=zero_metrics,\n            superior_nasal=zero_metrics,\n            inferior_nasal=zero_metrics,\n        )\n\n    # Extract boundary pixels, properly handling border cases\n    y_coords, x_coords, _ = _extract_boundary_with_border(mask)\n\n    if len(y_coords) == 0:\n        # Single pixel mask - use the pixel itself\n        y_coords, x_coords = np.where(mask)\n\n    # Compute metrics for all 8 directions\n    mask_shape = (mask.shape[0], mask.shape[1])\n    metrics = {}\n    for direction_name, config in directions_config.items():\n        metrics[direction_name] = self._compute_single_direction_metrics(\n            y_coords=y_coords,\n            x_coords=x_coords,\n            scale_x=scale_x,\n            scale_y=scale_y,\n            midpoint_angle=config['midpoint_angle'],\n            sector_range=config['sector_range'],\n            mask_shape=mask_shape,\n        )\n\n    return DirectionalExtent(\n        temporal=metrics['temporal'],\n        nasal=metrics['nasal'],\n        superior=metrics['superior'],\n        inferior=metrics['inferior'],\n        superior_temporal=metrics['superior_temporal'],\n        inferior_temporal=metrics['inferior_temporal'],\n        superior_nasal=metrics['superior_nasal'],\n        inferior_nasal=metrics['inferior_nasal'],\n    )\n</code></pre>"}]}